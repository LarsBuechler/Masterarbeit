{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "from matplotlib.lines import Line2D\n",
    "from math import radians, sin, cos, asin, sqrt\n",
    "import re\n",
    "import requests\n",
    "from datetime import time, timedelta, datetime\n",
    "from statistics import median, quantiles\n",
    "\n",
    "\n",
    "import geohash2\n",
    "import pyproj\n",
    "from pyproj import Proj, transform, CRS\n",
    "from functools import partial\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "from geopy.distance import geodesic\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy.stats import poisson\n",
    "\n",
    "from ortools.constraint_solver import routing_enums_pb2\n",
    "from ortools.constraint_solver import pywrapcp\n",
    "from ortools.linear_solver import pywraplp\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_demand_data(row):\n",
    "    probabilities = {\n",
    "        '0-10': 0,\n",
    "        '10-20': 0.003458068783068975,\n",
    "        '20-30': 0.013896825396825975,\n",
    "        '30-40': 0.02136825396825512,\n",
    "        '40-50': 0.02338333333333506,\n",
    "        '50-60': 0.026277248677250214,\n",
    "        '60-70': 0.03332089947090043,\n",
    "        '70-80': 0.046515343915346036,\n",
    "        '80+': 0.046515343915346036,\n",
    "    }\n",
    "\n",
    "    total_demand = 0\n",
    "    for age_group, count in row['Alter'].items():\n",
    "        lambda_value = count * probabilities[age_group]\n",
    "        total_demand += poisson.rvs(lambda_value)\n",
    "    return total_demand\n",
    "\n",
    "\n",
    "def setup_customer_data(folder, city):\n",
    "    customers_gdf = gpd.read_file(f'./{folder}/cluster_{city}.gpkg')\n",
    "    customers_gdf['Alter'] = customers_gdf['Alter'].apply(json.loads)\n",
    "    customers_gdf['nachfrage'] = 0\n",
    "    for i in range(365):\n",
    "        customers_gdf['nachfrage'] += customers_gdf.apply(calculate_demand_data, axis=1)\n",
    "\n",
    "    bevoelkerung_sum = customers_gdf[customers_gdf['cluster'] != -1].groupby('cluster')['sum_INSGESAMT_0'].sum()\n",
    "    noise_demand = customers_gdf[customers_gdf['cluster'] == -1]['nachfrage'].iloc[0]\n",
    "\n",
    "    # Verteilung des Noise-Bedarfs auf die anderen Cluster anteilig zur Anzahl der Polygone\n",
    "    for cluster in bevoelkerung_sum.index:\n",
    "        cluster_demand = noise_demand * (bevoelkerung_sum[cluster] / bevoelkerung_sum.sum())\n",
    "        customers_gdf.loc[customers_gdf['cluster'] == cluster, 'nachfrage'] += np.round(cluster_demand)\n",
    "\n",
    "    customers_gdf = customers_gdf[customers_gdf['cluster'] != -1].reset_index(drop=True)\n",
    "    # Set Index to cluster id\n",
    "    customers_gdf.set_index(['cluster'], inplace=True)\n",
    "\n",
    "    return customers_gdf\n",
    "\n",
    "\n",
    "def load_energy_costs():\n",
    "    # Calculate timestamps (current time minus 48 hours and current time)\n",
    "    current_time = datetime.now()\n",
    "    past_timestamp = (current_time - timedelta(days=365)).timestamp() * 1000\n",
    "    current_timestamp = current_time.timestamp() * 1000\n",
    "\n",
    "    # Construct the API URL with updated timestamps\n",
    "    api_url = f\"https://api.awattar.de/v1/marketdata?start={past_timestamp}&end={current_timestamp}\"\n",
    "\n",
    "    # Send GET request using the requests library\n",
    "    try:\n",
    "        response = requests.get(api_url)\n",
    "        response.raise_for_status()  # Raise an exception for non-2xx status codes\n",
    "    except requests.exceptions.RequestException as error:\n",
    "        print(f\"Error: {error}\")\n",
    "\n",
    "    # Load data in json format\n",
    "    data_energy = json.loads(response.content)\n",
    "    # Extract market prices\n",
    "    market_prices = [item[\"marketprice\"] for item in data_energy[\"data\"]]\n",
    "\n",
    "    # Calculate quantiles\n",
    "    q1, q2, q3 = quantiles(market_prices)  # Use quartiles function\n",
    "    # Transform to Eur/kWh\n",
    "    q1_kwh_eur = q1 / 1000\n",
    "    q2_kwh_eur = q2 / 1000\n",
    "    q3_kwh_eur = q3 / 1000\n",
    "\n",
    "    print(f\"Median market price (kWh): {q2_kwh_eur:.5f} Eur/kWh\")\n",
    "    print(f\"25th percentile (Q1, kWh): {q1_kwh_eur:.2f} Eur/kWh\")\n",
    "    print(f\"75th percentile (Q3, kWh): {q3_kwh_eur:.2f} Eur/kWh\")\n",
    "\n",
    "    return data_energy, q1_kwh_eur, q2_kwh_eur, q3_kwh_eur\n",
    "\n",
    "\n",
    "def calculate_travel_distance(warehouses_gdf, customers_gdf):\n",
    "    # Create an empty list to store the results\n",
    "    data = []\n",
    "    # Iterate through each warehouse in the warehouse DataFrame\n",
    "    for warehouse_index, warehouse in warehouses_gdf.iterrows():\n",
    "        for customer_index, customer in customers_gdf.iterrows():\n",
    "            # Calculate the distance between the centroid of the region and the warehouse\n",
    "            travel_distance = warehouse.geometry.distance(customer.geometry.centroid)/1000\n",
    "            # Append the calculated values to the list\n",
    "            data.append({'warehouse_id': warehouse_index, 'region_id': customer_index, 'travel_distance': travel_distance})\n",
    "    # Create a DataFrame from the collected data\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_data(customers_gdf, folder, city):\n",
    "    \n",
    "    # Grenzen des Simulationsrahmens laden\n",
    "    geo_würzburg = gpd.read_file(f'./{folder}/geo_{city}.gpkg')\n",
    "\n",
    "    # Detaillierte Gebäude/Personen Daten laden\n",
    "    bevölkerungs_gdf = gpd.read_file(f'./{folder}/pharmacy_assigned_complete.gpkg')\n",
    "    bevölkerungs_gdf['Alter'] = bevölkerungs_gdf['Alter'].apply(json.loads)\n",
    "    bevölkerungs_gdf['Geschlecht'] = bevölkerungs_gdf['Geschlecht'].apply(json.loads)\n",
    "\n",
    "    # Apotheken Daten laden\n",
    "    pharmacy_df = pd.read_csv(f'./{folder}/{city}-Apotheken.csv')\n",
    "    pharmacy_gdf = gpd.GeoDataFrame(pharmacy_df, geometry=gpd.points_from_xy(pharmacy_df['lon'], pharmacy_df['lat']), crs=CRS(\"EPSG:4326\"))\n",
    "    pharmacy_gdf = pharmacy_gdf.to_crs(bevölkerungs_gdf.crs)\n",
    "\n",
    "    # Warehouse Daten laden\n",
    "    warehouses_gdf = gpd.read_file(f'./{folder}/warehouses_{city}.gpkg')\n",
    "\n",
    "    # Distanzmatrix der Cluster und Warehouses erstellen\n",
    "    shifts_df = calculate_travel_distance(warehouses_gdf, customers_gdf)\n",
    "    shifts_df.set_index(['warehouse_id', 'region_id'], inplace=True)\n",
    "\n",
    "    return geo_würzburg, bevölkerungs_gdf, pharmacy_gdf, warehouses_gdf, shifts_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rahmen der Grafik definieren\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "geo_würzburg.boundary.plot(ax=ax, color='gray', linewidth=0.5)\n",
    "\n",
    "# Plotte gdf_loaded auf dieselbe Achse\n",
    "pharmacy_gdf.plot(ax=ax, markersize=20)\n",
    "\n",
    "# Titel hinzufügen\n",
    "plt.title('Apothekenstandorte im Landkreis Würzburg')\n",
    "plt.axis('off')\n",
    "\n",
    "# Add scale bar\n",
    "scalebar = ScaleBar(1, location='lower left', label='Maßstab')\n",
    "ax.add_artist(scalebar)\n",
    "\n",
    "# Zeige den Plot an\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a colormap based on the \"nachfrage\" column\n",
    "vmin = customers_gdf['nachfrage'].min()\n",
    "vmax = customers_gdf['nachfrage'].max()\n",
    "cmap = 'coolwarm'  \n",
    "\n",
    "# Plot the raster with boundary\n",
    "ax = geo_würzburg.boundary.plot(color='gray', linewidth=0.5, figsize = (5,5))\n",
    "\n",
    "# Plot the customers with custom colormap\n",
    "customers_gdf.plot(ax=ax, column='nachfrage', cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "\n",
    "# Add title and labels\n",
    "plt.axis('off')\n",
    "plt.title('Nachfrage der Cluster des Landkreis Würzburg')\n",
    "#plt.xlabel('Breitengradkoordinate im CSR3035 Format')\n",
    "#plt.ylabel('Längengradkoordinate im CSR3035 Format')\n",
    "\n",
    "# Add colorbar\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "sm._A = []  # Fake up the array of the scalar mappable\n",
    "cbar = plt.colorbar(sm, ax=ax, shrink=0.5, label='Nachfrage')  # Adjust shrink value as needed\n",
    "\n",
    "# Add scale bar\n",
    "scalebar = ScaleBar(1, location='lower left', label='Maßstab')  # 1 pixel = 1 meter\n",
    "ax.add_artist(scalebar)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a colormap based on the \"total_price\" column\n",
    "vmin = warehouses_gdf['total_price_big'].min()\n",
    "vmax = warehouses_gdf['total_price_big'].max()\n",
    "cmap = 'coolwarm'  \n",
    "\n",
    "\n",
    "# Rahmen der Grafik definieren\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "geo_würzburg.boundary.plot(ax=ax, color='gray', linewidth=0.5)\n",
    "\n",
    "# Plotte gdf_loaded auf dieselbe Achse\n",
    "warehouses_gdf.plot(ax=ax, column='total_price_big', cmap=cmap, markersize=20)\n",
    "\n",
    "# Titel hinzufügen\n",
    "plt.title('Lagerhaltungsimmobilien (Max) des Landkreis Würzburg')\n",
    "plt.axis('off')\n",
    "\n",
    "# Add colorbar\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "sm._A = []  # Fake up the array of the scalar mappable\n",
    "cbar = plt.colorbar(sm, ax=ax, shrink=0.5, label='Gesamter Mietpreis für ein Jahr')  # Adjust shrink value as needed\n",
    "\n",
    "# Add scale bar\n",
    "scalebar = ScaleBar(1, location='lower left', label='Maßstab')\n",
    "ax.add_artist(scalebar)\n",
    "\n",
    "# Zeige den Plot an\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a colormap based on the \"total_price\" column\n",
    "vmin = warehouses_gdf['total_price_small'].min()\n",
    "vmax = warehouses_gdf['total_price_small'].max()\n",
    "cmap = 'coolwarm'  \n",
    "\n",
    "\n",
    "# Rahmen der Grafik definieren\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "geo_würzburg.boundary.plot(ax=ax, color='gray', linewidth=0.5)\n",
    "\n",
    "# Plotte gdf_loaded auf dieselbe Achse\n",
    "warehouses_gdf.plot(ax=ax, column='total_price_small', cmap=cmap, markersize=20)\n",
    "\n",
    "# Titel hinzufügen\n",
    "plt.title('Lagerhaltungsimmobilien (Min) des Landkreis Würzburg')\n",
    "plt.axis('off')\n",
    "\n",
    "# Add colorbar\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "sm._A = []  # Fake up the array of the scalar mappable\n",
    "cbar = plt.colorbar(sm, ax=ax, shrink=0.5, label='Gesamter Mietpreis für ein Jahr')  # Adjust shrink value as needed\n",
    "\n",
    "# Add scale bar\n",
    "scalebar = ScaleBar(1, location='lower left', label='Maßstab')\n",
    "ax.add_artist(scalebar)\n",
    "\n",
    "# Zeige den Plot an\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert JSON data to pandas DataFrame\n",
    "df_energy = pd.DataFrame(data_energy[\"data\"])\n",
    "\n",
    "# Convert timestamps to datetime format\n",
    "df_energy[\"start_timestamp\"] = pd.to_datetime(df_energy[\"start_timestamp\"], unit=\"ms\")\n",
    "df_energy[\"end_timestamp\"] = pd.to_datetime(df_energy[\"end_timestamp\"], unit=\"ms\")\n",
    "\n",
    "# Filter data for values greater than 0\n",
    "df_filtered = df_energy[df_energy[\"marketprice\"] > 0]\n",
    "\n",
    "# Plot market price vs timestamps (using filtered data)\n",
    "plt.figure(figsize=(12, 6))  # Adjust figure size as needed\n",
    "plt.plot(df_filtered[\"start_timestamp\"], df_filtered[\"marketprice\"], label=\"Market Price (Eur/MWh)\")\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Market Price (Eur/MWh)\")\n",
    "plt.title(\"Market Price Fluctuations (Values > 0)\")  # Update title\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Set y-axis limits to start from 0 (optional)\n",
    "plt.ylim(bottom=0)  # This ensures the y-axis starts at 0\n",
    "\n",
    "# Add gridlines\n",
    "plt.grid(True)\n",
    "\n",
    "# Show legend\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimierungsmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(W,\n",
    "             R,\n",
    "             S,\n",
    "             warehouses_gdf_run,\n",
    "             cost_per_km_drone,\n",
    "             factory_fix_costs,\n",
    "             factory_variable_costs,\n",
    "             factory_operating_costs, \n",
    "             qm_per_customer, \n",
    "             rent_factor, \n",
    "             max_flight_distance, \n",
    "             drone_initial_costs, \n",
    "             drone_speed, \n",
    "             time_window, \n",
    "             night_shift_dist, \n",
    "             delivery_time,\n",
    "             alpha_drones,\n",
    "             customers_gdf_opt):\n",
    "    \n",
    "    # Create a solver\n",
    "    solver = pywraplp.Solver.CreateSolver('GUROBI')\n",
    "\n",
    "    # Define decision variables\n",
    "    # Which warehouse serves which region\n",
    "    x = {}\n",
    "    for w, r in S:\n",
    "        x[w,r] = solver.BoolVar(name=f'x_{w}_{r}')\n",
    "\n",
    "    # Which warehouses are opened\n",
    "    y = {}\n",
    "    # How many drones are needed in each warehouse\n",
    "    z = {}\n",
    "    # How much space is rented in each warehouse\n",
    "    d = {}\n",
    "    for w in W:\n",
    "        y[w] = solver.BoolVar(name=f'y_{w}')\n",
    "        z[w] = solver.IntVar(0, solver.infinity(), name=f'z_{w}')\n",
    "        d[w] = solver.IntVar(0, solver.infinity(), name=f'd_{w}')\n",
    "        \n",
    "    # Objective Function\n",
    "    objective = solver.Objective()\n",
    "    \n",
    "    \n",
    "    # Fixed costs for opening warehouses\n",
    "    for w in W:\n",
    "        objective.SetCoefficient(y[w], factory_fix_costs)  # Add fixed factory setup costs\n",
    "        objective.SetCoefficient(d[w], factory_variable_costs)  # Add variable factory setup costs\n",
    "        objective.SetCoefficient(d[w], factory_operating_costs * warehouses_gdf_run.loc[w, 'pricePerSquareMetre'] * 12 * rent_factor)  # Add factory operating costs\n",
    "        objective.SetCoefficient(d[w], warehouses_gdf_run.loc[w, 'pricePerSquareMetre'] * 12 * rent_factor)  # Cost per square meter\n",
    "\n",
    "        \n",
    "    # Costs for acquiring drones\n",
    "    for w in W:\n",
    "        objective.SetCoefficient(z[w], drone_initial_costs / 5)\n",
    "    \n",
    "    # Variable costs for transportation\n",
    "    for w, r in S:\n",
    "        objective.SetCoefficient(x[w,r], cost_per_km_drone * shifts_df.loc[w,r].travel_distance * 2 * customers_gdf_opt.loc[r, 'nachfrage'])\n",
    "\n",
    "    objective.SetMinimization()\n",
    "    \n",
    "    # Constraints\n",
    "    # Regions can only be served by open warehouses\n",
    "    for w in W:\n",
    "        for r in R:\n",
    "            solver.Add(x[w,r] <= y[w])\n",
    "\n",
    "    # Each region has to be served by exactly one warehouse\n",
    "    for r in R:\n",
    "        solver.Add(solver.Sum(x[w,r] for w in W) == 1)\n",
    "\n",
    "    # Each warehouse needs to be assigned with a certain amount of drones\n",
    "    # Definiere das Zeitfenster für die Erfüllung des Demands (in Minuten)\n",
    "    # Berechne den täglichen Demand Faktor\n",
    "    daily_demand_factor = (1 - night_shift_dist) / 365\n",
    "\n",
    "    for w in W:\n",
    "        # Initialisiere den Ausdruck für die gesamte Reisezeit\n",
    "        total_time = solver.Sum(\n",
    "            x[w, r] * shifts_df.loc[w, r].travel_distance * 2 * \n",
    "            (customers_gdf_opt.loc[r, 'nachfrage'] * daily_demand_factor / drone_speed)\n",
    "            for r in R\n",
    "        ) / time_window\n",
    "\n",
    "        # Berechne die maximale Anzahl an Drones, die benötigt werden, um parallele oder überlappende Demands zu erfüllen\n",
    "        max_drones_needed = solver.Sum(\n",
    "            x[w, r] * shifts_df.loc[w, r].travel_distance * 2 * \n",
    "            (customers_gdf_opt.loc[r, 'nachfrage'] * daily_demand_factor / drone_speed)\n",
    "            for r in R\n",
    "        ) / delivery_time\n",
    "\n",
    "        # Berücksichtige eine gewichtete Summe, um beiden Szenarien gerecht zu werden\n",
    "        combined_drones_needed = total_time + alpha_drones * (max_drones_needed - total_time)\n",
    "\n",
    "        # Füge die erweiterte Constraint hinzu\n",
    "        solver.Add(combined_drones_needed <= z[w])\n",
    "\n",
    "\n",
    "    # Each warehouse is assigned a certain amound of space that is between the boundries of the offering\n",
    "    for w in W:\n",
    "        solver.Add(y[w] * warehouses_gdf_run.loc[w, 'floorSpace_small'] <= d[w])\n",
    "        solver.Add(y[w] * warehouses_gdf_run.loc[w, 'floorSpace_big'] >= d[w])\n",
    "        \n",
    "    # The distance from warehouse to customer can't be taller than the maximum flight range of each drone\n",
    "    for w in W:\n",
    "        for r in R:\n",
    "            solver.Add(x[w,r] * shifts_df.loc[w,r].travel_distance <= max_flight_distance)\n",
    "\n",
    "    # Each warehouse needs a certain amount of space for each customer served\n",
    "    for w in W:\n",
    "        customer_demand_sum = solver.Sum(x[w, r] * (customers_gdf_opt.loc[r, 'nachfrage'] / 365) for r in R)\n",
    "        required_space_for_customers = customer_demand_sum * qm_per_customer\n",
    "        solver.Add(d[w] >= required_space_for_customers)\n",
    "\n",
    "    return solver, x, y, z, d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lösungsausgabe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(W, R, solver, x, y, z, d, customers_gdf_run, warehouses_gdf_run):\n",
    "  opened_warehouses = []\n",
    "  customers_gdf_run['assigned_warehouse'] = 0\n",
    "  warehouses_gdf_run['number_of_drones'] = 0\n",
    "  warehouses_gdf_run['floor_space_assigned'] = 0\n",
    "\n",
    "  #Solving the problem\n",
    "  status = solver.Solve()\n",
    "  print('Solved!')\n",
    "\n",
    "  def print_solution(status, solver, opened_warehouses, x, y, z, d, W, R):\n",
    "\n",
    "    if status == pywraplp.Solver.OPTIMAL:\n",
    "      print(\"Objective value:\", solver.Objective().Value())\n",
    "      #print(\"Opened warehouses:\")\n",
    "      opened_warehouses.clear()  # Clear the list before appending\n",
    "      for w in W:\n",
    "        if y[w].solution_value() > 0.5:\n",
    "          opened_warehouses.append(w)\n",
    "          warehouses_gdf_run.loc[w, 'number_of_drones'] = z[w].solution_value()\n",
    "          warehouses_gdf_run.loc[w, 'floor_space_assigned'] = d[w].solution_value()\n",
    "          #print(f\"- Warehouse {w}\")\n",
    "          #print(f\"Floor-Space: {d[w].solution_value()}\")\n",
    "          #print(f\"Drones needed: {z[w].solution_value()}\")\n",
    "      #print(\"Warehouse assignments:\")\n",
    "      for r in R:\n",
    "        assigned_warehouse = None\n",
    "        for w in W:\n",
    "          if x[w, r].solution_value() > 0.5:\n",
    "            assigned_warehouse = w\n",
    "            break\n",
    "        if assigned_warehouse is not None:\n",
    "          customers_gdf_run.loc[r, 'assigned_warehouse'] = assigned_warehouse\n",
    "          #print(f\"- Region {r} served by warehouse {assigned_warehouse}\")\n",
    "          #distance = shifts_df.loc[assigned_warehouse, r].travel_distance\n",
    "          #print(f\"- Distance: {distance}\")\n",
    "        else:\n",
    "          print(f\"- Region {r} has no assigned warehouse (might be infeasible)\")\n",
    "    else:\n",
    "      print(\"Solver failed to find an optimal solution. Status:\", status)\n",
    "\n",
    "\n",
    "  print_solution(status, solver, opened_warehouses, x, y, z, d, W, R)\n",
    "  print(f'Opened Warehouses: {opened_warehouses}')\n",
    "  \n",
    "  return opened_warehouses, customers_gdf_run, warehouses_gdf_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution Graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rahmen der Grafik definieren\n",
    "ax = geo_würzburg.boundary.plot(color='gray', linewidth=0.5, figsize = (7,7))\n",
    "\n",
    "# Plotte gdf_loaded auf dieselbe Achse\n",
    "warehouses_gdf[~warehouses_gdf.index.isin(opened_warehouses)].plot(ax=ax, color='red', marker='o', markersize=25)\n",
    "warehouses_gdf.loc[opened_warehouses].plot(ax=ax, color='blue', marker='^', markersize=35)\n",
    "\n",
    "# Titel hinzufügen\n",
    "plt.title('Lagerhaltungsimmobilien des Landkreis Würzburg')\n",
    "\n",
    "plt.axis('off')\n",
    "\n",
    "# Add scale bar\n",
    "scalebar = ScaleBar(1, location='lower left', label='Maßstab')\n",
    "ax.add_artist(scalebar)\n",
    "\n",
    "# Add legend\n",
    "custom_legend = [Line2D([0], [0], marker='^', color='w', markerfacecolor='blue', markersize=10, label='Geöffnet'),\n",
    "                 Line2D([0], [0], marker='o', color='w', markerfacecolor='red', markersize=10, label='Nicht geöffnet')]\n",
    "plt.legend(handles=custom_legend, title='Warenhäuser', bbox_to_anchor=(1,0.95), loc='upper left', borderaxespad=0., fontsize='small', ncol=1)\n",
    "plt.tight_layout()\n",
    "\n",
    "# # Index jedes Warehouses anzeigen\n",
    "# for idx, row in warehouses_gdf.loc[opened_warehouses].iterrows():\n",
    "#     plt.annotate(idx, (row.geometry.x, row.geometry.y), xytext=(5, 5), textcoords='offset points', fontsize=8, color='black')\n",
    "\n",
    "# for idx, row in warehouses_gdf[~warehouses_gdf.index.isin(opened_warehouses)].iterrows():\n",
    "#     plt.annotate(idx, (row.geometry.x, row.geometry.y), xytext=(5, 5), textcoords='offset points', fontsize=8, color='black')\n",
    "\n",
    "# Zeige den Plot an\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a colormap with a color for each opened warehouse\n",
    "colors = plt.cm.tab20(np.linspace(0, 1, len(opened_warehouses)))\n",
    "warehouse_colors = dict(zip(opened_warehouses, colors))\n",
    "\n",
    "# Create a dictionary to map each warehouse to a color\n",
    "warehouse_colors = {\n",
    "    warehouse: color\n",
    "    for warehouse, color in zip(opened_warehouses, warehouse_colors.values())\n",
    "}\n",
    "\n",
    "# Plot the boundaries of the region\n",
    "ax = geo_würzburg.boundary.plot(color='gray', linewidth=0.5, figsize=(8, 8))\n",
    "\n",
    "\n",
    "# Plot the customers with the color of their assigned warehouse\n",
    "for index, row in customers_gdf.iterrows():\n",
    "    warehouse = row['assigned_warehouse']\n",
    "    color = warehouse_colors.get(warehouse, 'gray')  # Use gray color if warehouse is not in the dictionary\n",
    "    customers_gdf.iloc[[index]].plot(ax=ax, color=color, markersize=20)\n",
    "\n",
    "\n",
    "# Plot the warehouses with their assigned colors\n",
    "for warehouse, color in warehouse_colors.items():\n",
    "    warehouses_gdf[warehouses_gdf.index == warehouse].plot(ax=ax, color=color, marker='^', markersize=50, edgecolor='black')\n",
    "\n",
    "\n",
    "# Turn off axis\n",
    "plt.axis('off')\n",
    "\n",
    "# Add title\n",
    "plt.title('Lagerhaltungsimmobilien des Landkreis Würzburg')\n",
    "\n",
    "# Add legend\n",
    "legend_handles = [Line2D([0], [0], marker='^', color='w', markerfacecolor=color, markersize=10, label=warehouse) for warehouse, color in warehouse_colors.items()]\n",
    "ax.legend(handles=legend_handles, title='Warenhäuser', bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0., fontsize='small', ncol=2)\n",
    "\n",
    "# Add scale bar\n",
    "scalebar = ScaleBar(1, location='lower left', label='Maßstab')\n",
    "ax.add_artist(scalebar)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning a warehouse to each building based on the optimal value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion, um das zugewiesene Lager für einen Punkt zu finden\n",
    "def find_assigned_warehouse(point, customers_gdf_run, cluster_sindex):\n",
    "    # Räumlichen Index für das Cluster-GDF erstellen\n",
    "    possible_matches_index = list(cluster_sindex.intersection(point.bounds))\n",
    "    possible_matches = customers_gdf_run.iloc[possible_matches_index]\n",
    "    output = possible_matches[possible_matches.geometry.contains(point)]\n",
    "    if not output.empty:\n",
    "        return [output.assigned_warehouse.iloc[0]]\n",
    "    else:\n",
    "        nearest_polygon_index = cluster_sindex.nearest(point)[0]\n",
    "        nearest_polygon = customers_gdf_run.iloc[nearest_polygon_index]\n",
    "        return [nearest_polygon.assigned_warehouse.iloc[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_warehouses(bevölkerungs_gdf_run, customers_gdf_run, warehouses_gdf_run):\n",
    "    # Verfolgen Sie den Fortschritt der apply-Methode\n",
    "    tqdm.pandas()\n",
    "    \n",
    "    cluster_sindex = customers_gdf_run.sindex\n",
    "\n",
    "    # Die apply-Methode auf die GeoDataFrame anwenden, um das zugewiesene Lager für jeden Punkt zu finden\n",
    "    warehouses = bevölkerungs_gdf_run['geometry'].progress_apply(find_assigned_warehouse, customers_gdf_run = customers_gdf_run, cluster_sindex = cluster_sindex)\n",
    "\n",
    "    bevölkerungs_gdf_run['assigned_warehouse'] = 0\n",
    "    bevölkerungs_gdf_run['distance_warehouse'] = 0.0\n",
    "\n",
    "    for index, row in tqdm(bevölkerungs_gdf_run.iterrows(), total=len(bevölkerungs_gdf_run)):\n",
    "        bevölkerungs_gdf_run.loc[index, 'assigned_warehouse'] = warehouses[index][0]\n",
    "        warehouse_geometry = warehouses_gdf_run.loc[row['assigned_warehouse'], 'geometry']\n",
    "        population_geometry = row['geometry']\n",
    "        bevölkerungs_gdf_run.loc[index, 'distance_warehouse'] = warehouse_geometry.distance(population_geometry) / 1000\n",
    "\n",
    "    return bevölkerungs_gdf_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulations LoopFunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_demand_sim(row, demand_factor):\n",
    "    \n",
    "    probabilities = {\n",
    "        '0-10': 0,\n",
    "        '10-20': 0.003458068783068975,\n",
    "        '20-30': 0.013896825396825975,\n",
    "        '30-40': 0.02136825396825512,\n",
    "        '40-50': 0.02338333333333506,\n",
    "        '50-60': 0.026277248677250214,\n",
    "        '60-70': 0.03332089947090043,\n",
    "        '70-80': 0.046515343915346036,\n",
    "        '80+': 0.046515343915346036,\n",
    "    }\n",
    "    \n",
    "    total_demand = 0\n",
    "    for age_group, count in row['Alter'].items():\n",
    "        lambda_value = count * probabilities[age_group]\n",
    "        total_demand += poisson.rvs(lambda_value)\n",
    "    return int(total_demand * demand_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_random_timestamp(row, night_shift_dist, start_time, end_time):\n",
    "    timestamp_list = []\n",
    "    for i in range(row['nachfrage']): \n",
    "        probabilities_timestamp = [1 - night_shift_dist, night_shift_dist]  # Wahrscheinlichkeit für innerhalb und außerhalb der Öffnungszeiten\n",
    "\n",
    "        start_hour = start_time.hour\n",
    "        start_minute = start_time.minute\n",
    "        end_hour = end_time.hour\n",
    "        end_minute = end_time.minute\n",
    "\n",
    "        if np.random.choice([False, True], p=probabilities_timestamp):\n",
    "            # Außerhalb der Öffnungszeiten\n",
    "            if random.choice([True, False]):\n",
    "                # Vor den Öffnungszeiten\n",
    "                hour = random.randint(0, start_hour - 1)\n",
    "                minute = random.randint(0, 59)\n",
    "                second = random.randint(0, 59)\n",
    "            else:\n",
    "                # Nach den Öffnungszeiten\n",
    "                hour = random.randint(end_hour + 1, 23)\n",
    "                minute = random.randint(0, 59)\n",
    "                second = random.randint(0, 59)\n",
    "        else:\n",
    "            # Innerhalb der Öffnungszeiten\n",
    "            if start_hour == end_hour:\n",
    "                hour = start_hour\n",
    "                minute = random.randint(start_minute, end_minute)\n",
    "            else:\n",
    "                hour = random.randint(start_hour, end_hour)\n",
    "                if hour == start_hour:\n",
    "                    minute = random.randint(start_minute, 59)\n",
    "                elif hour == end_hour:\n",
    "                    minute = random.randint(0, end_minute)\n",
    "                else:\n",
    "                    minute = random.randint(0, 59)\n",
    "            second = random.randint(0, 59)\n",
    "        \n",
    "        timestamp = datetime.combine(datetime.today(), datetime.min.time()) + timedelta(hours=hour, minutes=minute, seconds=second)\n",
    "        timestamp_list.append(timestamp)\n",
    "    return timestamp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_penalty_costs(bevoelkerungs_gdf_sim, warehouses_gdf_sim, drone_speed, time_window, opening_start_time, opening_end_time):\n",
    "    # Convert time_window to a timedelta object\n",
    "    time_window = timedelta(minutes=time_window)\n",
    "    \n",
    "    # Initialize a dictionary to keep track of next available times for drones in each warehouse\n",
    "    warehouse_drones = {warehouse: [opening_start_time] * warehouses_gdf_sim.loc[warehouse, 'number_of_drones'] for warehouse in warehouses_gdf_sim.index}\n",
    "    \n",
    "    total_exceeded_minutes = 0\n",
    "\n",
    "    # Flatten the demand timestamps and associate them with their warehouses and distances\n",
    "    all_demands = []\n",
    "    for index, row in bevoelkerungs_gdf_sim.iterrows():\n",
    "        assigned_warehouse = row['assigned_warehouse']\n",
    "        distance_warehouse = row['distance_warehouse']\n",
    "        for timestamp in row['demand_timestamp']:\n",
    "            all_demands.append((assigned_warehouse, distance_warehouse, timestamp))\n",
    "    \n",
    "    # Sort all demands by timestamp\n",
    "    all_demands.sort(key=lambda x: x[2])\n",
    "    \n",
    "    def time_to_minutes(t):\n",
    "        \"\"\"Convert a time object to minutes since midnight.\"\"\"\n",
    "        return t.hour * 60 + t.minute\n",
    "    \n",
    "    def minutes_to_time(m):\n",
    "        \"\"\"Convert minutes since midnight to a time object.\"\"\"\n",
    "        return time(int(m // 60), int(m % 60))\n",
    "    \n",
    "    opening_start_minutes = time_to_minutes(opening_start_time)\n",
    "    opening_end_minutes = time_to_minutes(opening_end_time)\n",
    "    \n",
    "    # Process each demand\n",
    "    for assigned_warehouse, distance_warehouse, timestamp in all_demands:\n",
    "        \n",
    "        # Find the first available drone\n",
    "        available_drones = warehouse_drones[assigned_warehouse]\n",
    "        next_available_time = min(available_drones, key=time_to_minutes)\n",
    "        start_time = max(time_to_minutes(timestamp), time_to_minutes(next_available_time))  # Use start_time to calculate when the drone can actually start\n",
    "        \n",
    "        # Ensure start time is within opening hours\n",
    "        if start_time < opening_start_minutes:\n",
    "            start_time = opening_start_minutes\n",
    "        elif start_time > opening_end_minutes:\n",
    "            continue  # Skip demands outside of opening hours\n",
    "\n",
    "        # Calculate the delivery time\n",
    "        delivery_time = start_time + int((2 * distance_warehouse) / (drone_speed))  # Round trip time in minutes\n",
    "        \n",
    "        # Ensure delivery time is within opening hours\n",
    "        if delivery_time > opening_end_minutes:\n",
    "            continue  # Skip deliveries that cannot be completed within opening hours\n",
    "\n",
    "        # Check if the delivery time exceeds the time window\n",
    "        if (delivery_time - time_to_minutes(timestamp)) > time_window.total_seconds() / 60:\n",
    "            exceeded_minutes = (delivery_time - time_to_minutes(timestamp)) - (time_window.total_seconds() / 60)\n",
    "            total_exceeded_minutes += exceeded_minutes\n",
    "\n",
    "        # Update the next available time for the drone\n",
    "        return_trip_end_time = minutes_to_time(delivery_time)\n",
    "        available_drones[available_drones.index(next_available_time)] = return_trip_end_time\n",
    "\n",
    "    return total_exceeded_minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_trip_request_string(pharmacy_lon, pharmacy_lat, demands):\n",
    "    waypoints = f\"{pharmacy_lon},{pharmacy_lat}\"\n",
    "    for _, row in demands.iterrows():\n",
    "        waypoints += f\";{row.lon},{row.lat}\"\n",
    "    return f\"http://router.project-osrm.org/trip/v1/driving/{waypoints}?roundtrip=true&source=first&destination=last&overview=false&steps=false\"\n",
    "\n",
    "def calculate_total_distance_and_duration(demands, pharmacy_lon, pharmacy_lat, total_distance_sum, total_duration_sum, counter):\n",
    "    try:\n",
    "        request_string = build_trip_request_string(pharmacy_lon, pharmacy_lat, demands)\n",
    "        res = requests.get(request_string)\n",
    "        res.raise_for_status()  # Raise an exception for non-200 status codes\n",
    "\n",
    "        content = json.loads(res.content)\n",
    "\n",
    "        # Check if trips are available\n",
    "        if 'trips' in content and len(content['trips']) > 0:\n",
    "            trip = content['trips'][0]\n",
    "            total_distance = trip['distance']\n",
    "            total_duration = trip['duration']\n",
    "            return total_distance, total_duration\n",
    "        else:\n",
    "            #print(f\"No trips found for request {request_string}\")\n",
    "            return total_distance_sum/counter, total_duration_sum/counter\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        #print(f\"Error occurred on attempt for request {request_string}: {e}\")\n",
    "        return total_distance_sum/counter, total_duration_sum/counter\n",
    "\n",
    "def expand_timestamps(demands_df):\n",
    "    # Explode the DataFrame by demand_timestamp\n",
    "    demands_df = demands_df.explode('demand_timestamp')\n",
    "    demands_df['demand_timestamp'] = pd.to_datetime(demands_df['demand_timestamp'])\n",
    "    return demands_df\n",
    "\n",
    "def calculate_pharmacy_routing(demands_df, pharmacies_df):\n",
    "    # Expand the demands DataFrame so each timestamp is in its own row\n",
    "    demands_df = expand_timestamps(demands_df)\n",
    "\n",
    "    # Split demands into two DataFrames by half, grouped by assigned pharmacy\n",
    "    demands_df_groups = demands_df.groupby('assigned_pharmacy')\n",
    "    groups_list = list(demands_df_groups)\n",
    "    split_index = len(groups_list) // 2\n",
    "\n",
    "    # Split the DataFrame into two DataFrames\n",
    "    first_half_demands = pd.concat([group[1] for group in groups_list[:split_index]])\n",
    "    second_half_demands = pd.concat([group[1] for group in groups_list[split_index:]])\n",
    "    \n",
    "\n",
    "    # Group by assigned pharmacy and filter demands by time\n",
    "    before_13pm = first_half_demands[first_half_demands['demand_timestamp'].dt.hour < 13].drop_duplicates(subset=['lon', 'lat'])\n",
    "    after_13pm = first_half_demands[first_half_demands['demand_timestamp'].dt.hour >= 13].drop_duplicates(subset=['lon', 'lat'])\n",
    "\n",
    "    total_distance_sum = 0\n",
    "    total_duration_sum = 0\n",
    "    counter = 1\n",
    "\n",
    "    # Vectorized processing within each time period\n",
    "    for time_period, demands in [('before_13pm', before_13pm), ('after_13pm', after_13pm)]:\n",
    "        if demands.empty:\n",
    "            continue\n",
    "\n",
    "        grouped = demands.groupby('assigned_pharmacy')\n",
    "\n",
    "        for pharmacy_id, group in grouped:\n",
    "            pharmacy_info = pharmacies_df[pharmacies_df['id'] == pharmacy_id]\n",
    "\n",
    "            if pharmacy_info.empty:\n",
    "                print(f\"Pharmacy ID {pharmacy_id} not found in pharmacies dataframe.\")\n",
    "                continue\n",
    "\n",
    "            pharmacy_lon = pharmacy_info.lon.iloc[0]\n",
    "            pharmacy_lat = pharmacy_info.lat.iloc[0]\n",
    "\n",
    "            total_distance, total_duration = calculate_total_distance_and_duration(group, pharmacy_lon, pharmacy_lat, total_distance_sum, total_duration_sum, counter)\n",
    "            total_distance_sum += total_distance\n",
    "            total_duration_sum += total_duration\n",
    "            counter += 1\n",
    "            \n",
    "\n",
    "    \n",
    "    second_half_demands = second_half_demands.groupby('assigned_pharmacy')\n",
    "    for pharmacy_id, group in second_half_demands:\n",
    "        pharmacy_info = pharmacies_df[pharmacies_df['id'] == pharmacy_id]\n",
    "\n",
    "        if pharmacy_info.empty:\n",
    "            print(f\"Pharmacy ID {pharmacy_id} not found in pharmacies dataframe.\")\n",
    "            continue\n",
    "\n",
    "        pharmacy_lon = pharmacy_info.lon.iloc[0]\n",
    "        pharmacy_lat = pharmacy_info.lat.iloc[0]\n",
    "\n",
    "        total_distance, total_duration = calculate_total_distance_and_duration(group, pharmacy_lon, pharmacy_lat, total_distance_sum, total_duration_sum, counter)\n",
    "        total_distance_sum += total_distance\n",
    "        total_duration_sum += total_duration\n",
    "        counter += 1\n",
    "\n",
    "    return total_distance_sum / 1000, total_duration_sum / 60 #Meters to km, seconds to minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(opened_warehouses_run, bevölkerungs_gdf_run, warehouses_gdf_run, cost_per_km_drone, drone_speed, delivery_time, start_time, end_time, demand_factor, rent_factor, night_shift_dist, cost_per_km_car, cost_per_km_truck, factory_fix_costs, factory_variable_costs, factory_operating_costs, drone_initial_costs, sensitivity_run):\n",
    "\n",
    "    #Calculate the monthly fix costs due to drone and factory setup\n",
    "    rental_cost = (np.sum(warehouses_gdf_run.loc[opened_warehouses_run].floor_space_assigned * warehouses_gdf_run.loc[opened_warehouses_run].pricePerSquareMetre)) * rent_factor\n",
    "    factory_fix_monthly = (len(opened_warehouses_run) * factory_fix_costs) / 12\n",
    "    factory_variable_monthly = np.sum(warehouses_gdf_run.loc[opened_warehouses_run].floor_space_assigned * factory_variable_costs) / 12\n",
    "    factory_operating_monthly = np.sum(warehouses_gdf_run.loc[opened_warehouses_run].floor_space_assigned * warehouses_gdf_run.loc[opened_warehouses_run].pricePerSquareMetre * factory_operating_costs)\n",
    "    drone_setup_cost = ((np.sum(warehouses_gdf_run.loc[opened_warehouses_run].number_of_drones) * drone_initial_costs) / 12) / 5\n",
    "\n",
    "    drone_transportation_cost = 0\n",
    "    drone_transportation_time = 0\n",
    "    time_penalty_costs = 0\n",
    "    time_penalty_day = 0\n",
    "    avg_waiting_time = 0\n",
    "\n",
    "    car_transportation_cost_customer = 0\n",
    "    car_transportation_time_customer = 0\n",
    "\n",
    "    car_transportation_cost_pharmacy = 0\n",
    "    car_transportation_time_pharmacy = 0\n",
    "\n",
    "\n",
    "    tqdm.pandas()\n",
    "\n",
    "    #Loop der Simulation über ein gesamtes Jahr\n",
    "    for i in range(30):\n",
    "\n",
    "        print(f'Simulation - Tag: {i + 1}')\n",
    "        \n",
    "        bevölkerungs_gdf_run['nachfrage'] = bevölkerungs_gdf_run.progress_apply(calculate_demand_sim, axis=1, demand_factor = demand_factor)\n",
    "        bevölkerungs_gdf_run['demand_timestamp'] = bevölkerungs_gdf_run.progress_apply(lambda row: assign_random_timestamp(row, night_shift_dist, start_time, end_time), axis=1)\n",
    "\n",
    "        # Calculate transportation costs and time using vectorized operations\n",
    "        drone_transportation_cost += np.sum(bevölkerungs_gdf_run['nachfrage'] * bevölkerungs_gdf_run['distance_warehouse'] * cost_per_km_drone * 2)\n",
    "        drone_transportation_time += np.sum((bevölkerungs_gdf_run['nachfrage'] * bevölkerungs_gdf_run['distance_warehouse']) / drone_speed )\n",
    "        time_penalty_day = calculate_penalty_costs(bevölkerungs_gdf_run, warehouses_gdf_run, drone_speed, delivery_time, start_time, end_time)\n",
    "        time_penalty_costs += time_penalty_day\n",
    "        avg_waiting_time = (avg_waiting_time + time_penalty_day / np.sum(bevölkerungs_gdf_run['nachfrage'])) / (i+1)\n",
    "\n",
    "        if sensitivity_run:\n",
    "            car_transportation_cost_customer += np.sum(bevölkerungs_gdf_run['nachfrage'] * bevölkerungs_gdf_run['distance_pharmacy'] * cost_per_km_car * 2)\n",
    "            car_transportation_time_customer += np.sum(bevölkerungs_gdf_run['nachfrage'] * bevölkerungs_gdf_run['time_pharmacy'])\n",
    "\n",
    "            car_transportation_cost_pharmacy_temp, car_transportation_time_pharmacy_temp = calculate_pharmacy_routing(bevölkerungs_gdf_run[bevölkerungs_gdf_run['nachfrage'] > 0], pharmacy_gdf)\n",
    "            car_transportation_cost_pharmacy += car_transportation_cost_pharmacy_temp * cost_per_km_truck + bevölkerungs_gdf_run['distance_pharmacy'].median() * cost_per_km_truck\n",
    "            car_transportation_time_pharmacy += car_transportation_time_pharmacy_temp\n",
    "        \n",
    "        bevölkerungs_gdf_run.drop('nachfrage', axis=1, inplace=True)\n",
    "        bevölkerungs_gdf_run.drop('demand_timestamp', axis=1, inplace=True)\n",
    "\n",
    "    return [rental_cost, factory_fix_monthly, factory_variable_monthly, factory_operating_monthly ,drone_setup_cost, drone_transportation_cost, drone_transportation_time, time_penalty_costs, avg_waiting_time, car_transportation_cost_customer, car_transportation_time_customer, car_transportation_cost_pharmacy, car_transportation_time_pharmacy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cost_summary(costs):\n",
    "\n",
    "  print(\"-\" * 50)\n",
    "  print(\"Logistical Cost Summary (per year):\")\n",
    "  print(\"-\" * 50)\n",
    "  print(f\"Factory Rental Cost: \\t\\t\\t€{costs[0]:.2f}\")\n",
    "  print(f\"Factory Fix Cost: \\t\\t\\t€{costs[1]:.2f}\")\n",
    "  print(f\"Factory Variable Cost: \\t\\t\\t€{costs[2]:.2f}\")\n",
    "  print(f\"Factory Operating Cost: \\t\\t€{costs[3]:.2f}\")\n",
    "  print(f\"Drone Setup Cost: \\t\\t\\t€{costs[4]:.2f}\")\n",
    "  print(\"-\" * 50)\n",
    "  print(f\"Drone Transportation Cost: \\t\\t€{costs[5]:.2f}\")\n",
    "  print(f\"Drone Transportation Time: \\t\\t{costs[6]/60:.2f} hours\")\n",
    "  print(f\"Transportation Penalty Time: \\t\\t{costs[7]:.2f}\")\n",
    "  print(f\"Transportation Avg Waiting Time: \\t{costs[8]:.2f}\")\n",
    "  print(\"-\" * 50)\n",
    "  print(f\"Car/Truck Customer Transportation Cost: €{costs[9]:.2f}\")\n",
    "  print(f\"Car/Truck Customer Transportation Time: {costs[10]/60:.2f} hours\")\n",
    "  print(\"-\" * 50)\n",
    "  print(f\"Car/Truck Pharmacy Transportation Cost: €{costs[11]:.2f}\")\n",
    "  print(f\"Car/Truck Pharmacy Transportation Time: {costs[12]/60:.2f} hours\")\n",
    "  print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robustheit / Parameter Changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_times(minutes):\n",
    "  start_time = time(hour=8, minute=0) # Set initial start time to 8:00 AM\n",
    "  total_minutes = (start_time.hour * 60 + start_time.minute) + minutes # Convert minutes to total number of minutes\n",
    "  end_time = time(hour=total_minutes // 60 % 24, minute=total_minutes % 60)   # Calculate end time by handling overflow within 24 hours\n",
    "\n",
    "  # Adjust start time if end time is before start time (overflow)\n",
    "  if end_time < start_time:\n",
    "    # Calculate the adjustment needed (difference in minutes)\n",
    "    if start_time.minute > end_time.minute:\n",
    "      start_time = time(start_time.hour - end_time.hour, start_time.minute - end_time.minute)\n",
    "    else:\n",
    "      start_time = time(start_time.hour - end_time.hour -1, 60 - end_time.minute)\n",
    "    end_time = time(23,59,59)\n",
    "\n",
    "  return start_time, end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(parameter_values, bevölkerungs_gdf_run, warehouses_gdf_run, customers_gdf_run, shifts_df_run, optimal_run, city, opened_warehouses_optimal, sensitivity_run):\n",
    "\n",
    "    # Drone Parameters\n",
    "    cost_per_km_drone = (parameter_values['kwh_eur'] * parameter_values['watt_drone']) / (parameter_values['drone_speed'] * 60)  # EUR/km # Calculate cost per kilometer for the drone\n",
    "    # Car/Truck Parameters:\n",
    "    cost_per_km_car = 0.5\n",
    "    cost_per_km_truck = 2\n",
    "\n",
    "    W = warehouses_gdf_run.index.values\n",
    "    R = customers_gdf_run.index.values\n",
    "    S = shifts_df_run.index.values\n",
    "    \n",
    "    if optimal_run:\n",
    "        # Set the optimization problem\n",
    "        solver, x, y, z, d = optimize(\n",
    "            W = W, \n",
    "            R = R,\n",
    "            S = S, \n",
    "            warehouses_gdf_run = warehouses_gdf_run,\n",
    "            customers_gdf_opt = customers_gdf_run, \n",
    "            cost_per_km_drone = cost_per_km_drone,\n",
    "            factory_fix_costs = parameter_values['factory_fix_costs'],\n",
    "            factory_variable_costs = parameter_values['factory_variable_costs'],\n",
    "            factory_operating_costs =  parameter_values['factory_operating_costs'],\n",
    "            qm_per_customer = parameter_values['qm_per_customer'],\n",
    "            rent_factor = parameter_values['rent_factor'],\n",
    "            max_flight_distance = parameter_values['max_flight_distance'],\n",
    "            drone_initial_costs = parameter_values['drone_initial_costs'],\n",
    "            drone_speed = parameter_values['drone_speed'],\n",
    "            time_window = parameter_values['time_window'],\n",
    "            alpha_drones = parameter_values['alpha'],\n",
    "            delivery_time = parameter_values['delivery_time'],\n",
    "            night_shift_dist = parameter_values['night_shift_dist']\n",
    "            )\n",
    "\n",
    "        print('Solver set up!')\n",
    "\n",
    "        # Solve the problem and get the solution\n",
    "        opened_warehouses, customers_gdf_run, warehouses_gdf_run = solve(\n",
    "            W = W,\n",
    "            R = R, \n",
    "            solver = solver, \n",
    "            x = x, \n",
    "            y = y, \n",
    "            z = z, \n",
    "            d = d, \n",
    "            customers_gdf_run = customers_gdf_run, \n",
    "            warehouses_gdf_run = warehouses_gdf_run)\n",
    "        \n",
    "        # Assign the in the solution chosen warehouses in the dataset\n",
    "        bevölkerungs_gdf_run = assign_warehouses(bevölkerungs_gdf_run=bevölkerungs_gdf_run,\n",
    "                                                 customers_gdf_run=customers_gdf_run,\n",
    "                                                 warehouses_gdf_run=warehouses_gdf_run)\n",
    "        print('Dataset set up!')\n",
    "\n",
    "    \n",
    "    if not optimal_run: \n",
    "        opened_warehouses = opened_warehouses_optimal\n",
    "\n",
    "    # Get the start and end time of the service hours\n",
    "    start_time, end_time = calculate_times(minutes=parameter_values['time_window'])\n",
    "\n",
    "\n",
    "\n",
    "    # Simulate with optimal values\n",
    "    costs = simulate(\n",
    "        opened_warehouses_run = opened_warehouses, \n",
    "        bevölkerungs_gdf_run = bevölkerungs_gdf_run, \n",
    "        warehouses_gdf_run = warehouses_gdf_run, \n",
    "        cost_per_km_drone = cost_per_km_drone,\n",
    "        start_time = start_time,\n",
    "        end_time = end_time,\n",
    "        demand_factor = parameter_values['demand_factor'],\n",
    "        rent_factor = parameter_values['rent_factor'],\n",
    "        drone_speed = parameter_values['drone_speed'],\n",
    "        delivery_time = parameter_values['delivery_time'],\n",
    "        night_shift_dist = parameter_values['night_shift_dist'],\n",
    "        cost_per_km_car = cost_per_km_car,\n",
    "        cost_per_km_truck = cost_per_km_truck,\n",
    "        factory_fix_costs = parameter_values['factory_fix_costs'],\n",
    "        factory_variable_costs = parameter_values['factory_variable_costs'],\n",
    "        factory_operating_costs =  parameter_values['factory_operating_costs'],\n",
    "        drone_initial_costs = parameter_values['drone_initial_costs'],\n",
    "        sensitivity_run = sensitivity_run) \n",
    "    print('Simulation done!')\n",
    "\n",
    "    print_cost_summary(costs = costs)\n",
    "\n",
    "\n",
    "    if optimal_run:\n",
    "        if not sensitivity_run:\n",
    "            customers_gdf_run['Alter'] = customers_gdf_run['Alter'].apply(json.dumps)\n",
    "            customers_gdf_run.to_file(f'./Results/Optimal_Results_customers_{city}.gpkg', driver = 'GPKG')\n",
    "\n",
    "            bevölkerungs_gdf_run['Alter'] = bevölkerungs_gdf_run['Alter'].apply(json.dumps)\n",
    "            bevölkerungs_gdf_run['Geschlecht'] = bevölkerungs_gdf_run['Geschlecht'].apply(json.dumps)\n",
    "            bevölkerungs_gdf_run.to_file(f'./Results/Optimal_Results_bevoelkerung_{city}.gpkg', driver = 'GPKG')\n",
    "\n",
    "    \n",
    "            warehouses_gdf_run.to_file(f'./Results/Optimal_Results_warehouses_{city}.gpkg', driver = 'GPKG')\n",
    "\n",
    "        \n",
    "        # Dictionary erstellen, um die Werte zu speichern\n",
    "        warehouse_info = {}\n",
    "        # Durch die geöffneten Lagerhäuser iterieren und die entsprechenden Werte hinzufügen\n",
    "        for warehouse_id in opened_warehouses:\n",
    "            if warehouse_id in warehouses_gdf_run.index:\n",
    "                warehouse_info[warehouse_id] = {\n",
    "                    'floor_space_assigned': warehouses_gdf_run.at[warehouse_id, 'floor_space_assigned'],\n",
    "                    'number_of_drones': warehouses_gdf_run.at[warehouse_id, 'number_of_drones']\n",
    "        }\n",
    "\n",
    "        return {\n",
    "                'opened_warehouses': np.array(opened_warehouses),\n",
    "                'number_of_drones': np.sum(warehouses_gdf_run.loc[opened_warehouses].number_of_drones),\n",
    "                'floor_space_assigned': np.sum(warehouses_gdf_run.loc[opened_warehouses].floor_space_assigned),\n",
    "                'objective_value': solver.Objective().Value(),\n",
    "                'Factory Rental Cost': costs[0],\n",
    "                'Factory Fix Cost': costs[1],\n",
    "                'Factory Variable Cost': costs[2],\n",
    "                'Factory Operating Cost': costs[3],\n",
    "                'Drone Setup Cost': costs[4],\n",
    "                'Drone Transportation Cost': costs[5],\n",
    "                'Drone Transportation Time': costs[6]/60,\n",
    "                'Transportation Penalty Cost': costs[7],\n",
    "                'Transportation Avg Waiting Time': costs[8],\n",
    "                'Car/Truck Customer Transportation Cost': costs[9],\n",
    "                'Car/Truck Customer Transportation Time': costs[10],\n",
    "                'Car/Truck Pharmacy Transportation Cost': costs[11],\n",
    "                'Car/Truck Pharmacy Transportation Time': costs[12],\n",
    "                'Warehouse Info': warehouse_info\n",
    "                }\n",
    "    return {\n",
    "        'opened_warehouses': np.array(opened_warehouses_optimal),\n",
    "        'number_of_drones': np.sum(warehouses_gdf_run.loc[opened_warehouses_optimal].number_of_drones),\n",
    "        'floor_space_assigned': np.sum(warehouses_gdf_run.loc[opened_warehouses_optimal].floor_space_assigned),\n",
    "        'Factory Rental Cost': costs[0],\n",
    "        'Factory Fix Cost': costs[1],\n",
    "        'Factory Variable Cost': costs[2],\n",
    "        'Factory Operating Cost': costs[3],\n",
    "        'Drone Setup Cost': costs[4],\n",
    "        'Drone Transportation Cost': costs[5],\n",
    "        'Drone Transportation Time': costs[6],\n",
    "        'Transportation Penalty Cost': costs[7],\n",
    "        'Transportation Avg Waiting Time': costs[8],\n",
    "        'Car/Truck Customer Transportation Cost': costs[9],\n",
    "        'Car/Truck Customer Transportation Time': costs[10],\n",
    "        'Car/Truck Pharmacy Transportation Cost': costs[11],\n",
    "        'Car/Truck Pharmacy Transportation Time': costs[12]\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity_analysis(parameter_values, number_of_runs, sensitivity_index, parameter_names, optimal_run, sensitivity_run, bevölkerungs_gdf_run, warehouses_gdf_run, customers_gdf_run, shifts_df_run, opened_warehouses_optimal, warehouses_gdf_optimal, customers_gdf_optimal, bevölkerungs_gdf_optimal, city):\n",
    "    \n",
    "    if sensitivity_index != 'None':\n",
    "        triangular_values = np.random.triangular(parameter_values[sensitivity_index][0], parameter_values[sensitivity_index][1], parameter_values[sensitivity_index][2], number_of_runs)\n",
    "        triangular_values = np.append(triangular_values, parameter_values[sensitivity_index][0])\n",
    "        triangular_values = np.append(triangular_values, parameter_values[sensitivity_index][2])\n",
    "\n",
    "    result_list = []\n",
    "\n",
    "    for i in range(number_of_runs):\n",
    "    \n",
    "        if sensitivity_index != 'None':\n",
    "            parameter_values[sensitivity_index][1] = triangular_values[i]\n",
    "\n",
    "        base_values = [param[1] for param in parameter_values]\n",
    "\n",
    "        # Set the demand in case of demand_factor\n",
    "        customers_gdf_run_demand = customers_gdf_run.copy()\n",
    "        customers_gdf_run_demand['nachfrage'] = customers_gdf_run_demand['nachfrage'] * base_values[13]\n",
    "\n",
    "        warehouses_gdf_filtered = warehouses_gdf_run[warehouses_gdf_run['floorSpace_small'] >= base_values[4]].copy()\n",
    "\n",
    "        base_dict = {\n",
    "            'factory_fix_costs': base_values[0],\n",
    "            'factory_variable_costs': base_values[1],\n",
    "            'factory_operating_costs': base_values[2],\n",
    "            'qm_per_customer': base_values[3],\n",
    "            'minimum_square_requirement': base_values[4],\n",
    "            'rent_factor': base_values[5],\n",
    "            'max_flight_distance': base_values[6],\n",
    "            'drone_initial_costs': base_values[7],\n",
    "            'drone_speed': base_values[8],\n",
    "            'time_window': base_values[9],\n",
    "            'delivery_time': base_values[10],\n",
    "            'alpha': base_values[11],\n",
    "            'night_shift_dist': base_values[12],\n",
    "            'demand_factor': base_values[13],\n",
    "            'watt_drone': base_values[14],\n",
    "            'kwh_eur': base_values[15]\n",
    "            }\n",
    "\n",
    "        if optimal_run:\n",
    "            results = run(\n",
    "                parameter_values = base_dict, \n",
    "                bevölkerungs_gdf_run = bevölkerungs_gdf_run, \n",
    "                warehouses_gdf_run = warehouses_gdf_filtered, \n",
    "                customers_gdf_run = customers_gdf_run_demand, \n",
    "                shifts_df_run = shifts_df_run, \n",
    "                optimal_run = True,\n",
    "                opened_warehouses_optimal = None,\n",
    "                city = city,\n",
    "                sensitivity_run = False\n",
    "                )\n",
    "        \n",
    "        else: \n",
    "            results_new_optimal = run(\n",
    "                parameter_values = base_dict, \n",
    "                bevölkerungs_gdf_run = bevölkerungs_gdf_run, \n",
    "                warehouses_gdf_run = warehouses_gdf_filtered, \n",
    "                customers_gdf_run = customers_gdf_run_demand, \n",
    "                shifts_df_run = shifts_df_run, \n",
    "                optimal_run = True, \n",
    "                opened_warehouses_optimal = opened_warehouses_optimal,\n",
    "                city = city,\n",
    "                sensitivity_run = sensitivity_run\n",
    "                )\n",
    "            \n",
    "            results_old_optimal = run(\n",
    "                    parameter_values = base_dict, \n",
    "                    bevölkerungs_gdf_run = bevölkerungs_gdf_optimal, \n",
    "                    warehouses_gdf_run = warehouses_gdf_optimal, \n",
    "                    customers_gdf_run = customers_gdf_optimal, \n",
    "                    shifts_df_run = shifts_df_run, \n",
    "                    optimal_run = False, \n",
    "                    opened_warehouses_optimal = opened_warehouses_optimal,\n",
    "                    city = city,\n",
    "                    sensitivity_run = sensitivity_run\n",
    "                    )\n",
    "        \n",
    "        if optimal_run:\n",
    "            result_list.append({\n",
    "                'parameter': 'Base Value',\n",
    "                'parameter_value': 'Base_Value',\n",
    "                'results': results\n",
    "            })\n",
    "  \n",
    "        else: \n",
    "            result_list.append({\n",
    "                'parameter': parameter_names[sensitivity_index],\n",
    "                'parameter_value': triangular_values[i],\n",
    "                'results_old_optimal': results_old_optimal,\n",
    "                'results_new_optimal': results_new_optimal\n",
    "            })\n",
    "\n",
    "    \n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min_travel_distance(shifts_df):\n",
    "    # Initialize variables\n",
    "    min_distance = 0\n",
    "    max_distance = shifts_df['travel_distance'].max()\n",
    "    shifts_df.reset_index(inplace=True)\n",
    "\n",
    "    while min_distance <= max_distance:\n",
    "\n",
    "        current_distance = min_distance + 1\n",
    "\n",
    "        # Assuming 'node_a' and 'node_b' are columns containing node IDs, and 'distance' is the distance column\n",
    "        filtered_data = shifts_df[shifts_df['travel_distance'] < current_distance]\n",
    "\n",
    "        all_regions = shifts_df.region_id.unique()\n",
    "        filtered_regions = filtered_data.region_id.unique()  \n",
    "        region_present = set(all_regions).issubset(set(filtered_regions))\n",
    "\n",
    "        if region_present:\n",
    "            break\n",
    "        else:\n",
    "            min_distance = current_distance  # Update min distance if condition not met\n",
    "\n",
    "    shifts_df.set_index(['warehouse_id', 'region_id'], inplace=True)\n",
    "    return min_distance  # Minimum distance found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_names = [\n",
    "    \"factory_fix_costs\",\n",
    "    \"factory_variable_costs\",\n",
    "    \"factory_operating_costs\",\n",
    "    \"qm_per_customer\",\n",
    "    \"minimum_square_requirement\",\n",
    "    \"rent_factor\",\n",
    "    \"max_flight_distance\",\n",
    "    \"drone_initial_costs\",\n",
    "    \"drone_speed\",\n",
    "    \"time_window\",\n",
    "    \"delivery_time\",\n",
    "    \"alpha\",\n",
    "    \"night_shift_dist\",\n",
    "    \"demand_factor\",\n",
    "    \"watt_drone\",\n",
    "    \"kwh_eur\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_parameters(shifts_df): \n",
    "    base_factory_fix_costs = 50000 #Eur\n",
    "    min_factory_fix_costs = 10000 \n",
    "    max_factory_fix_costs = 100000 \n",
    "\n",
    "    base_factory_variable_costs = 0.5#Eur\n",
    "    min_factory_variable_costs = 0.25 \n",
    "    max_factory_variable_costs = 0.75 \n",
    "\n",
    "    base_factory_operating_costs = 0.375 # Prozent der Mietkosten\n",
    "    min_factory_operating_costs = 0.25 \n",
    "    max_factory_operating_costs = 0.5 \n",
    "\n",
    "    base_qm_per_customer = 10 #Quadratmeter\n",
    "    min_qm_per_customer = 5\n",
    "    max_qm_per_customer = 15 \n",
    "\n",
    "    base_minimum_square_requirement = 1000 #Quadratmeter\n",
    "    min_minimum_square_requirement = 500 \n",
    "    max_minimum_square_requirement = 1500 \n",
    "\n",
    "    base_rent_factor = 1 #Prozent\n",
    "    min_rent_factor = 0.5 \n",
    "    max_rent_factor = 1.5 \n",
    "\n",
    "    base_max_flight_distance = 25 #km\n",
    "    min_max_flight_distance = find_min_travel_distance(shifts_df=shifts_df)\n",
    "    max_max_flight_distance = 40 \n",
    "\n",
    "    base_drone_initial_costs = 4000 #Eur\n",
    "    min_drone_initial_costs = 2000 \n",
    "    max_drone_initial_costs = 6000 \n",
    "\n",
    "    base_drone_speed = 65/60 #km/h/60 = km/min\n",
    "    min_drone_speed = 50/60 \n",
    "    max_drone_speed = 80/60 \n",
    "\n",
    "    base_time_window = 630 #Min\n",
    "    min_time_window = 60 \n",
    "    max_time_window = 1439 \n",
    "\n",
    "    base_delivery_time = 60 #Min\n",
    "    min_delivery_time = 30\n",
    "    max_delivery_time = 90\n",
    "\n",
    "    base_alpha = 0.5\n",
    "    min_alpha = 0.25\n",
    "    max_alpha = 0.75\n",
    "\n",
    "    base_night_shift_dist = 0.00112103746 #Prozent \n",
    "    min_night_shift_dist = 0.00056051873 \n",
    "    max_night_shift_dist = 0.00168155619 \n",
    "\n",
    "    base_demand_factor = 1 #Prozent\n",
    "    min_demand_factor = 0.5 \n",
    "    max_demand_factor = 1.5 \n",
    "\n",
    "    base_watt_drone = 0.3 #Kw\n",
    "    min_watt_drone = 0.15 \n",
    "    max_watt_drone = 0.45 \n",
    "\n",
    "    base_kwh_eur = 0.4175\n",
    "    min_kwh_eur = 0.20875\n",
    "    max_kwh_eur = 0.62625\n",
    "\n",
    "    parameter_values = [\n",
    "    [min_factory_fix_costs, base_factory_fix_costs, max_factory_fix_costs],\n",
    "    [min_factory_variable_costs, base_factory_variable_costs, max_factory_variable_costs],\n",
    "    [min_factory_operating_costs, base_factory_operating_costs, max_factory_operating_costs],\n",
    "    [min_qm_per_customer, base_qm_per_customer, max_qm_per_customer],\n",
    "    [min_minimum_square_requirement, base_minimum_square_requirement, max_minimum_square_requirement],\n",
    "    [min_rent_factor, base_rent_factor, max_rent_factor],\n",
    "    [min_max_flight_distance, base_max_flight_distance, max_max_flight_distance],\n",
    "    [min_drone_initial_costs, base_drone_initial_costs, max_drone_initial_costs],\n",
    "    [min_drone_speed, base_drone_speed, max_drone_speed],\n",
    "    [min_time_window, base_time_window, max_time_window],\n",
    "    [min_delivery_time, base_delivery_time, max_delivery_time],\n",
    "    [min_alpha, base_alpha, max_alpha],\n",
    "    [min_night_shift_dist, base_night_shift_dist, max_night_shift_dist],\n",
    "    [min_demand_factor, base_demand_factor, max_demand_factor],\n",
    "    [min_watt_drone, base_watt_drone, max_watt_drone],\n",
    "    [min_kwh_eur, base_kwh_eur, max_kwh_eur]\n",
    "    ]\n",
    "    return parameter_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_run_results = []\n",
    "folder = ['Wuerzburg_Data', 'Donner_Data', 'Frankfurt_Data']\n",
    "city = ['wuerzburg', 'donner', 'frankfurt']\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "    customers_gdf = setup_customer_data(folder[i], city[i])\n",
    "    geo_würzburg, bevölkerungs_gdf, pharmacy_gdf, warehouses_gdf, shifts_df = load_data(customers_gdf, folder[i], city[i])\n",
    "\n",
    "    parameter_values = setup_parameters(shifts_df=shifts_df)\n",
    "\n",
    "    optimal_run_results.append({\n",
    "        'result_list': sensitivity_analysis(\n",
    "                            parameter_values = parameter_values, \n",
    "                            number_of_runs = 1, \n",
    "                            sensitivity_index = 'None', \n",
    "                            parameter_names = parameter_names, \n",
    "                            optimal_run = True,\n",
    "                            sensitivity_run = False,\n",
    "                            bevölkerungs_gdf_run = bevölkerungs_gdf,\n",
    "                            warehouses_gdf_run = warehouses_gdf,\n",
    "                            customers_gdf_run = customers_gdf,\n",
    "                            shifts_df_run = shifts_df,\n",
    "                            city = city[i],\n",
    "                            opened_warehouses_optimal = None,\n",
    "                            warehouses_gdf_optimal = None,\n",
    "                            customers_gdf_optimal = None,\n",
    "                            bevölkerungs_gdf_optimal = None\n",
    "                            ),\n",
    "        'city': city[i]\n",
    "    })\n",
    "\n",
    "    with open(f'./Results/optimal_run_results.pkl', 'wb') as outfile:\n",
    "        pickle.dump(optimal_run_results, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sensitivity(parameter_values, parameter_names, warehouses_gdf_run, customers_gdf_run, shifts_df_run, number_of_runs, sensitivity_index):\n",
    "    \n",
    "    triangular_parameter_values = [list(param) for param in parameter_values]\n",
    "\n",
    "    if sensitivity_index != 'None':\n",
    "        triangular_values = np.random.triangular(parameter_values[sensitivity_index][0], parameter_values[sensitivity_index][1], parameter_values[sensitivity_index][2], number_of_runs)\n",
    "        triangular_values = np.append(triangular_values, parameter_values[sensitivity_index][0])\n",
    "        triangular_values = np.append(triangular_values, parameter_values[sensitivity_index][2])\n",
    "\n",
    "    result_list = []\n",
    "\n",
    "    # Speichere den ursprünglichen Nachfragewert\n",
    "    original_demand = customers_gdf_run['nachfrage'].copy()\n",
    "\n",
    "    for i in range(len(triangular_values)):\n",
    "\n",
    "        print(f'Triangular Value: {triangular_values[i]}')\n",
    "    \n",
    "        triangular_parameter_values[sensitivity_index][1] = triangular_values[i]\n",
    "\n",
    "        base_values = [param[1] for param in triangular_parameter_values]\n",
    "\n",
    "        base_dict = {\n",
    "            'factory_fix_costs': base_values[0],\n",
    "            'factory_variable_costs': base_values[1],\n",
    "            'factory_operating_costs': base_values[2],\n",
    "            'qm_per_customer': base_values[3],\n",
    "            'minimum_square_requirement': base_values[4],\n",
    "            'rent_factor': base_values[5],\n",
    "            'max_flight_distance': base_values[6],\n",
    "            'drone_initial_costs': base_values[7],\n",
    "            'drone_speed': base_values[8],\n",
    "            'time_window': base_values[9],\n",
    "            'delivery_time': base_values[10],\n",
    "            'alpha': base_values[11],\n",
    "            'night_shift_dist': base_values[12],\n",
    "            'demand_factor': base_values[13],\n",
    "            'watt_drone': base_values[14],\n",
    "            'kwh_eur': base_values[15]\n",
    "        }\n",
    "        \n",
    "        # Setze die Nachfrage auf den ursprünglichen Wert zurück und multipliziere mit dem aktuellen demand_factor\n",
    "        customers_gdf_run_demand = customers_gdf_run.copy()\n",
    "        customers_gdf_run_demand['nachfrage'] = original_demand * base_dict['demand_factor']\n",
    "\n",
    "        warehouses_gdf_filtered = warehouses_gdf_run[warehouses_gdf_run['floorSpace_small'] >= base_dict['minimum_square_requirement']].copy()\n",
    "        \n",
    "        # Drohnenparameter\n",
    "        cost_per_km_drone = (base_dict['kwh_eur'] * base_dict['watt_drone']) / (base_dict['drone_speed'] * 60)  # EUR/km\n",
    "\n",
    "        W = warehouses_gdf_filtered.index.values\n",
    "        R = customers_gdf_run_demand.index.values\n",
    "        S = shifts_df_run.index.values\n",
    "        \n",
    "        # Setze das Optimierungsproblem\n",
    "        solver, x, y, z, d = optimize(\n",
    "            W=W, \n",
    "            R=R,\n",
    "            S=S, \n",
    "            warehouses_gdf_run=warehouses_gdf_filtered,\n",
    "            customers_gdf_opt=customers_gdf_run_demand,\n",
    "            cost_per_km_drone=cost_per_km_drone,\n",
    "            factory_fix_costs=base_dict['factory_fix_costs'],\n",
    "            factory_variable_costs=base_dict['factory_variable_costs'],\n",
    "            factory_operating_costs=base_dict['factory_operating_costs'],\n",
    "            qm_per_customer=base_dict['qm_per_customer'],\n",
    "            rent_factor=base_dict['rent_factor'],\n",
    "            max_flight_distance=base_dict['max_flight_distance'],\n",
    "            drone_initial_costs=base_dict['drone_initial_costs'],\n",
    "            drone_speed=base_dict['drone_speed'],\n",
    "            time_window=base_dict['time_window'],\n",
    "            alpha_drones=base_dict['alpha'],\n",
    "            delivery_time=base_dict['delivery_time'],\n",
    "            night_shift_dist=base_dict['night_shift_dist']\n",
    "        )\n",
    "\n",
    "        print('Solver set up!')\n",
    "\n",
    "        # Löse das Problem und erhalte die Lösung\n",
    "        opened_warehouses, customers_gdf_run, warehouses_gdf_filtered = solve(\n",
    "            W=W,\n",
    "            R=R, \n",
    "            solver=solver, \n",
    "            x=x, \n",
    "            y=y, \n",
    "            z=z, \n",
    "            d=d, \n",
    "            customers_gdf_run=customers_gdf_run_demand, \n",
    "            warehouses_gdf_run=warehouses_gdf_filtered\n",
    "        )\n",
    "\n",
    "        # Dictionary erstellen, um die Werte zu speichern\n",
    "        warehouse_info = {}\n",
    "        # Durch die geöffneten Lagerhäuser iterieren und die entsprechenden Werte hinzufügen\n",
    "        for warehouse_id in opened_warehouses:\n",
    "            if warehouse_id in warehouses_gdf_filtered.index:\n",
    "                warehouse_info[warehouse_id] = {\n",
    "                    'floor_space_assigned': warehouses_gdf_filtered.at[warehouse_id, 'floor_space_assigned'],\n",
    "                    'number_of_drones': warehouses_gdf_filtered.at[warehouse_id, 'number_of_drones']\n",
    "                }\n",
    "                \n",
    "        result_list.append({\n",
    "            'parameter_name': parameter_names[sensitivity_index],\n",
    "            'parameter_value': triangular_values[i],\n",
    "            'opened_warehouses': np.array(opened_warehouses),\n",
    "            'number_of_drones': np.sum(warehouses_gdf_filtered.loc[opened_warehouses].number_of_drones),\n",
    "            'floor_space_assigned': np.sum(warehouses_gdf_filtered.loc[opened_warehouses].floor_space_assigned),\n",
    "            'objective_value': solver.Objective().Value(),\n",
    "            'Warehouse Info': warehouse_info,\n",
    "            'parameter_values': triangular_parameter_values\n",
    "        })\n",
    "\n",
    "        #print(result_list)\n",
    "\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    return result_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity_run_results = []\n",
    "folder = ['Wuerzburg_Data', 'Donner_Data', 'Frankfurt_Data']\n",
    "city = ['wuerzburg', 'donner', 'frankfurt']\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "    customers_gdf = setup_customer_data(folder[i], city[i])\n",
    "    geo_würzburg, bevölkerungs_gdf, pharmacy_gdf, warehouses_gdf, shifts_df = load_data(customers_gdf, folder[i], city[i])\n",
    "\n",
    "    parameter_values = setup_parameters(shifts_df=shifts_df)\n",
    "    print(f'City: {city[i]}')\n",
    "    \n",
    "    for j in range(len(parameter_names)):\n",
    "        print(f'Parameter:{parameter_names[j]}')\n",
    "        sensitivity_run_results.append({\n",
    "            'result_list': test_sensitivity(\n",
    "                                parameter_values=[list(param) for param in parameter_values],\n",
    "                                number_of_runs = 50, \n",
    "                                sensitivity_index = j, \n",
    "                                parameter_names = parameter_names, \n",
    "                                warehouses_gdf_run = warehouses_gdf.copy(),\n",
    "                                customers_gdf_run = customers_gdf.copy(),\n",
    "                                shifts_df_run = shifts_df.copy()\n",
    "                                ),\n",
    "            'city': city[i]\n",
    "        })\n",
    "\n",
    "        with open('./Results/sensitivity_results_complete.pkl', 'wb') as outfile:\n",
    "            pickle.dump(sensitivity_run_results, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparison_simulate(opened_warehouses_run_sensitiv, \n",
    "                        bevölkerungs_gdf_run_sensitiv, \n",
    "                        warehouses_gdf_run_sensitiv,\n",
    "                        opened_warehouses_run_optimal, \n",
    "                        bevölkerungs_gdf_run_optimal, \n",
    "                        warehouses_gdf_run_optimal,\n",
    "                        cost_per_km_drone, \n",
    "                        drone_speed, \n",
    "                        delivery_time, \n",
    "                        start_time, \n",
    "                        end_time, \n",
    "                        demand_factor, \n",
    "                        rent_factor, \n",
    "                        night_shift_dist,\n",
    "                        factory_fix_costs, \n",
    "                        factory_variable_costs, \n",
    "                        factory_operating_costs, \n",
    "                        drone_initial_costs):\n",
    "\n",
    "    #Calculate the monthly fix costs due to drone and factory setup\n",
    "    rental_cost_sensitiv = (np.sum(warehouses_gdf_run_sensitiv.loc[opened_warehouses_run_sensitiv].floor_space_assigned * warehouses_gdf_run_sensitiv.loc[opened_warehouses_run_sensitiv].pricePerSquareMetre)) * rent_factor\n",
    "    factory_fix_monthly_sensitiv = (len(opened_warehouses_run_sensitiv) * factory_fix_costs) / 12\n",
    "    factory_variable_monthly_sensitiv = np.sum(warehouses_gdf_run_sensitiv.loc[opened_warehouses_run_sensitiv].floor_space_assigned * factory_variable_costs) / 12\n",
    "    factory_operating_monthly_sensitiv = np.sum(warehouses_gdf_run_sensitiv.loc[opened_warehouses_run_sensitiv].floor_space_assigned * warehouses_gdf_run_sensitiv.loc[opened_warehouses_run_sensitiv].pricePerSquareMetre * factory_operating_costs)\n",
    "    drone_setup_cost_sensitiv = ((np.sum(warehouses_gdf_run_sensitiv.loc[opened_warehouses_run_sensitiv].number_of_drones) * drone_initial_costs) / 12) / 5 \n",
    "\n",
    "    drone_transportation_cost_sensitiv = 0\n",
    "    drone_transportation_time_sensitiv = 0\n",
    "    time_penalty_costs_sensitiv = 0\n",
    "    time_penalty_day_sensitiv = 0\n",
    "    avg_waiting_time_sensitiv = 0\n",
    "\n",
    "\n",
    "    #Calculate the monthly fix costs due to drone and factory setup\n",
    "    rental_cost_optimal = (np.sum(warehouses_gdf_run_optimal.loc[opened_warehouses_run_optimal].floor_space_assigned * warehouses_gdf_run_optimal.loc[opened_warehouses_run_optimal].pricePerSquareMetre)) * rent_factor\n",
    "    factory_fix_monthly_optimal = (len(opened_warehouses_run_optimal) * factory_fix_costs) / 12\n",
    "    factory_variable_monthly_optimal = np.sum(warehouses_gdf_run_optimal.loc[opened_warehouses_run_optimal].floor_space_assigned * factory_variable_costs) / 12\n",
    "    factory_operating_monthly_optimal = np.sum(warehouses_gdf_run_optimal.loc[opened_warehouses_run_optimal].floor_space_assigned * warehouses_gdf_run_optimal.loc[opened_warehouses_run_optimal].pricePerSquareMetre * factory_operating_costs)\n",
    "    drone_setup_cost_optimal = ((np.sum(warehouses_gdf_run_optimal.loc[opened_warehouses_run_optimal].number_of_drones) * drone_initial_costs) / 12) / 5 \n",
    "\n",
    "    drone_transportation_cost_optimal = 0\n",
    "    drone_transportation_time_optimal = 0\n",
    "    time_penalty_costs_optimal = 0\n",
    "    time_penalty_day_optimal = 0\n",
    "    avg_waiting_time_optimal = 0\n",
    "\n",
    "    tqdm.pandas()\n",
    "\n",
    "    #Loop der Simulation über ein gesamtes Jahr\n",
    "    for i in range(2):\n",
    "\n",
    "        print(f'Simulation - Tag: {i + 1}')\n",
    "        \n",
    "        #Sensitiv\n",
    "        bevölkerungs_gdf_run_sensitiv['nachfrage'] = bevölkerungs_gdf_run_sensitiv.progress_apply(calculate_demand_sim, axis=1, demand_factor = demand_factor)\n",
    "        bevölkerungs_gdf_run_sensitiv['demand_timestamp'] = bevölkerungs_gdf_run_sensitiv.progress_apply(lambda row: assign_random_timestamp(row, night_shift_dist, start_time, end_time), axis=1)\n",
    "\n",
    "        # Calculate transportation costs and time using vectorized operations\n",
    "        drone_transportation_cost_sensitiv += np.sum(bevölkerungs_gdf_run_sensitiv['nachfrage'] * bevölkerungs_gdf_run_sensitiv['distance_warehouse'] * cost_per_km_drone * 2)\n",
    "        drone_transportation_time_sensitiv += np.sum((bevölkerungs_gdf_run_sensitiv['nachfrage'] * bevölkerungs_gdf_run_sensitiv['distance_warehouse']) / drone_speed )\n",
    "        time_penalty_day_sensitiv = calculate_penalty_costs(bevölkerungs_gdf_run_sensitiv, warehouses_gdf_run_sensitiv, drone_speed, delivery_time, start_time, end_time)\n",
    "        time_penalty_costs_sensitiv += time_penalty_day_sensitiv\n",
    "        avg_waiting_time_sensitiv = (avg_waiting_time_sensitiv + time_penalty_day_sensitiv / np.sum(bevölkerungs_gdf_run_sensitiv['nachfrage'])) / (i+1)\n",
    "        \n",
    "        bevölkerungs_gdf_run_sensitiv.drop('nachfrage', axis=1, inplace=True)\n",
    "        bevölkerungs_gdf_run_sensitiv.drop('demand_timestamp', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "        #Optimal\n",
    "        bevölkerungs_gdf_run_optimal['nachfrage'] = bevölkerungs_gdf_run_optimal.progress_apply(calculate_demand_sim, axis=1, demand_factor = demand_factor)\n",
    "        bevölkerungs_gdf_run_optimal['demand_timestamp'] = bevölkerungs_gdf_run_optimal.progress_apply(lambda row: assign_random_timestamp(row, night_shift_dist, start_time, end_time), axis=1)\n",
    "\n",
    "        # Calculate transportation costs and time using vectorized operations\n",
    "        drone_transportation_cost_optimal += np.sum(bevölkerungs_gdf_run_optimal['nachfrage'] * bevölkerungs_gdf_run_optimal['distance_warehouse'] * cost_per_km_drone * 2)\n",
    "        drone_transportation_time_optimal += np.sum((bevölkerungs_gdf_run_optimal['nachfrage'] * bevölkerungs_gdf_run_optimal['distance_warehouse']) / drone_speed )\n",
    "        time_penalty_day_optimal = calculate_penalty_costs(bevölkerungs_gdf_run_optimal, warehouses_gdf_run_optimal, drone_speed, delivery_time, start_time, end_time)\n",
    "        time_penalty_costs_optimal += time_penalty_day_optimal\n",
    "        avg_waiting_time_optimal = (avg_waiting_time_optimal + time_penalty_day_optimal / np.sum(bevölkerungs_gdf_run_optimal['nachfrage'])) / (i+1)\n",
    "        \n",
    "        bevölkerungs_gdf_run_optimal.drop('nachfrage', axis=1, inplace=True)\n",
    "        bevölkerungs_gdf_run_optimal.drop('demand_timestamp', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    return {\n",
    "        'sensitiv':\n",
    "        {\n",
    "            'rental_cost': rental_cost_sensitiv * 15,\n",
    "            'factory_fix_monthly': factory_fix_monthly_sensitiv * 15, \n",
    "            'factory_variable_monthly': factory_variable_monthly_sensitiv * 15, \n",
    "            'factory_operating_monthly': factory_operating_monthly_sensitiv * 15,\n",
    "            'drone_setup_cost': drone_setup_cost_sensitiv * 15, \n",
    "            'drone_transportation_cost': drone_transportation_cost_sensitiv * 15, \n",
    "            'drone_transportation_time': drone_transportation_time_sensitiv * 15, \n",
    "            'time_penalty_costs': time_penalty_costs_sensitiv * 15, \n",
    "            'avg_waiting_time': avg_waiting_time_sensitiv\n",
    "        },\n",
    "        'optimal':\n",
    "        {\n",
    "            'rental_cost': rental_cost_optimal * 15,\n",
    "            'factory_fix_monthly': factory_fix_monthly_optimal * 15, \n",
    "            'factory_variable_monthly': factory_variable_monthly_optimal * 15, \n",
    "            'factory_operating_monthly': factory_operating_monthly_optimal * 15,\n",
    "            'drone_setup_cost': drone_setup_cost_optimal * 15, \n",
    "            'drone_transportation_cost': drone_transportation_cost_optimal * 15, \n",
    "            'drone_transportation_time': drone_transportation_time_optimal * 15, \n",
    "            'time_penalty_costs': time_penalty_costs_optimal * 15, \n",
    "            'avg_waiting_time': avg_waiting_time_optimal\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_comparison_parameters():\n",
    "    parameters = {\n",
    "        'factory_fix_costs': 50000,\n",
    "        'factory_variable_costs': 0.5,\n",
    "        'factory_operating_costs': 0.375,\n",
    "        'qm_per_customer': 10,\n",
    "        'minimum_square_requirement': 1000, # Quadratmeter\n",
    "        'rent_factor': 1, # Prozent\n",
    "        'max_flight_distance': 25, # km\n",
    "        'drone_initial_costs': 4000, # Eur\n",
    "        'drone_speed': 65 / 60, # km/h / 60 = km/min\n",
    "        'time_window': 630, # Min\n",
    "        'delivery_time': 60, # Min\n",
    "        'alpha': 0.3,\n",
    "        'night_shift_dist': 0.00112103746, # Prozent\n",
    "        'demand_factor': 1, # Prozent\n",
    "        'watt_drone': 0.3, # kW\n",
    "        'kwh_eur': 0.4175\n",
    "    }\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: factory_fix_costs, Wert: 29517.008460113866\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 42\u001b[0m\n\u001b[1;32m     38\u001b[0m opened_warehouses_optimal \u001b[38;5;241m=\u001b[39m optimal_results[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult_list\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopened_warehouses\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     41\u001b[0m customers_gdf_sensitiv \u001b[38;5;241m=\u001b[39m setup_customer_data(folder[i], city[i])\n\u001b[0;32m---> 42\u001b[0m geo_würzburg, bevölkerungs_gdf_sensitiv, pharmacy_gdf, warehouses_gdf_sensitiv, shifts_df \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcustomers_gdf_sensitiv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolder\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcity\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m customers_gdf_sensitiv[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnachfrage\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m customers_gdf_sensitiv[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnachfrage\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;241m*\u001b[39m parameter_values[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdemand_factor\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     44\u001b[0m warehouses_gdf_sensitiv \u001b[38;5;241m=\u001b[39m warehouses_gdf_sensitiv[warehouses_gdf_sensitiv[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloorSpace_small\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m parameter_values[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimum_square_requirement\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "Cell \u001b[0;32mIn[2], line 99\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(customers_gdf, folder, city)\u001b[0m\n\u001b[1;32m     96\u001b[0m geo_würzburg \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mread_file(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfolder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/geo_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcity\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.gpkg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# Detaillierte Gebäude/Personen Daten laden\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m bevölkerungs_gdf \u001b[38;5;241m=\u001b[39m \u001b[43mgpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfolder\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/pharmacy_assigned_complete.gpkg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m bevölkerungs_gdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAlter\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m bevölkerungs_gdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAlter\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(json\u001b[38;5;241m.\u001b[39mloads)\n\u001b[1;32m    101\u001b[0m bevölkerungs_gdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGeschlecht\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m bevölkerungs_gdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGeschlecht\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(json\u001b[38;5;241m.\u001b[39mloads)\n",
      "File \u001b[0;32m~/anaconda3/envs/masterarbeit_python311/lib/python3.11/site-packages/geopandas/io/file.py:297\u001b[0m, in \u001b[0;36m_read_file\u001b[0;34m(filename, bbox, mask, rows, engine, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    295\u001b[0m         path_or_bytes \u001b[38;5;241m=\u001b[39m filename\n\u001b[0;32m--> 297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read_file_fiona\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown engine \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/masterarbeit_python311/lib/python3.11/site-packages/geopandas/io/file.py:395\u001b[0m, in \u001b[0;36m_read_file_fiona\u001b[0;34m(path_or_bytes, from_bytes, bbox, mask, rows, where, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[1;32m    392\u001b[0m         [record[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproperties\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m f_filt], columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[1;32m    393\u001b[0m     )\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 395\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mGeoDataFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_features\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf_filt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgeometry\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m datetime_fields:\n\u001b[1;32m    399\u001b[0m     as_dt \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[k], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/masterarbeit_python311/lib/python3.11/site-packages/geopandas/geodataframe.py:636\u001b[0m, in \u001b[0;36mGeoDataFrame.from_features\u001b[0;34m(cls, features, crs, columns)\u001b[0m\n\u001b[1;32m    633\u001b[0m     features_lst \u001b[38;5;241m=\u001b[39m features\n\u001b[1;32m    635\u001b[0m rows \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 636\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfeatures_lst\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# load geometry\u001b[39;49;00m\n\u001b[1;32m    638\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m__geo_interface__\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfeature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__geo_interface__\u001b[49m\n",
      "File \u001b[0;32mfiona/ogrext.pyx:1739\u001b[0m, in \u001b[0;36mfiona.ogrext.Iterator.__next__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mfiona/ogrext.pyx:391\u001b[0m, in \u001b[0;36mfiona.ogrext.FeatureBuilder.build\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/masterarbeit_python311/lib/python3.11/site-packages/fiona/model.py:288\u001b[0m, in \u001b[0;36mFeature.__init__\u001b[0;34m(self, geometry, id, properties, **data)\u001b[0m\n\u001b[1;32m    286\u001b[0m     properties \u001b[38;5;241m=\u001b[39m Properties()\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_delegate \u001b[38;5;241m=\u001b[39m _Feature(geometry\u001b[38;5;241m=\u001b[39mgeometry, \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mid\u001b[39m, properties\u001b[38;5;241m=\u001b[39mproperties)\n\u001b[0;32m--> 288\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/masterarbeit_python311/lib/python3.11/site-packages/fiona/model.py:127\u001b[0m, in \u001b[0;36mObject.__init__\u001b[0;34m(self, **kwds)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Base class for CRS, geometry, and feature objects\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03mIn Fiona 2.0, the implementation of those objects will change.  They\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;124;03mabout future deprecation of features.\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    125\u001b[0m _delegated_properties \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data \u001b[38;5;241m=\u001b[39m OrderedDict(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_props\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "folder = ['Wuerzburg_Data', 'Donner_Data', 'Frankfurt_Data']\n",
    "city = ['wuerzburg', 'donner', 'frankfurt']\n",
    "with open('./Results/optimal_run_results.pkl', 'rb') as infile:\n",
    "    optimal_results = pickle.load(infile)\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "    cost_comparison_result = []\n",
    "\n",
    "    with open(f'./Results/parameter_comparison_{city[i]}.pkl', 'rb') as infile:\n",
    "        parameter_change_list = pickle.load(infile)\n",
    "\n",
    "    min_value = min(item['max_flight_distance'] for item in parameter_change_list if 'max_flight_distance' in item)\n",
    "    parameter_change_list = [item for item in parameter_change_list if not ('max_flight_distance' in item and item['max_flight_distance'] == min_value)]\n",
    "\n",
    "\n",
    "    for j in range(len(parameter_change_list)):\n",
    "\n",
    "        key = 0\n",
    "        value = 0\n",
    "\n",
    "        for key, value in parameter_change_list[j].items():\n",
    "            key = key\n",
    "            value = value\n",
    "\n",
    "        parameter_values = setup_comparison_parameters()\n",
    "        parameter_values[key] = value\n",
    "\n",
    "        print(f'Parameter: {key}, Wert: {value}')\n",
    "\n",
    "\n",
    "        customers_gdf_optimal = gpd.read_file(f'./Results/Optimal_Results_customers_{city[i]}.gpkg')\n",
    "        warehouses_gdf_optimal = gpd.read_file(f'./Results/Optimal_Results_warehouses_{city[i]}.gpkg')\n",
    "        warehouses_gdf_optimal = warehouses_gdf_optimal.set_index('matching_index')\n",
    "        bevölkerungs_gdf_optimal = gpd.read_file(f'./Results/Optimal_Results_bevoelkerung_{city[i]}.gpkg')\n",
    "        bevölkerungs_gdf_optimal['Alter'] = bevölkerungs_gdf_optimal['Alter'].apply(json.loads)\n",
    "        bevölkerungs_gdf_optimal['Geschlecht'] = bevölkerungs_gdf_optimal['Geschlecht'].apply(json.loads)\n",
    "        opened_warehouses_optimal = optimal_results[i]['result_list'][0]['results']['opened_warehouses']\n",
    "\n",
    "\n",
    "        customers_gdf_sensitiv = setup_customer_data(folder[i], city[i])\n",
    "        geo_würzburg, bevölkerungs_gdf_sensitiv, pharmacy_gdf, warehouses_gdf_sensitiv, shifts_df = load_data(customers_gdf_sensitiv, folder[i], city[i])\n",
    "        customers_gdf_sensitiv['nachfrage'] = customers_gdf_sensitiv['nachfrage']  * parameter_values['demand_factor']\n",
    "        warehouses_gdf_sensitiv = warehouses_gdf_sensitiv[warehouses_gdf_sensitiv['floorSpace_small'] >= parameter_values['minimum_square_requirement']]\n",
    "\n",
    "        parameter_values['time_window'] = int(parameter_values['time_window'])\n",
    "        parameter_values['delivery_time'] = int(parameter_values['delivery_time'])\n",
    "        start_time, end_time = calculate_times(minutes=parameter_values['time_window'])\n",
    "        cost_per_km_drone = (parameter_values['kwh_eur'] * parameter_values['watt_drone']) / (parameter_values['drone_speed'] * 60)  # EUR/km # Calculate cost per kilometer for the drone\n",
    "\n",
    "        W = warehouses_gdf_sensitiv.index.values\n",
    "        R = customers_gdf_sensitiv.index.values\n",
    "        S = shifts_df.index.values\n",
    "        \n",
    "        # Set the optimization problem\n",
    "        solver, x, y, z, d = optimize(\n",
    "            W = W, \n",
    "            R = R,\n",
    "            S = S, \n",
    "            warehouses_gdf_run = warehouses_gdf_sensitiv,\n",
    "            customers_gdf_opt = customers_gdf_sensitiv, \n",
    "            cost_per_km_drone = cost_per_km_drone,\n",
    "            factory_fix_costs = parameter_values['factory_fix_costs'],\n",
    "            factory_variable_costs = parameter_values['factory_variable_costs'],\n",
    "            factory_operating_costs =  parameter_values['factory_operating_costs'],\n",
    "            qm_per_customer = parameter_values['qm_per_customer'],\n",
    "            rent_factor = parameter_values['rent_factor'],\n",
    "            max_flight_distance = parameter_values['max_flight_distance'],\n",
    "            drone_initial_costs = parameter_values['drone_initial_costs'],\n",
    "            drone_speed = parameter_values['drone_speed'],\n",
    "            time_window = parameter_values['time_window'],\n",
    "            alpha_drones = parameter_values['alpha'],\n",
    "            delivery_time = parameter_values['delivery_time'],\n",
    "            night_shift_dist = parameter_values['night_shift_dist']\n",
    "            )\n",
    "        \n",
    "        # Löse das Problem und erhalte die Lösung\n",
    "        opened_warehouses_sensitiv, customers_gdf_sensitiv, warehouses_gdf_sensitiv = solve(\n",
    "            W=W,\n",
    "            R=R, \n",
    "            solver=solver, \n",
    "            x=x, \n",
    "            y=y, \n",
    "            z=z, \n",
    "            d=d, \n",
    "            customers_gdf_run=customers_gdf_sensitiv, \n",
    "            warehouses_gdf_run=warehouses_gdf_sensitiv\n",
    "        )\n",
    "\n",
    "        bevölkerungs_gdf_sensitiv = assign_warehouses(bevölkerungs_gdf_run=bevölkerungs_gdf_sensitiv, \n",
    "                                                      customers_gdf_run=customers_gdf_sensitiv,\n",
    "                                                      warehouses_gdf_run=warehouses_gdf_sensitiv)\n",
    "\n",
    "        compared_costs = comparison_simulate(opened_warehouses_run_sensitiv=opened_warehouses_sensitiv,\n",
    "                                             bevölkerungs_gdf_run_sensitiv=bevölkerungs_gdf_sensitiv,\n",
    "                                             warehouses_gdf_run_sensitiv=warehouses_gdf_sensitiv,\n",
    "                                             opened_warehouses_run_optimal=opened_warehouses_optimal,\n",
    "                                             bevölkerungs_gdf_run_optimal=bevölkerungs_gdf_optimal,\n",
    "                                             warehouses_gdf_run_optimal=warehouses_gdf_optimal,\n",
    "                                             cost_per_km_drone=cost_per_km_drone,\n",
    "                                             drone_speed=parameter_values['drone_speed'],\n",
    "                                             delivery_time=parameter_values['delivery_time'],\n",
    "                                             start_time=start_time,\n",
    "                                             end_time=end_time,\n",
    "                                             demand_factor=parameter_values['demand_factor'],\n",
    "                                             rent_factor=parameter_values['rent_factor'],\n",
    "                                             night_shift_dist=parameter_values['night_shift_dist'],\n",
    "                                             factory_fix_costs=parameter_values['factory_fix_costs'],\n",
    "                                             factory_variable_costs=parameter_values['factory_variable_costs'],\n",
    "                                             factory_operating_costs=parameter_values['factory_operating_costs'],\n",
    "                                             drone_initial_costs=parameter_values['drone_initial_costs'])\n",
    "\n",
    "        cost_comparison_result.append({\n",
    "            'parameter': key,\n",
    "            'parameter_value': value,\n",
    "            'compared_costs': compared_costs,\n",
    "        })\n",
    "        \n",
    "        with open(f'./Results/cost_comparison_{city[i]}_complete.pkl', 'wb') as outfile:\n",
    "            pickle.dump(cost_comparison_result, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity_run_results = []\n",
    "folder = ['Wuerzburg_Data', 'Donner_Data', 'Frankfurt_Data']\n",
    "city = ['wuerzburg', 'donner', 'frankfurt']\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "    customers_gdf = setup_customer_data(folder[i], city[i])\n",
    "    geo_würzburg, bevölkerungs_gdf, pharmacy_gdf, warehouses_gdf, shifts_df = load_data(customers_gdf, folder[i], city[i])\n",
    "    \n",
    "    with open('./Results/optimal_run_results.pkl', 'rb') as infile:\n",
    "        optimal_result = pickle.load(infile)\n",
    "        opened_warehouses = optimal_result[i]['result_list'][0]['results']['opened_warehouses']\n",
    "\n",
    "    parameter_values = setup_parameters(shifts_df=shifts_df)\n",
    "\n",
    "    customers_gdf_optimal = gpd.read_file(f'./Results/Optimal_Results_customers_{city[i]}.gpkg')\n",
    "    customers_gdf_optimal['Alter'] = customers_gdf_optimal['Alter'].apply(json.loads)\n",
    "\n",
    "    warehouses_gdf_optimal = gpd.read_file(f'./Results/Optimal_Results_warehouses_{city[i]}.gpkg')\n",
    "\n",
    "    bevölkerungs_gdf_optimal = gpd.read_file(f'./Results/Optimal_Results_bevoelkerung_{city[i]}.gpkg')\n",
    "    bevölkerungs_gdf_optimal['Alter'] = bevölkerungs_gdf_optimal['Alter'].apply(json.loads)\n",
    "    bevölkerungs_gdf_optimal['Geschlecht'] = bevölkerungs_gdf_optimal['Geschlecht'].apply(json.loads)\n",
    "    \n",
    "    for i in range(len(parameter_values)):    \n",
    "        sensitivity_run_results.append({\n",
    "            'result_list': sensitivity_analysis(\n",
    "                                parameter_values = parameter_values, \n",
    "                                number_of_runs = 10, \n",
    "                                sensitivity_index = i, \n",
    "                                parameter_names = parameter_names, \n",
    "                                optimal_run = False,\n",
    "                                sensitivity_run = True,\n",
    "                                bevölkerungs_gdf_run = bevölkerungs_gdf,\n",
    "                                warehouses_gdf_run = warehouses_gdf,\n",
    "                                customers_gdf_run = customers_gdf,\n",
    "                                shifts_df_run = shifts_df,\n",
    "                                city = city[i],\n",
    "                                opened_warehouses_optimal = opened_warehouses,\n",
    "                                customers_gdf_optimal = customers_gdf_optimal,\n",
    "                                warehouses_gdf_optimal = warehouses_gdf_optimal, \n",
    "                                bevölkerungs_gdf_optimal = bevölkerungs_gdf_optimal  \n",
    "                                ),\n",
    "            'city': city[i]\n",
    "        })\n",
    "\n",
    "        with open('./Results/sensitivity_results.pkl', 'wb') as outfile:\n",
    "            pickle.dump(sensitivity_run_results, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## datafix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## energy_costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get('https://api.corrently.io/v2.0/gsi/marketdata?zip=97072')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = json.loads(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the response data is stored in a variable called 'response_data'\n",
    "\n",
    "# Extract market prices\n",
    "market_prices = [item['localprice'] for item in content['data']]\n",
    "\n",
    "# Sort the market prices\n",
    "sorted_prices = sorted(market_prices)\n",
    "\n",
    "# Calculate the number of data points\n",
    "num_prices = len(sorted_prices)\n",
    "\n",
    "# Calculate median position\n",
    "median_pos = (num_prices + 1) // 2\n",
    "\n",
    "# Access the median value\n",
    "median = sorted_prices[median_pos - 1] / 1000\n",
    "\n",
    "# Calculate quartile positions (rounded down)\n",
    "q1_pos = (num_prices + 1) // 4\n",
    "q3_pos = 3 * (num_prices + 1) // 4\n",
    "\n",
    "# Access the quartile values\n",
    "q1 = sorted_prices[q1_pos - 1] / 1000\n",
    "q3 = sorted_prices[q3_pos - 1] / 1000\n",
    "\n",
    "# Print the results\n",
    "print(\"Median market price:\", median, \"Eur/MWh\")\n",
    "print(\"25th percentile (Q1):\", q1, \"Eur/MWh\")\n",
    "print(\"75th percentile (Q3):\", q3, \"Eur/MWh\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sim Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Results/cost_comparison_frankfurt_complete.pkl', 'rb') as infile:\n",
    "    solution = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Results/optimal_run_results.pkl', 'rb') as infile:\n",
    "    solution2 = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keys to remove\n",
    "keys_to_remove = {'factory_fix_costs', 'qm_per_customer', 'qm_per_drone', 'max_flight_distance', 'drone_initial_costs'}\n",
    "\n",
    "# Filter out dictionaries that contain any of the keys\n",
    "filtered_solution = [entry for entry in solution if not any(key in entry for key in keys_to_remove)]\n",
    "\n",
    "filtered_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Results/parameter_comparison_filtered_1.pkl', 'wb') as outfile:\n",
    "    pickle.dump(filtered_solution, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_gdf_sensitiv = setup_customer_data('Wuerzburg_Data', 'wuerzburg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(customers_gdf_sensitiv['nachfrage']/365) * 15"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterarbeit_python311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
