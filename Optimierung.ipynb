{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "from matplotlib.lines import Line2D\n",
    "from math import radians, sin, cos, asin, sqrt\n",
    "import re\n",
    "import requests\n",
    "from datetime import time, timedelta, datetime\n",
    "from statistics import median, quantiles\n",
    "\n",
    "\n",
    "import geohash2\n",
    "import pyproj\n",
    "from pyproj import Proj, transform, CRS\n",
    "from functools import partial\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "from geopy.distance import geodesic\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy.stats import poisson\n",
    "\n",
    "from ortools.constraint_solver import routing_enums_pb2\n",
    "from ortools.constraint_solver import pywrapcp\n",
    "from ortools.linear_solver import pywraplp\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_demand_data(row):\n",
    "    probabilities = {\n",
    "        '0-10': 0,\n",
    "        '10-20': 0.003458068783068975,\n",
    "        '20-30': 0.013896825396825975,\n",
    "        '30-40': 0.02136825396825512,\n",
    "        '40-50': 0.02338333333333506,\n",
    "        '50-60': 0.026277248677250214,\n",
    "        '60-70': 0.03332089947090043,\n",
    "        '70-80': 0.046515343915346036,\n",
    "        '80+': 0.046515343915346036,\n",
    "    }\n",
    "\n",
    "    total_demand = 0\n",
    "    for age_group, count in row['Alter'].items():\n",
    "        lambda_value = count * probabilities[age_group]\n",
    "        total_demand += poisson.rvs(lambda_value)\n",
    "    return total_demand * 365\n",
    "\n",
    "\n",
    "def setup_customer_data(folder, city):\n",
    "    customers_gdf = gpd.read_file(f'./{folder}/cluster_{city}.gpkg')\n",
    "    customers_gdf['Alter'] = customers_gdf['Alter'].apply(json.loads)\n",
    "\n",
    "    customers_gdf['nachfrage'] = customers_gdf.apply(calculate_demand_data, axis=1)\n",
    "\n",
    "    bevoelkerung_sum = customers_gdf[customers_gdf['cluster'] != -1].groupby('cluster')['sum_INSGESAMT_0'].sum()\n",
    "    noise_demand = customers_gdf[customers_gdf['cluster'] == -1]['nachfrage'].iloc[0]\n",
    "\n",
    "    # Verteilung des Noise-Bedarfs auf die anderen Cluster anteilig zur Anzahl der Polygone\n",
    "    for cluster in bevoelkerung_sum.index:\n",
    "        cluster_demand = noise_demand * (bevoelkerung_sum[cluster] / bevoelkerung_sum.sum())\n",
    "        customers_gdf.loc[customers_gdf['cluster'] == cluster, 'nachfrage'] += np.round(cluster_demand)\n",
    "\n",
    "    customers_gdf = customers_gdf[customers_gdf['cluster'] != -1].reset_index(drop=True)\n",
    "    # Set Index to cluster id\n",
    "    customers_gdf.set_index(['cluster'], inplace=True)\n",
    "\n",
    "    return customers_gdf\n",
    "\n",
    "\n",
    "def load_energy_costs():\n",
    "    # Calculate timestamps (current time minus 48 hours and current time)\n",
    "    current_time = datetime.now()\n",
    "    past_timestamp = (current_time - timedelta(days=365)).timestamp() * 1000\n",
    "    current_timestamp = current_time.timestamp() * 1000\n",
    "\n",
    "    # Construct the API URL with updated timestamps\n",
    "    api_url = f\"https://api.awattar.de/v1/marketdata?start={past_timestamp}&end={current_timestamp}\"\n",
    "\n",
    "    # Send GET request using the requests library\n",
    "    try:\n",
    "        response = requests.get(api_url)\n",
    "        response.raise_for_status()  # Raise an exception for non-2xx status codes\n",
    "    except requests.exceptions.RequestException as error:\n",
    "        print(f\"Error: {error}\")\n",
    "\n",
    "    # Load data in json format\n",
    "    data_energy = json.loads(response.content)\n",
    "    # Extract market prices\n",
    "    market_prices = [item[\"marketprice\"] for item in data_energy[\"data\"]]\n",
    "\n",
    "    # Calculate quantiles\n",
    "    q1, q2, q3 = quantiles(market_prices)  # Use quartiles function\n",
    "    # Transform to Eur/kWh\n",
    "    q1_kwh_eur = q1 / 1000\n",
    "    q2_kwh_eur = q2 / 1000\n",
    "    q3_kwh_eur = q3 / 1000\n",
    "\n",
    "    print(f\"Median market price (kWh): {q2_kwh_eur:.5f} Eur/kWh\")\n",
    "    print(f\"25th percentile (Q1, kWh): {q1_kwh_eur:.2f} Eur/kWh\")\n",
    "    print(f\"75th percentile (Q3, kWh): {q3_kwh_eur:.2f} Eur/kWh\")\n",
    "\n",
    "    return data_energy, q1_kwh_eur, q2_kwh_eur, q3_kwh_eur\n",
    "\n",
    "\n",
    "def calculate_travel_distance(warehouses_gdf, customers_gdf):\n",
    "    # Create an empty list to store the results\n",
    "    data = []\n",
    "    # Iterate through each warehouse in the warehouse DataFrame\n",
    "    for warehouse_index, warehouse in warehouses_gdf.iterrows():\n",
    "        for customer_index, customer in customers_gdf.iterrows():\n",
    "            # Calculate the distance between the centroid of the region and the warehouse\n",
    "            travel_distance = warehouse.geometry.distance(customer.geometry.centroid)/1000\n",
    "            # Append the calculated values to the list\n",
    "            data.append({'warehouse_id': warehouse_index, 'region_id': customer_index, 'travel_distance': travel_distance})\n",
    "    # Create a DataFrame from the collected data\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_data(customers_gdf, folder, city):\n",
    "    \n",
    "    # Grenzen des Simulationsrahmens laden\n",
    "    geo_würzburg = gpd.read_file(f'./{folder}/geo_{city}.gpkg')\n",
    "\n",
    "    # Detaillierte Gebäude/Personen Daten laden\n",
    "    bevölkerungs_gdf = gpd.read_file(f'./{folder}/pharmacy_assigned_complete.gpkg')\n",
    "    bevölkerungs_gdf['Alter'] = bevölkerungs_gdf['Alter'].apply(json.loads)\n",
    "    bevölkerungs_gdf['Geschlecht'] = bevölkerungs_gdf['Geschlecht'].apply(json.loads)\n",
    "\n",
    "    # Apotheken Daten laden\n",
    "    pharmacy_df = pd.read_csv(f'./{folder}/{city}-Apotheken.csv')\n",
    "    pharmacy_gdf = gpd.GeoDataFrame(pharmacy_df, geometry=gpd.points_from_xy(pharmacy_df['lon'], pharmacy_df['lat']), crs=CRS(\"EPSG:4326\"))\n",
    "    pharmacy_gdf = pharmacy_gdf.to_crs(bevölkerungs_gdf.crs)\n",
    "\n",
    "    # Warehouse Daten laden\n",
    "    warehouses_gdf = gpd.read_file(f'./{folder}/warehouses_{city}.gpkg')\n",
    "\n",
    "    # Distanzmatrix der Cluster und Warehouses erstellen\n",
    "    shifts_df = calculate_travel_distance(warehouses_gdf, customers_gdf)\n",
    "    shifts_df.set_index(['warehouse_id', 'region_id'], inplace=True)\n",
    "\n",
    "    return geo_würzburg, bevölkerungs_gdf, pharmacy_gdf, warehouses_gdf, shifts_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'Wuerzburg_Data'\n",
    "city = 'wuerzburg'\n",
    "\n",
    "customers_gdf = setup_customer_data(folder, city)\n",
    "geo_würzburg, bevölkerungs_gdf, pharmacy_gdf, warehouses_gdf, shifts_df, data_energy, q1_kwh_eur, q2_kwh_eur, q3_kwh_eur = load_data(customers_gdf, folder, city)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimierungsmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(W,\n",
    "             R,\n",
    "             S,\n",
    "             warehouses_gdf_run,\n",
    "             cost_per_km_drone,\n",
    "             factory_setup_costs, \n",
    "             qm_per_customer, \n",
    "             qm_per_drone,\n",
    "             minimum_square_requirement, \n",
    "             rent_factor, \n",
    "             max_flight_distance, \n",
    "             drone_initial_costs, \n",
    "             drone_speed, \n",
    "             time_window, \n",
    "             night_shift_dist, \n",
    "             delivery_time,\n",
    "             alpha_drones):\n",
    "    \n",
    "    M = 1000000000\n",
    "    \n",
    "    # Create a solver\n",
    "    solver = pywraplp.Solver('FacilityLocation', pywraplp.Solver.CBC_MIXED_INTEGER_PROGRAMMING)\n",
    "\n",
    "    # Define decision variables\n",
    "    # Which warehouse serves which region\n",
    "    x = {}\n",
    "    for w, r in S:\n",
    "        x[w,r] = solver.BoolVar(name=f'x_{w}_{r}')\n",
    "\n",
    "    # Which warehouses are opened\n",
    "    y = {}\n",
    "    # How many drones are needed in each warehouse\n",
    "    z = {}\n",
    "    # How much space is rented in each warehouse\n",
    "    d = {}\n",
    "    for w in W:\n",
    "        y[w] = solver.BoolVar(name=f'y_{w}')\n",
    "        z[w] = solver.IntVar(0, solver.infinity(), name=f'z_{w}')\n",
    "        d[w] = solver.IntVar(0, solver.infinity(), name=f'd_{w}')\n",
    "        \n",
    "    # Objective Function\n",
    "    objective = solver.Objective()\n",
    "    \n",
    "    \n",
    "    # Fixed costs for opening warehouses\n",
    "    for w in W:\n",
    "        objective.SetCoefficient(y[w], factory_setup_costs)  # Add fixed factory setup costs\n",
    "        objective.SetCoefficient(d[w], warehouses_gdf_run.loc[w, 'pricePerSquareMetre'] * rent_factor)  # Cost per square meter\n",
    "\n",
    "        \n",
    "    # Costs for acquiring drones\n",
    "    for w in W:\n",
    "        objective.SetCoefficient(z[w], drone_initial_costs)\n",
    "    \n",
    "    # Variable costs for transportation\n",
    "    for w, r in S:\n",
    "        objective.SetCoefficient(x[w,r], cost_per_km_drone * shifts_df.loc[w,r].travel_distance * 2 * customers_gdf.loc[r, 'nachfrage'])\n",
    "\n",
    "    objective.SetMinimization()\n",
    "    \n",
    "    # Constraints\n",
    "    # Regions can only be served by open warehouses\n",
    "    for w in W:\n",
    "        for r in R:\n",
    "            solver.Add(x[w,r] <= y[w])\n",
    "\n",
    "    # Each region has to be served by exactly one warehouse\n",
    "    for r in R:\n",
    "        solver.Add(solver.Sum(x[w,r] for w in W) == 1)\n",
    "\n",
    "    # Each warehouse needs to be assigned with a certain amount of drones\n",
    "    # Definiere das Zeitfenster für die Erfüllung des Demands (in Minuten)\n",
    "    # Berechne den täglichen Demand Faktor\n",
    "    daily_demand_factor = (1 - night_shift_dist) / 365\n",
    "\n",
    "    for w in W:\n",
    "        # Initialisiere den Ausdruck für die gesamte Reisezeit\n",
    "        total_time = solver.Sum(\n",
    "            x[w, r] * shifts_df.loc[w, r].travel_distance * 2 * \n",
    "            (customers_gdf.loc[r, 'nachfrage'] * daily_demand_factor / drone_speed)\n",
    "            for r in R\n",
    "        ) / time_window\n",
    "\n",
    "        # Berechne die maximale Anzahl an Drones, die benötigt werden, um parallele oder überlappende Demands zu erfüllen\n",
    "        max_drones_needed = solver.Sum(\n",
    "            x[w, r] * shifts_df.loc[w, r].travel_distance * 2 * \n",
    "            (customers_gdf.loc[r, 'nachfrage'] * daily_demand_factor / drone_speed)\n",
    "            for r in R\n",
    "        ) / delivery_time\n",
    "\n",
    "        # Berücksichtige eine gewichtete Summe, um beiden Szenarien gerecht zu werden\n",
    "        combined_drones_needed = (1 - alpha_drones) * total_time + alpha_drones * max_drones_needed\n",
    "\n",
    "        # Füge die erweiterte Constraint hinzu\n",
    "        solver.Add(combined_drones_needed <= z[w])\n",
    "\n",
    "\n",
    "    # Each warehouse is assigned a certain amound of space that is between the boundries of the offering\n",
    "    for w in W:\n",
    "        solver.Add(y[w] * warehouses_gdf_run.loc[w, 'floorSpace_small'] <= d[w])\n",
    "        solver.Add(y[w] * warehouses_gdf_run.loc[w, 'floorSpace_big'] >= d[w])\n",
    "        \n",
    "    # The distance from warehouse to customer can't be taller than the maximum flight range of each drone\n",
    "    for w in W:\n",
    "        for r in R:\n",
    "            solver.Add(x[w,r] * shifts_df.loc[w,r].travel_distance <= max_flight_distance)\n",
    "\n",
    "    # Each warehouse has to fulfill a certain minimum space requirement\n",
    "    for w in W:\n",
    "        solver.Add(d[w] >= y[w] * minimum_square_requirement)\n",
    "\n",
    "    # Each warehouse needs a certain amount of space for each customer served\n",
    "    for w in W:\n",
    "        customer_demand_sum = solver.Sum(x[w, r] * (customers_gdf.loc[r, 'nachfrage'] / 365) for r in R)\n",
    "        required_space_for_customers = customer_demand_sum * qm_per_customer\n",
    "        required_space_for_drones = z[w] * qm_per_drone\n",
    "        solver.Add(d[w] >= (required_space_for_customers + required_space_for_drones))\n",
    "\n",
    "    return solver, x, y, z, d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lösungsausgabe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(W, R, solver, x, y, z, d, customers_gdf_run, warehouses_gdf_run):\n",
    "  opened_warehouses = []\n",
    "  customers_gdf_run['assigned_warehouse'] = 0\n",
    "  warehouses_gdf_run['number_of_drones'] = 0\n",
    "  warehouses_gdf_run['floor_space_assigned'] = 0\n",
    "\n",
    "  #Solving the problem\n",
    "  status = solver.Solve()\n",
    "  print('Solved!')\n",
    "\n",
    "  def print_solution(status, solver, opened_warehouses, x, y, z, d, W, R):\n",
    "\n",
    "    if status == pywraplp.Solver.OPTIMAL:\n",
    "      print(\"Objective value:\", solver.Objective().Value())\n",
    "      #print(\"Opened warehouses:\")\n",
    "      opened_warehouses.clear()  # Clear the list before appending\n",
    "      for w in W:\n",
    "        if y[w].solution_value() > 0.5:\n",
    "          opened_warehouses.append(w)\n",
    "          warehouses_gdf_run.loc[w, 'number_of_drones'] = z[w].solution_value()\n",
    "          warehouses_gdf_run.loc[w, 'floor_space_assigned'] = d[w].solution_value()\n",
    "          #print(f\"- Warehouse {w}\")\n",
    "          #print(f\"Floor-Space: {d[w].solution_value()}\")\n",
    "          #print(f\"Drones needed: {z[w].solution_value()}\")\n",
    "      #print(\"Warehouse assignments:\")\n",
    "      for r in R:\n",
    "        assigned_warehouse = None\n",
    "        for w in W:\n",
    "          if x[w, r].solution_value() > 0.5:\n",
    "            assigned_warehouse = w\n",
    "            break\n",
    "        if assigned_warehouse is not None:\n",
    "          customers_gdf_run.loc[r, 'assigned_warehouse'] = assigned_warehouse\n",
    "          #print(f\"- Region {r} served by warehouse {assigned_warehouse}\")\n",
    "          #distance = shifts_df.loc[assigned_warehouse, r].travel_distance\n",
    "          #print(f\"- Distance: {distance}\")\n",
    "        else:\n",
    "          print(f\"- Region {r} has no assigned warehouse (might be infeasible)\")\n",
    "    else:\n",
    "      print(\"Solver failed to find an optimal solution. Status:\", status)\n",
    "\n",
    "\n",
    "  print_solution(status, solver, opened_warehouses, x, y, z, d, W, R)\n",
    "  print(f'Opened Warehouses: {opened_warehouses}')\n",
    "  \n",
    "  return opened_warehouses, customers_gdf_run, warehouses_gdf_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning a warehouse to each building based on the optimal value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion, um das zugewiesene Lager für einen Punkt zu finden\n",
    "def find_assigned_warehouse(point, customers_gdf_run, cluster_sindex):\n",
    "    # Räumlichen Index für das Cluster-GDF erstellen\n",
    "    possible_matches_index = list(cluster_sindex.intersection(point.bounds))\n",
    "    possible_matches = customers_gdf_run.iloc[possible_matches_index]\n",
    "    output = possible_matches[possible_matches.geometry.contains(point)]\n",
    "    if not output.empty:\n",
    "        return [output.assigned_warehouse.iloc[0]]\n",
    "    else:\n",
    "        nearest_polygon_index = cluster_sindex.nearest(point)[0]\n",
    "        nearest_polygon = customers_gdf_run.iloc[nearest_polygon_index]\n",
    "        return [nearest_polygon.assigned_warehouse.iloc[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_warehouses(bevölkerungs_gdf_run, customers_gdf_run):\n",
    "    # Verfolgen Sie den Fortschritt der apply-Methode\n",
    "    tqdm.pandas()\n",
    "    \n",
    "    cluster_sindex = customers_gdf_run.sindex\n",
    "\n",
    "    # Die apply-Methode auf die GeoDataFrame anwenden, um das zugewiesene Lager für jeden Punkt zu finden\n",
    "    warehouses = bevölkerungs_gdf_run['geometry'].progress_apply(find_assigned_warehouse, customers_gdf_run = customers_gdf_run, cluster_sindex = cluster_sindex)\n",
    "\n",
    "    bevölkerungs_gdf_run['assigned_warehouse'] = 0\n",
    "    bevölkerungs_gdf_run['distance_warehouse'] = 0.0\n",
    "\n",
    "    for index, row in tqdm(bevölkerungs_gdf_run.iterrows(), total=len(bevölkerungs_gdf_run)):\n",
    "        bevölkerungs_gdf_run.loc[index, 'assigned_warehouse'] = warehouses[index][0]\n",
    "        warehouse_geometry = warehouses_gdf.loc[row['assigned_warehouse'], 'geometry']\n",
    "        population_geometry = row['geometry']\n",
    "        bevölkerungs_gdf_run.loc[index, 'distance_warehouse'] = warehouse_geometry.distance(population_geometry) / 1000\n",
    "\n",
    "    return bevölkerungs_gdf_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulations LoopFunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_demand_sim(row, demand_factor):\n",
    "    \n",
    "    probabilities = {\n",
    "        '0-10': 0,\n",
    "        '10-20': 0.003458068783068975,\n",
    "        '20-30': 0.013896825396825975,\n",
    "        '30-40': 0.02136825396825512,\n",
    "        '40-50': 0.02338333333333506,\n",
    "        '50-60': 0.026277248677250214,\n",
    "        '60-70': 0.03332089947090043,\n",
    "        '70-80': 0.046515343915346036,\n",
    "        '80+': 0.046515343915346036,\n",
    "    }\n",
    "    \n",
    "    total_demand = 0\n",
    "    for age_group, count in row['Alter'].items():\n",
    "        lambda_value = count * probabilities[age_group]\n",
    "        total_demand += poisson.rvs(lambda_value)\n",
    "    return total_demand * demand_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_random_timestamp(row, night_shift_dist, start_time, end_time):\n",
    "    timestamp_list = []\n",
    "    for i in range(row['nachfrage']): \n",
    "        probabilities_timestamp = [1 - night_shift_dist, night_shift_dist]  # Wahrscheinlichkeit für innerhalb und außerhalb der Öffnungszeiten\n",
    "\n",
    "        start_hour = start_time.hour\n",
    "        start_minute = start_time.minute\n",
    "        end_hour = end_time.hour\n",
    "        end_minute = end_time.minute\n",
    "\n",
    "        if np.random.choice([False, True], p=probabilities_timestamp):\n",
    "            # Außerhalb der Öffnungszeiten\n",
    "            if random.choice([True, False]):\n",
    "                # Vor den Öffnungszeiten\n",
    "                hour = random.randint(0, start_hour - 1)\n",
    "                minute = random.randint(0, 59)\n",
    "                second = random.randint(0, 59)\n",
    "            else:\n",
    "                # Nach den Öffnungszeiten\n",
    "                hour = random.randint(end_hour + 1, 23)\n",
    "                minute = random.randint(0, 59)\n",
    "                second = random.randint(0, 59)\n",
    "        else:\n",
    "            # Innerhalb der Öffnungszeiten\n",
    "            if start_hour == end_hour:\n",
    "                hour = start_hour\n",
    "                minute = random.randint(start_minute, end_minute)\n",
    "            else:\n",
    "                hour = random.randint(start_hour, end_hour)\n",
    "                if hour == start_hour:\n",
    "                    minute = random.randint(start_minute, 59)\n",
    "                elif hour == end_hour:\n",
    "                    minute = random.randint(0, end_minute)\n",
    "                else:\n",
    "                    minute = random.randint(0, 59)\n",
    "            second = random.randint(0, 59)\n",
    "        \n",
    "        timestamp = datetime.combine(datetime.today(), datetime.min.time()) + timedelta(hours=hour, minutes=minute, seconds=second)\n",
    "        timestamp_list.append(timestamp)\n",
    "    return timestamp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_penalty_costs(bevoelkerungs_gdf_sim, warehouses_gdf_sim, drone_speed, time_window, opening_start_time, opening_end_time):\n",
    "    # Convert time_window to a timedelta object\n",
    "    time_window = timedelta(minutes=time_window)\n",
    "    \n",
    "    # Initialize a dictionary to keep track of next available times for drones in each warehouse\n",
    "    warehouse_drones = {warehouse: [opening_start_time] * warehouses_gdf_sim.loc[warehouse, 'number_of_drones'] for warehouse in warehouses_gdf_sim.index}\n",
    "    \n",
    "    total_exceeded_minutes = 0\n",
    "\n",
    "    # Flatten the demand timestamps and associate them with their warehouses and distances\n",
    "    all_demands = []\n",
    "    for index, row in bevoelkerungs_gdf_sim.iterrows():\n",
    "        assigned_warehouse = row['assigned_warehouse']\n",
    "        distance_warehouse = row['distance_warehouse']\n",
    "        for timestamp in row['demand_timestamp']:\n",
    "            all_demands.append((assigned_warehouse, distance_warehouse, timestamp))\n",
    "    \n",
    "    # Sort all demands by timestamp\n",
    "    all_demands.sort(key=lambda x: x[2])\n",
    "    \n",
    "    def time_to_minutes(t):\n",
    "        \"\"\"Convert a time object to minutes since midnight.\"\"\"\n",
    "        return t.hour * 60 + t.minute\n",
    "    \n",
    "    def minutes_to_time(m):\n",
    "        \"\"\"Convert minutes since midnight to a time object.\"\"\"\n",
    "        return time(int(m // 60), int(m % 60))\n",
    "    \n",
    "    opening_start_minutes = time_to_minutes(opening_start_time)\n",
    "    opening_end_minutes = time_to_minutes(opening_end_time)\n",
    "    \n",
    "    # Process each demand\n",
    "    for assigned_warehouse, distance_warehouse, timestamp in all_demands:\n",
    "        \n",
    "        # Find the first available drone\n",
    "        available_drones = warehouse_drones[assigned_warehouse]\n",
    "        next_available_time = min(available_drones, key=time_to_minutes)\n",
    "        start_time = max(time_to_minutes(timestamp), time_to_minutes(next_available_time))  # Use start_time to calculate when the drone can actually start\n",
    "        \n",
    "        # Ensure start time is within opening hours\n",
    "        if start_time < opening_start_minutes:\n",
    "            start_time = opening_start_minutes\n",
    "        elif start_time > opening_end_minutes:\n",
    "            continue  # Skip demands outside of opening hours\n",
    "\n",
    "        # Calculate the delivery time\n",
    "        delivery_time = start_time + int(2 * distance_warehouse * 60 / drone_speed)  # Round trip time in minutes\n",
    "        \n",
    "        # Ensure delivery time is within opening hours\n",
    "        if delivery_time > opening_end_minutes:\n",
    "            continue  # Skip deliveries that cannot be completed within opening hours\n",
    "\n",
    "        # Check if the delivery time exceeds the time window\n",
    "        if (delivery_time - time_to_minutes(timestamp)) > time_window.total_seconds() / 60:\n",
    "            exceeded_minutes = (delivery_time - time_to_minutes(timestamp)) - (time_window.total_seconds() / 60)\n",
    "            total_exceeded_minutes += exceeded_minutes\n",
    "\n",
    "        # Update the next available time for the drone\n",
    "        return_trip_end_time = minutes_to_time(delivery_time)\n",
    "        available_drones[available_drones.index(next_available_time)] = return_trip_end_time\n",
    "\n",
    "    return total_exceeded_minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_trip_request_string(pharmacy_lon, pharmacy_lat, demands):\n",
    "    waypoints = f\"{pharmacy_lon},{pharmacy_lat}\"\n",
    "    for _, row in demands.iterrows():\n",
    "        waypoints += f\";{row.lon},{row.lat}\"\n",
    "    return f\"http://router.project-osrm.org/trip/v1/driving/{waypoints}?roundtrip=true&source=first&destination=last&overview=false&steps=false\"\n",
    "\n",
    "def calculate_total_distance_and_duration(demands, pharmacy_lon, pharmacy_lat, total_distance_sum, total_duration_sum, counter):\n",
    "    try:\n",
    "        request_string = build_trip_request_string(pharmacy_lon, pharmacy_lat, demands)\n",
    "        res = requests.get(request_string)\n",
    "        res.raise_for_status()  # Raise an exception for non-200 status codes\n",
    "\n",
    "        content = json.loads(res.content)\n",
    "\n",
    "        # Check if trips are available\n",
    "        if 'trips' in content and len(content['trips']) > 0:\n",
    "            trip = content['trips'][0]\n",
    "            total_distance = trip['distance']\n",
    "            total_duration = trip['duration']\n",
    "            return total_distance, total_duration\n",
    "        else:\n",
    "            #print(f\"No trips found for request {request_string}\")\n",
    "            return total_distance_sum/counter, total_duration_sum/counter\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        #print(f\"Error occurred on attempt for request {request_string}: {e}\")\n",
    "        return total_distance_sum/counter, total_duration_sum/counter\n",
    "\n",
    "def expand_timestamps(demands_df):\n",
    "    # Explode the DataFrame by demand_timestamp\n",
    "    demands_df = demands_df.explode('demand_timestamp')\n",
    "    demands_df['demand_timestamp'] = pd.to_datetime(demands_df['demand_timestamp'])\n",
    "    return demands_df\n",
    "\n",
    "def calculate_pharmacy_routing(demands_df, pharmacies_df):\n",
    "    # Expand the demands DataFrame so each timestamp is in its own row\n",
    "    demands_df = expand_timestamps(demands_df)\n",
    "\n",
    "    # Split demands into two DataFrames by half, grouped by assigned pharmacy\n",
    "    demands_df_groups = demands_df.groupby('assigned_pharmacy')\n",
    "    groups_list = list(demands_df_groups)\n",
    "    split_index = len(groups_list) // 2\n",
    "\n",
    "    # Split the DataFrame into two DataFrames\n",
    "    first_half_demands = pd.concat([group[1] for group in groups_list[:split_index]])\n",
    "    second_half_demands = pd.concat([group[1] for group in groups_list[split_index:]])\n",
    "    \n",
    "\n",
    "    # Group by assigned pharmacy and filter demands by time\n",
    "    before_13pm = first_half_demands[first_half_demands['demand_timestamp'].dt.hour < 13].drop_duplicates(subset=['lon', 'lat'])\n",
    "    after_13pm = first_half_demands[first_half_demands['demand_timestamp'].dt.hour >= 13].drop_duplicates(subset=['lon', 'lat'])\n",
    "\n",
    "    total_distance_sum = 0\n",
    "    total_duration_sum = 0\n",
    "    counter = 1\n",
    "\n",
    "    # Vectorized processing within each time period\n",
    "    for time_period, demands in [('before_13pm', before_13pm), ('after_13pm', after_13pm)]:\n",
    "        if demands.empty:\n",
    "            continue\n",
    "\n",
    "        grouped = demands.groupby('assigned_pharmacy')\n",
    "\n",
    "        for pharmacy_id, group in grouped:\n",
    "            pharmacy_info = pharmacies_df[pharmacies_df['id'] == pharmacy_id]\n",
    "\n",
    "            if pharmacy_info.empty:\n",
    "                print(f\"Pharmacy ID {pharmacy_id} not found in pharmacies dataframe.\")\n",
    "                continue\n",
    "\n",
    "            pharmacy_lon = pharmacy_info.lon.iloc[0]\n",
    "            pharmacy_lat = pharmacy_info.lat.iloc[0]\n",
    "\n",
    "            total_distance, total_duration = calculate_total_distance_and_duration(group, pharmacy_lon, pharmacy_lat, total_distance_sum, total_duration_sum, counter)\n",
    "            total_distance_sum += total_distance\n",
    "            total_duration_sum += total_duration\n",
    "            counter += 1\n",
    "            \n",
    "\n",
    "    \n",
    "    second_half_demands = second_half_demands.groupby('assigned_pharmacy')\n",
    "    for pharmacy_id, group in second_half_demands:\n",
    "        pharmacy_info = pharmacies_df[pharmacies_df['id'] == pharmacy_id]\n",
    "\n",
    "        if pharmacy_info.empty:\n",
    "            print(f\"Pharmacy ID {pharmacy_id} not found in pharmacies dataframe.\")\n",
    "            continue\n",
    "\n",
    "        pharmacy_lon = pharmacy_info.lon.iloc[0]\n",
    "        pharmacy_lat = pharmacy_info.lat.iloc[0]\n",
    "\n",
    "        total_distance, total_duration = calculate_total_distance_and_duration(group, pharmacy_lon, pharmacy_lat, total_distance_sum, total_duration_sum, counter)\n",
    "        total_distance_sum += total_distance\n",
    "        total_duration_sum += total_duration\n",
    "        counter += 1\n",
    "\n",
    "    return total_distance_sum / 1000, total_duration_sum / 60 #Meters to km, seconds to minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(opened_warehouses_run, bevölkerungs_gdf_run, warehouses_gdf_run, cost_per_km_drone, drone_speed, delivery_time, start_time, end_time, demand_factor, rent_factor, night_shift_dist, cost_per_km_car, cost_per_km_truck, factory_setup_costs, drone_initial_costs, sensitivity_run):\n",
    "\n",
    "    #Calculate the monthly fix costs due to drone and factory setup\n",
    "    rental_cost = (np.sum(warehouses_gdf_run.loc[opened_warehouses_run].floor_space_assigned * warehouses_gdf_run.loc[opened_warehouses_run].pricePerSquareMetre) / 12) * rent_factor\n",
    "    factory_setup_cost = (len(opened_warehouses_run) * factory_setup_costs) / 12\n",
    "    drone_setup_cost = (np.sum(warehouses_gdf_run.loc[opened_warehouses_run].number_of_drones) * drone_initial_costs) / 12 \n",
    "\n",
    "    drone_transportation_cost = 0\n",
    "    drone_transportation_time = 0\n",
    "    time_penalty_costs = 0\n",
    "    time_penalty_day = 0\n",
    "    avg_waiting_time = 0\n",
    "\n",
    "    car_transportation_cost_customer = 0\n",
    "    car_transportation_time_customer = 0\n",
    "\n",
    "    car_transportation_cost_pharmacy = 0\n",
    "    car_transportation_time_pharmacy = 0\n",
    "\n",
    "\n",
    "    tqdm.pandas()\n",
    "\n",
    "    #Loop der Simulation über ein gesamtes Jahr\n",
    "    for i in range(1):\n",
    "\n",
    "        print(f'Simulation - Tag: {i + 1}')\n",
    "        \n",
    "        \n",
    "        bevölkerungs_gdf_run['nachfrage'] = 0\n",
    "        bevölkerungs_gdf_run['nachfrage'] = bevölkerungs_gdf_run.progress_apply(calculate_demand_sim, axis=1, demand_factor = demand_factor)\n",
    "        bevölkerungs_gdf_run['demand_timestamp'] = bevölkerungs_gdf_run.progress_apply(lambda row: assign_random_timestamp(row, night_shift_dist, start_time, end_time), axis=1)\n",
    "\n",
    "        # Calculate transportation costs and time using vectorized operations\n",
    "        drone_transportation_cost += np.sum(bevölkerungs_gdf_run['nachfrage'] * bevölkerungs_gdf_run['distance_warehouse'] * cost_per_km_drone * 2)\n",
    "        drone_transportation_time += np.sum((bevölkerungs_gdf_run['nachfrage'] * bevölkerungs_gdf_run['distance_warehouse']) / drone_speed )\n",
    "        time_penalty_day = calculate_penalty_costs(bevölkerungs_gdf_run, warehouses_gdf_run, drone_speed, delivery_time, start_time, end_time)\n",
    "        time_penalty_costs += time_penalty_day\n",
    "        avg_waiting_time = (avg_waiting_time + time_penalty_day / np.sum(bevölkerungs_gdf_run['nachfrage'])) / (i+1)\n",
    "\n",
    "        if not sensitivity_run:\n",
    "            car_transportation_cost_customer += np.sum(bevölkerungs_gdf_run['nachfrage'] * bevölkerungs_gdf_run['distance_pharmacy'] * cost_per_km_car * 2)\n",
    "            car_transportation_time_customer += np.sum(bevölkerungs_gdf_run['nachfrage'] * bevölkerungs_gdf_run['time_pharmacy'])\n",
    "\n",
    "            car_transportation_cost_pharmacy_temp, car_transportation_time_pharmacy_temp = calculate_pharmacy_routing(bevölkerungs_gdf_run[bevölkerungs_gdf_run['nachfrage'] > 0], pharmacy_gdf)\n",
    "            car_transportation_cost_pharmacy += car_transportation_cost_pharmacy_temp * cost_per_km_truck + bevölkerungs_gdf_run['distance_pharmacy'].median() * cost_per_km_truck\n",
    "            car_transportation_time_pharmacy += car_transportation_time_pharmacy_temp\n",
    "\n",
    "        # Reset the timestamps\n",
    "        bevölkerungs_gdf_run = bevölkerungs_gdf_run.drop('demand_timestamp', axis=1, inplace=True)\n",
    "\n",
    "    return [rental_cost, factory_setup_cost, drone_setup_cost, drone_transportation_cost, drone_transportation_time, time_penalty_costs, avg_waiting_time, car_transportation_cost_customer, car_transportation_time_customer, car_transportation_cost_pharmacy, car_transportation_time_pharmacy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cost_summary(costs):\n",
    "\n",
    "  print(\"-\" * 50)\n",
    "  print(\"Logistical Cost Summary (per year):\")\n",
    "  print(\"-\" * 50)\n",
    "  print(f\"Factory Rental Cost: \\t\\t\\t€{costs[0]:.2f}\")\n",
    "  print(f\"Factory Setup Cost: \\t\\t\\t€{costs[1]:.2f}\")\n",
    "  print(f\"Drone Setup Cost: \\t\\t\\t€{costs[2]:.2f}\")\n",
    "  print(\"-\" * 50)\n",
    "  print(f\"Drone Transportation Cost: \\t\\t€{costs[3]:.2f}\")\n",
    "  print(f\"Drone Transportation Time: \\t\\t€{costs[4]/60:.2f} hours\")\n",
    "  print(f\"Transportation Penalty Time: \\t\\t{costs[5]:.2f}\")\n",
    "  print(f\"Transportation Avg Waiting Time: \\t{costs[6]:.2f}\")\n",
    "  print(\"-\" * 50)\n",
    "  print(f\"Car/Truck Customer Transportation Cost: €{costs[7]:.2f}\")\n",
    "  print(f\"Car/Truck Customer Transportation Time: {costs[8]/60:.2f} hours\")\n",
    "  print(\"-\" * 50)\n",
    "  print(f\"Car/Truck Pharmacy Transportation Cost: €{costs[9]:.2f}\")\n",
    "  print(f\"Car/Truck Pharmacy Transportation Time: {costs[10]/60:.2f} hours\")\n",
    "  print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robustheit / Parameter Changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_times(minutes):\n",
    "  start_time = time(hour=8, minute=0) # Set initial start time to 8:00 AM\n",
    "  total_minutes = (start_time.hour * 60 + start_time.minute) + minutes # Convert minutes to total number of minutes\n",
    "  end_time = time(hour=total_minutes // 60 % 24, minute=total_minutes % 60)   # Calculate end time by handling overflow within 24 hours\n",
    "\n",
    "  # Adjust start time if end time is before start time (overflow)\n",
    "  if end_time < start_time:\n",
    "    # Calculate the adjustment needed (difference in minutes)\n",
    "    if start_time.minute > end_time.minute:\n",
    "      start_time = time(start_time.hour - end_time.hour, start_time.minute - end_time.minute)\n",
    "    else:\n",
    "      start_time = time(start_time.hour - end_time.hour -1, 60 - end_time.minute)\n",
    "    end_time = time(23,59,59)\n",
    "\n",
    "  return start_time, end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(parameter_values, bevölkerungs_gdf_run, warehouses_gdf_run, customers_gdf_run, shifts_df_run, optimal_run, city, opened_warehouses_optimal, sensitivity_run):\n",
    "\n",
    "    # Drone Parameters\n",
    "    cost_per_km_drone = parameter_values['kwh_eur'] * parameter_values['watt_drone']  # EUR/km # Calculate cost per kilometer for the drone\n",
    "    # Car/Truck Parameters:\n",
    "    cost_per_km_car = 0.38\n",
    "    cost_per_km_truck = 2\n",
    "\n",
    "    W = warehouses_gdf_run.index.values\n",
    "    R = customers_gdf_run.index.values\n",
    "    S = shifts_df_run.index.values\n",
    "    \n",
    "    if optimal_run:\n",
    "        # Set the optimization problem\n",
    "        solver, x, y, z, d = optimize(\n",
    "            W = W, \n",
    "            R = R,\n",
    "            S = S, \n",
    "            warehouses_gdf_run = warehouses_gdf_run,\n",
    "            cost_per_km_drone = cost_per_km_drone,\n",
    "            factory_setup_costs = parameter_values['factory_setup_costs'],\n",
    "            qm_per_customer = parameter_values['qm_per_customer'],\n",
    "            qm_per_drone = parameter_values['qm_per_drone'],\n",
    "            minimum_square_requirement = parameter_values['minimum_square_requirement'],\n",
    "            rent_factor = parameter_values['rent_factor'],\n",
    "            max_flight_distance = parameter_values['max_flight_distance'],\n",
    "            drone_initial_costs = parameter_values['drone_initial_costs'],\n",
    "            drone_speed = parameter_values['drone_speed'],\n",
    "            time_window = parameter_values['time_window'],\n",
    "            alpha_drones = parameter_values['alpha'],\n",
    "            delivery_time = parameter_values['delivery_time'],\n",
    "            night_shift_dist = parameter_values['night_shift_dist']\n",
    "            )\n",
    "\n",
    "        print('Solver set up!')\n",
    "\n",
    "        # Solve the problem and get the solution\n",
    "        opened_warehouses, customers_gdf_run, warehouses_gdf_run = solve(\n",
    "            W = W,\n",
    "            R = R, \n",
    "            solver = solver, \n",
    "            x = x, \n",
    "            y = y, \n",
    "            z = z, \n",
    "            d = d, \n",
    "            customers_gdf_run = customers_gdf_run, \n",
    "            warehouses_gdf_run = warehouses_gdf_run)\n",
    "        \n",
    "        # Assign the in the solution chosen warehouses in the dataset\n",
    "        bevölkerungs_gdf_run = assign_warehouses(bevölkerungs_gdf_run, customers_gdf_run)\n",
    "        print('Dataset set up!')\n",
    "\n",
    "    \n",
    "    if not optimal_run: \n",
    "        opened_warehouses = opened_warehouses_optimal\n",
    "\n",
    "    # Get the start and end time of the service hours\n",
    "    start_time, end_time = calculate_times(minutes=parameter_values['time_window'])\n",
    "\n",
    "\n",
    "\n",
    "    # Simulate with optimal values\n",
    "    costs = simulate(\n",
    "        opened_warehouses_run = opened_warehouses, \n",
    "        bevölkerungs_gdf_run = bevölkerungs_gdf_run, \n",
    "        warehouses_gdf_run = warehouses_gdf_run, \n",
    "        cost_per_km_drone = cost_per_km_drone,\n",
    "        start_time = start_time,\n",
    "        end_time = end_time,\n",
    "        demand_factor = parameter_values['demand_factor'],\n",
    "        rent_factor = parameter_values['rent_factor'],\n",
    "        drone_speed = parameter_values['drone_speed'],\n",
    "        delivery_time = parameter_values['delivery_time'],\n",
    "        night_shift_dist = parameter_values['night_shift_dist'],\n",
    "        cost_per_km_car = cost_per_km_car,\n",
    "        cost_per_km_truck = cost_per_km_truck,\n",
    "        factory_setup_costs = parameter_values['factory_setup_costs'],\n",
    "        drone_initial_costs = parameter_values['drone_initial_costs'],\n",
    "        sensitivity_run = sensitivity_run) \n",
    "    print('Simulation done!')\n",
    "\n",
    "    print_cost_summary(costs = costs)\n",
    "\n",
    "\n",
    "    if optimal_run:\n",
    "        if not sensitivity_run:\n",
    "            customers_gdf_run['Alter'] = customers_gdf_run['Alter'].apply(json.dumps)\n",
    "            customers_gdf_run.to_file(f'./Results/Optimal_Results_customers_{city}.gpkg', driver = 'GPKG')\n",
    "\n",
    "            bevölkerungs_gdf_run['Alter'] = bevölkerungs_gdf_run['Alter'].apply(json.dumps)\n",
    "            bevölkerungs_gdf_run['Geschlecht'] = bevölkerungs_gdf_run['Geschlecht'].apply(json.dumps)\n",
    "            bevölkerungs_gdf_run.to_file(f'./Results/Optimal_Results_bevoelkerung_{city}.gpkg', driver = 'GPKG')\n",
    "\n",
    "    \n",
    "            warehouses_gdf_run.to_file(f'./Results/Optimal_Results_warehouses_{city}.gpkg', driver = 'GPKG')\n",
    "\n",
    "        return {\n",
    "                'opened_warehouses': np.array(opened_warehouses),\n",
    "                'number_of_drones': np.sum(warehouses_gdf_run.loc[opened_warehouses].number_of_drones),\n",
    "                'floor_space_assigned': np.sum(warehouses_gdf_run.loc[opened_warehouses].floor_space_assigned),\n",
    "                'objective_value': solver.Objective().Value(),\n",
    "                'Factory Rental Cost': costs[0],\n",
    "                'Factory Setup Cost': costs[1],\n",
    "                'Drone Setup Cost': costs[2],\n",
    "                'Drone Transportation Cost': costs[3],\n",
    "                'Drone Transportation Time': costs[4],\n",
    "                'Transportation Penalty Cost': costs[5],\n",
    "                'Transportation Avg Waiting Time': costs[6],\n",
    "                'Car/Truck Customer Transportation Cost': costs[7],\n",
    "                'Car/Truck Customer Transportation Time': costs[8],\n",
    "                'Car/Truck Pharmacy Transportation Cost': costs[9],\n",
    "                'Car/Truck Pharmacy Transportation Time': costs[10]\n",
    "                }\n",
    "    return {\n",
    "        'opened_warehouses': np.array(opened_warehouses_optimal),\n",
    "        'number_of_drones': np.sum(warehouses_gdf_run.loc[opened_warehouses_optimal].number_of_drones),\n",
    "        'floor_space_assigned': np.sum(warehouses_gdf_run.loc[opened_warehouses_optimal].floor_space_assigned),\n",
    "        'Factory Rental Cost': costs[0],\n",
    "        'Factory Setup Cost': costs[1],\n",
    "        'Drone Setup Cost': costs[2],\n",
    "        'Drone Transportation Cost': costs[3],\n",
    "        'Drone Transportation Time': costs[4],\n",
    "        'Transportation Penalty Cost': costs[5],\n",
    "        'Transportation Avg Waiting Time': costs[6],\n",
    "        'Car/Truck Customer Transportation Cost': costs[7],\n",
    "        'Car/Truck Customer Transportation Time': costs[8],\n",
    "        'Car/Truck Pharmacy Transportation Cost': costs[9],\n",
    "        'Car/Truck Pharmacy Transportation Time': costs[10]\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity_analysis(parameter_values, number_of_runs, sensitivity_index, parameter_names, optimal_run, sensitivity_run, bevölkerungs_gdf_run, warehouses_gdf_run, customers_gdf_run, shifts_df_run, opened_warehouses_optimal, warehouses_gdf_optimal, customers_gdf_optimal, bevölkerungs_gdf_optimal, city):\n",
    "    \n",
    "    if sensitivity_index != 'None':\n",
    "        triangular_values = np.random.triangular(parameter_values[sensitivity_index][0], parameter_values[sensitivity_index][1], parameter_values[sensitivity_index][2], number_of_runs)\n",
    "\n",
    "\n",
    "    result_list = []\n",
    "\n",
    "    for i in range(number_of_runs):\n",
    "    \n",
    "        if sensitivity_index != 'None':\n",
    "            parameter_values[sensitivity_index][1] = triangular_values[i]\n",
    "\n",
    "        base_values = [param[1] for param in parameter_values]\n",
    "\n",
    "        # Set the demand in case of demand_factor\n",
    "        customers_gdf_run_demand = customers_gdf_run.copy()\n",
    "        customers_gdf_run_demand['nachfrage'] = customers_gdf_run_demand['nachfrage'] * base_values[11]\n",
    "\n",
    "        base_dict = {\n",
    "            'factory_setup_costs': base_values[0],\n",
    "            'qm_per_customer': base_values[1],\n",
    "            'qm_per_drone': base_values[2],\n",
    "            'minimum_square_requirement': base_values[3],\n",
    "            'rent_factor': base_values[4],\n",
    "            'max_flight_distance': base_values[5],\n",
    "            'drone_initial_costs': base_values[6],\n",
    "            'drone_speed': base_values[7],\n",
    "            'time_window': base_values[8],\n",
    "            'delivery_time': base_values[9],\n",
    "            'alpha': base_values[10],\n",
    "            'night_shift_dist': base_values[11],\n",
    "            'demand_factor': base_values[12],\n",
    "            'watt_drone': base_values[13],\n",
    "            'kwh_eur': base_values[14]\n",
    "            }\n",
    "\n",
    "        if optimal_run:\n",
    "            results = run(\n",
    "                parameter_values = base_dict, \n",
    "                bevölkerungs_gdf_run = bevölkerungs_gdf_run, \n",
    "                warehouses_gdf_run = warehouses_gdf_run, \n",
    "                customers_gdf_run = customers_gdf_run_demand, \n",
    "                shifts_df_run = shifts_df_run, \n",
    "                optimal_run = True,\n",
    "                opened_warehouses_optimal = None,\n",
    "                city = city,\n",
    "                sensitivity_run = False\n",
    "                )\n",
    "        \n",
    "        else: \n",
    "            results_new_optimal = run(\n",
    "                parameter_values = base_dict, \n",
    "                bevölkerungs_gdf_run = bevölkerungs_gdf_run, \n",
    "                warehouses_gdf_run = warehouses_gdf_run, \n",
    "                customers_gdf_run = customers_gdf_run_demand, \n",
    "                shifts_df_run = shifts_df_run, \n",
    "                optimal_run = True, \n",
    "                opened_warehouses_optimal = opened_warehouses_optimal,\n",
    "                city = city,\n",
    "                sensitivity_run = sensitivity_run\n",
    "                )\n",
    "            \n",
    "            results_old_optimal = run(\n",
    "                    parameter_values = base_dict, \n",
    "                    bevölkerungs_gdf_run = bevölkerungs_gdf_optimal, \n",
    "                    warehouses_gdf_run = warehouses_gdf_optimal, \n",
    "                    customers_gdf_run = customers_gdf_optimal, \n",
    "                    shifts_df_run = shifts_df_run, \n",
    "                    optimal_run = False, \n",
    "                    opened_warehouses_optimal = opened_warehouses_optimal,\n",
    "                    city = city,\n",
    "                    sensitivity_run = sensitivity_run\n",
    "                    )\n",
    "        \n",
    "        if optimal_run:\n",
    "            result_list.append({\n",
    "                'parameter': 'Base Value',\n",
    "                'parameter_value': 'Base_Value',\n",
    "                'results': results\n",
    "            })\n",
    "  \n",
    "        else: \n",
    "            result_list.append({\n",
    "                'parameter': parameter_names[sensitivity_index],\n",
    "                'parameter_value': triangular_values[i],\n",
    "                'results_old_optimal': results_old_optimal,\n",
    "                'results_new_optimal': results_new_optimal\n",
    "            })\n",
    "\n",
    "    \n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min_travel_distance(shifts_df):\n",
    "    # Initialize variables\n",
    "    min_distance = 0\n",
    "    max_distance = shifts_df['travel_distance'].max()\n",
    "    shifts_df.reset_index(inplace=True)\n",
    "\n",
    "    while min_distance <= max_distance:\n",
    "\n",
    "        current_distance = min_distance + 0.1\n",
    "\n",
    "        # Assuming 'node_a' and 'node_b' are columns containing node IDs, and 'distance' is the distance column\n",
    "        filtered_data = shifts_df[shifts_df['travel_distance'] < current_distance]\n",
    "\n",
    "        all_regions = shifts_df.region_id.unique()\n",
    "        filtered_regions = filtered_data.region_id.unique()  \n",
    "        region_present = set(all_regions).issubset(set(filtered_regions))\n",
    "\n",
    "        if region_present:\n",
    "            break\n",
    "        else:\n",
    "            min_distance = current_distance  # Update min distance if condition not met\n",
    "\n",
    "    shifts_df.set_index(['warehouse_id', 'region_id'], inplace=True)\n",
    "    return min_distance  # Minimum distance found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_names = [\n",
    "    \"factory_setup_costs\",\n",
    "    \"qm_per_customer\",\n",
    "    \"qm_per_drone\",\n",
    "    \"minimum_square_requirement\",\n",
    "    \"rent_factor\",\n",
    "    \"max_flight_distance\",\n",
    "    \"drone_initial_costs\",\n",
    "    \"drone_speed\",\n",
    "    \"time_window\",\n",
    "    \"delivery_time\",\n",
    "    \"alpha\",\n",
    "    \"night_shift_dist\",\n",
    "    \"demand_factor\",\n",
    "    \"watt_drone\",\n",
    "    \"kwh_eur\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_energy, q1_kwh_eur, q2_kwh_eur, q3_kwh_eur = load_energy_costs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_parameters(shifts_df): \n",
    "    base_factory_setup_costs = 250000 #Eur\n",
    "    min_factory_setup_costs = 100000 # Set an appropriate value\n",
    "    max_factory_setup_costs = 500000 # Set an appropriate value\n",
    "\n",
    "    base_qm_per_customer = 0.25 #Quadratmeter\n",
    "    min_qm_per_customer = 0.1 # Set an appropriate value\n",
    "    max_qm_per_customer = 0.5 # Set an appropriate value\n",
    "\n",
    "    base_qm_per_drone = 2 #Quadratmeter\n",
    "    min_qm_per_drone = 1 # Set an appropriate value\n",
    "    max_qm_per_drone = 3 # Set an appropriate value\n",
    "\n",
    "    base_minimum_square_requirement = 100 #Quadratmeter\n",
    "    min_minimum_square_requirement = 50 # Set an appropriate value\n",
    "    max_minimum_square_requirement = 150 # Set an appropriate value\n",
    "\n",
    "    base_rent_factor = 1 #Prozent\n",
    "    min_rent_factor = 0.5 # Set an appropriate value\n",
    "    max_rent_factor = 1.5 # Set an appropriate value\n",
    "\n",
    "    base_max_flight_distance = 25 #km\n",
    "    min_max_flight_distance = find_min_travel_distance(shifts_df=shifts_df) # Set an appropriate value\n",
    "    max_max_flight_distance = 40 # Set an appropriate value\n",
    "\n",
    "    base_drone_initial_costs = 4000 #Eur\n",
    "    min_drone_initial_costs = 2000 # Set an appropriate value\n",
    "    max_drone_initial_costs = 6000 # Set an appropriate value\n",
    "\n",
    "    base_drone_speed = 65/60 #km/h/60 = km/min\n",
    "    min_drone_speed = 50/60 # Set an appropriate value\n",
    "    max_drone_speed = 80/60 # Set an appropriate value\n",
    "\n",
    "    base_time_window = 630 #Min\n",
    "    min_time_window = 60 # Set an appropriate value\n",
    "    max_time_window = 1439 # Set an appropriate value\n",
    "\n",
    "    base_delivery_time = 60 #Min\n",
    "    min_delivery_time = 30\n",
    "    max_delivery_time = 90\n",
    "\n",
    "    base_alpha = 0.3\n",
    "    min_alpha = 0.15\n",
    "    max_alpha = 0.45\n",
    "\n",
    "    base_night_shift_dist = 0.00100142348 #Prozent\n",
    "    min_night_shift_dist = 0.000750711742 # Set an appropriate value\n",
    "    max_night_shift_dist = 0.001251778735 # Set an appropriate value\n",
    "\n",
    "    base_demand_factor = 1 #Prozent\n",
    "    min_demand_factor = 0.5 # Set an appropriate value\n",
    "    max_demand_factor = 1.5 # Set an appropriate value\n",
    "\n",
    "    base_watt_drone = 0.3 #Kw\n",
    "    min_watt_drone = 0.15 # Set an appropriate value\n",
    "    max_watt_drone = 0.45 # Set an appropriate value\n",
    "\n",
    "    base_kwh_eur = 0.4175\n",
    "    min_kwh_eur = 0.313125\n",
    "    max_kwh_eur = 0.521875\n",
    "\n",
    "    parameter_values = [\n",
    "    [min_factory_setup_costs, base_factory_setup_costs, max_factory_setup_costs],\n",
    "    [min_qm_per_customer, base_qm_per_customer, max_qm_per_customer],\n",
    "    [min_qm_per_drone, base_qm_per_drone, max_qm_per_drone],\n",
    "    [min_minimum_square_requirement, base_minimum_square_requirement, max_minimum_square_requirement],\n",
    "    [min_rent_factor, base_rent_factor, max_rent_factor],\n",
    "    [min_max_flight_distance, base_max_flight_distance, max_max_flight_distance],\n",
    "    [min_drone_initial_costs, base_drone_initial_costs, max_drone_initial_costs],\n",
    "    [min_drone_speed, base_drone_speed, max_drone_speed],\n",
    "    [min_time_window, base_time_window, max_time_window],\n",
    "    [min_delivery_time, base_delivery_time, max_delivery_time],\n",
    "    [min_alpha, base_alpha, max_alpha],\n",
    "    [min_night_shift_dist, base_night_shift_dist, max_night_shift_dist],\n",
    "    [min_demand_factor, base_demand_factor, max_demand_factor],\n",
    "    [min_watt_drone, base_watt_drone, max_watt_drone],\n",
    "    [min_kwh_eur, base_kwh_eur, max_kwh_eur]\n",
    "    ]\n",
    "    return parameter_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_run_results = []\n",
    "folder = ['Wuerzburg_Data', 'Donner_Data', 'Frankfurt_Data']\n",
    "city = ['wuerzburg', 'donner', 'frankfurt']\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "    customers_gdf = setup_customer_data(folder[i], city[i])\n",
    "    geo_würzburg, bevölkerungs_gdf, pharmacy_gdf, warehouses_gdf, shifts_df = load_data(customers_gdf, folder[i], city[i])\n",
    "\n",
    "    parameter_values = setup_parameters(shifts_df=shifts_df)\n",
    "\n",
    "    optimal_run_results.append({\n",
    "        'result_list': sensitivity_analysis(\n",
    "                            parameter_values = parameter_values, \n",
    "                            number_of_runs = 1, \n",
    "                            sensitivity_index = 'None', \n",
    "                            parameter_names = parameter_names, \n",
    "                            optimal_run = True,\n",
    "                            sensitivity_run = False,\n",
    "                            bevölkerungs_gdf_run = bevölkerungs_gdf,\n",
    "                            warehouses_gdf_run = warehouses_gdf,\n",
    "                            customers_gdf_run = customers_gdf,\n",
    "                            shifts_df_run = shifts_df,\n",
    "                            city = city[i],\n",
    "                            opened_warehouses_optimal = None,\n",
    "                            warehouses_gdf_optimal = None,\n",
    "                            customers_gdf_optimal = None,\n",
    "                            bevölkerungs_gdf_optimal = None\n",
    "                            ),\n",
    "        'city': city[i]\n",
    "    })\n",
    "\n",
    "    with open(f'./Results/optimal_run_results.pkl', 'wb') as outfile:\n",
    "        pickle.dump(optimal_run_results, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_run_results = []\n",
    "folder = ['Wuerzburg_Data', 'Donner_Data', 'Frankfurt_Data']\n",
    "city = ['wuerzburg', 'donner', 'frankfurt']\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "    customers_gdf = setup_customer_data(folder[i], city[i])\n",
    "    geo_würzburg, bevölkerungs_gdf, pharmacy_gdf, warehouses_gdf, shifts_df = load_data(customers_gdf, folder[i], city[i])\n",
    "    \n",
    "    with open('./Results/optimal_run_results.pkl', 'rb') as infile:\n",
    "        optimal_result = pickle.load(infile)\n",
    "        opened_warehouses = optimal_result[i]['result_list'][0]['results']['opened_warehouses']\n",
    "\n",
    "    parameter_values = setup_parameters(shifts_df=shifts_df)\n",
    "\n",
    "    customers_gdf_optimal = gpd.read_file(f'./Results/Optimal_Results_customers_{city[i]}.gpkg')\n",
    "    customers_gdf_optimal['Alter'] = customers_gdf_optimal['Alter'].apply(json.loads)\n",
    "\n",
    "    warehouses_gdf_optimal = gpd.read_file(f'./Results/Optimal_Results_warehouses_{city[i]}.gpkg')\n",
    "\n",
    "    bevölkerungs_gdf_optimal = gpd.read_file(f'./Results/Optimal_Results_bevoelkerung_{city[i]}.gpkg')\n",
    "    bevölkerungs_gdf_optimal['Alter'] = bevölkerungs_gdf_optimal['Alter'].apply(json.loads)\n",
    "    bevölkerungs_gdf_optimal['Geschlecht'] = bevölkerungs_gdf_optimal['Geschlecht'].apply(json.loads)\n",
    "    \n",
    "    for i in range(len(parameter_values)):    \n",
    "        optimal_run_results.append({\n",
    "            'result_list': sensitivity_analysis(\n",
    "                                parameter_values = parameter_values, \n",
    "                                number_of_runs = 2, \n",
    "                                sensitivity_index = i, \n",
    "                                parameter_names = parameter_names, \n",
    "                                optimal_run = False,\n",
    "                                sensitivity_run = True,\n",
    "                                bevölkerungs_gdf_run = bevölkerungs_gdf,\n",
    "                                warehouses_gdf_run = warehouses_gdf,\n",
    "                                customers_gdf_run = customers_gdf,\n",
    "                                shifts_df_run = shifts_df,\n",
    "                                city = city[i],\n",
    "                                opened_warehouses_optimal = opened_warehouses,\n",
    "                                customers_gdf_optimal = customers_gdf_optimal,\n",
    "                                warehouses_gdf_optimal = warehouses_gdf_optimal, \n",
    "                                bevölkerungs_gdf_optimal = bevölkerungs_gdf_optimal  \n",
    "                                ),\n",
    "            'city': city[i]\n",
    "        })\n",
    "\n",
    "        with open('./Results/sensitivity_results.pkl', 'wb') as outfile:\n",
    "            pickle.dump(optimal_run_results, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results.pkl', 'rb') as infile:\n",
    "  loaded_data = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data[0]['result_list'][0]['results']['opened_warehouses']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## datafix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = gpd.read_file('./Wuerzburg_Data/pharmacy_assigned_complete.gpkg')\n",
    "test1['Alter'] = test1['Alter'].apply(json.loads)\n",
    "test1['Geschlecht'] = test1['Geschlecht'].apply(json.loads)\n",
    "\n",
    "test2 = gpd.read_file('./Donner_Data/pharmacy_assigned_complete.gpkg')\n",
    "test2['Alter'] = test2['Alter'].apply(json.loads)\n",
    "test2['Geschlecht'] = test2['Geschlecht'].apply(json.loads)\n",
    "\n",
    "test3 = gpd.read_file('./Frankfurt_Data/pharmacy_assigned_complete.gpkg')\n",
    "test3['Alter'] = test3['Alter'].apply(json.loads)\n",
    "test3['Geschlecht'] = test3['Geschlecht'].apply(json.loads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test3 = gpd.read_file('./Results/Optimal_Results_bevoelkerung_donner.gpkg')\n",
    "test3['Alter'] = test3['Alter'].apply(json.loads)\n",
    "test3['Geschlecht'] = test3['Geschlecht'].apply(json.loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = gpd.read_file('./Results/Optimal_Results_customers_donner.gpkg')\n",
    "test2['Alter'] = test2['Alter'].apply(json.loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Results/optimal_run_results.pkl', 'rb') as infile:\n",
    "    optimal_result = pickle.load(infile)\n",
    "    opened_warehouses = optimal_result[1]['result_list'][0]['results']['opened_warehouses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = gpd.read_file('./Results/Optimal_Results_warehouses_donner.gpkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = simulate(opened_warehouses_run=opened_warehouses,\n",
    "         bevölkerungs_gdf_run=test3,\n",
    "         warehouses_gdf_run=test,\n",
    "         cost_per_km_drone=0.03,\n",
    "         drone_speed=1,\n",
    "         delivery_time=60,\n",
    "         start_time=time(8,0),\n",
    "         end_time = time(18,30),\n",
    "         demand_factor=1,\n",
    "         rent_factor=1,\n",
    "         night_shift_dist=0.0001,\n",
    "         cost_per_km_car=0.38,\n",
    "         cost_per_km_truck=2,\n",
    "         factory_setup_costs=10000,\n",
    "         drone_initial_costs=4000,\n",
    "         sensitivity_run=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cost_summary(costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(test['number_of_drones'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(test3['nachfrage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(test2['nachfrage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6127 * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangular_values = np.random.triangular(10, 15, 20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangular_values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## energy_costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get('https://api.corrently.io/v2.0/gsi/marketdata?zip=97072')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = json.loads(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the response data is stored in a variable called 'response_data'\n",
    "\n",
    "# Extract market prices\n",
    "market_prices = [item['localprice'] for item in content['data']]\n",
    "\n",
    "# Sort the market prices\n",
    "sorted_prices = sorted(market_prices)\n",
    "\n",
    "# Calculate the number of data points\n",
    "num_prices = len(sorted_prices)\n",
    "\n",
    "# Calculate median position\n",
    "median_pos = (num_prices + 1) // 2\n",
    "\n",
    "# Access the median value\n",
    "median = sorted_prices[median_pos - 1] / 1000\n",
    "\n",
    "# Calculate quartile positions (rounded down)\n",
    "q1_pos = (num_prices + 1) // 4\n",
    "q3_pos = 3 * (num_prices + 1) // 4\n",
    "\n",
    "# Access the quartile values\n",
    "q1 = sorted_prices[q1_pos - 1] / 1000\n",
    "q3 = sorted_prices[q3_pos - 1] / 1000\n",
    "\n",
    "# Print the results\n",
    "print(\"Median market price:\", median, \"Eur/MWh\")\n",
    "print(\"25th percentile (Q1):\", q1, \"Eur/MWh\")\n",
    "print(\"75th percentile (Q3):\", q3, \"Eur/MWh\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterarbeit_python311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
