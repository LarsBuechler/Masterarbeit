{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import geohash2\n",
    "import pyproj\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Immoscout mit Selenium aufrufen und Daten scrapen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste der Bundesländer und Regionen\n",
    "bundesland = [\n",
    "    'rheinland-pfalz'\n",
    "    #'bayern',\n",
    "    #'hessen'\n",
    "]\n",
    "\n",
    "region = [\n",
    "    'donnersbergkreis'\n",
    "    #'wuerzburg-kreis',\n",
    "    #'wuerzburg'\n",
    "    #'frankfurt-am-main'\n",
    "]\n",
    "\n",
    "# URL für ImmobilienScout24 zur Miete von Produktionshallen\n",
    "url = 'https://www.immobilienscout24.de/gewerbe-flaechen/de/' + bundesland[0] + '/' + region[0] + '/hallenproduktion-mieten/'\n",
    "\n",
    "# Starten des Chrome-Drivers mit Selenium\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Navigieren zur URL und manuelles Lösen des Captchas\n",
    "driver.get(url)\n",
    "input(\"Bitte lösen Sie das Captcha und drücken Sie Enter, um fortzufahren...\")\n",
    "\n",
    "# Extrahieren des HTML-Inhalts der Seite\n",
    "html_content = driver.page_source\n",
    "\n",
    "# Schließen des Chrome-Drivers\n",
    "driver.quit()\n",
    "\n",
    "# Verarbeiten des HTML-Inhalts mit BeautifulSoup\n",
    "soup = BeautifulSoup(html_content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relevante Daten mit BeautifulSoup filtern und laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finden und Extrahieren von Skript-Tags aus dem HTML-Inhalt\n",
    "script_tags = soup.find_all('script')\n",
    "\n",
    "# Durchsuchen der Skript-Tags nach dem relevanten Inhalt\n",
    "for script_tag in script_tags:\n",
    "    script_content = script_tag.string\n",
    "    if script_content and 'tilesResult' in script_content:\n",
    "        tiles_result_content = script_content\n",
    "        break\n",
    "\n",
    "# Überprüfen, ob der Inhalt des tilesResult-Objekts gefunden wurde\n",
    "if tiles_result_content:\n",
    "    start_index = tiles_result_content.find('{', tiles_result_content.find('tilesResult')) + 10\n",
    "    end_index = tiles_result_content.find('numberOfHits') + len('numberOfHits') - 18\n",
    "    tiles_result_data = tiles_result_content[start_index:end_index]\n",
    "    \n",
    "    # Ersetzen von Zeichenfolgen, um JSON-kompatiblen Inhalt zu erhalten\n",
    "    json_content = re.sub(r'\"[^\"]*\"', lambda m: m.group(0).replace(':', ''), tiles_result_data)\n",
    "    json_content = re.sub(r'(\\w+):', r'\"\\1\":', json_content)\n",
    "    \n",
    "    # Erstellen eines DataFrames aus dem JSON-Inhalt\n",
    "    df_json = pd.read_json(json_content)\n",
    "    \n",
    "    # Normalisieren der JSON-Daten und Erstellen eines DataFrames\n",
    "    exposes_df = pd.concat([pd.json_normalize(exp) for exp in df_json['exposes']], ignore_index=True)\n",
    "else:\n",
    "    print(\"No tilesResult content found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exposes_df.to_csv('./Immobilien_Data/Wuerzburg.csv', index=False)\n",
    "warehouse_data = exposes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Die Geodaten transformieren und in einen GeoDataframe laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zur Umwandlung eines Geohash in das Koordinatensystem CSR3035\n",
    "def geohash_to_csr3035(geohash):\n",
    "    # Dekodierung des Geohash in Breitengrad und Längengrad\n",
    "    lat, lon = geohash2.decode(geohash)\n",
    "    # Definition der Koordinatensysteme WGS84 und CSR3035\n",
    "    wgs84 = pyproj.Proj(init='epsg:4326')\n",
    "    csr3035 = pyproj.Proj(init='epsg:3035')\n",
    "    # Umwandlung der Koordinaten von WGS84 nach CSR3035\n",
    "    x_csr3035, y_csr3035 = pyproj.transform(wgs84, csr3035, lon, lat)\n",
    "    return x_csr3035, y_csr3035\n",
    "\n",
    "# Funktion zur Umwandlung eines Preisstrings in einen Float-Wert\n",
    "def convert_price_string_to_float(price_string):\n",
    "    # Entfernen von nicht-numerischen Zeichen\n",
    "    numeric_part = re.sub(r\"[^\\d,.]\", \"\", price_string)\n",
    "    # Ersetzen von Komma durch Punkt\n",
    "    numeric_part = numeric_part.replace(\",\", \".\")\n",
    "    # Umwandlung in einen Float-Wert\n",
    "    return float(numeric_part)\n",
    "\n",
    "# Funktion zur Extraktion des größten Float-Werts aus einem Bereichsstring\n",
    "def extract_largest_float(area_string):\n",
    "    # Entfernen von nicht-numerischen Zeichen und Aufteilen des Strings in Teile\n",
    "    area_parts = re.sub(r\"[^\\d\\-\\s]\", \"\", area_string).split()\n",
    "\n",
    "    # Umgang mit verschiedenen Formaten\n",
    "    if len(area_parts) == 1:  # Ein-Wert-Format (3.000 m²)\n",
    "        largest_value = float(area_parts[0])\n",
    "    elif len(area_parts) == 3 and area_parts[1] == '-':  # Bereichsformat (5.000 - 15.000 m²)\n",
    "        largest_value = max(float(area_parts[0]), float(area_parts[2]))\n",
    "    else:  # Ungültiges Format\n",
    "        largest_value = None\n",
    "\n",
    "    return largest_value\n",
    "\n",
    "# Funktion zur Extraktion des kleinsten Float-Werts aus einem Bereichsstring\n",
    "def extract_smallest_float(area_string):\n",
    "    # Entfernen von nicht-numerischen Zeichen und Aufteilen des Strings in Teile\n",
    "    area_parts = re.sub(r\"[^\\d\\-\\s]\", \"\", area_string).split()\n",
    "\n",
    "    if len(area_parts) == 1:  # Ein-Wert-Format (3.000 m²)\n",
    "        smallest_value = float(area_parts[0])\n",
    "    elif len(area_parts) == 3 und area_parts[1] == '-':  # Bereichsformat (5.000 - 15.000 m²)\n",
    "        smallest_value = min(float(area_parts[0]), float(area_parts[2]))\n",
    "    else:  # Ungültiges Format\n",
    "        smallest_value = None\n",
    "\n",
    "    return smallest_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einlesen der Lagerhausdaten aus CSV-Dateien\n",
    "warehouse_data_wuerzburg = pd.read_csv('./Immobilien_Data/Wuerzburg.csv')  # Daten aus der CSV-Datei für Würzburg einlesen\n",
    "warehouse_data_wuerzburg_kreis = pd.read_csv('./Immobilien_Data/Wuerzburg-Kreis.csv')  # Daten aus der CSV-Datei für Würzburg-Kreis einlesen\n",
    "\n",
    "# Kombinieren der Daten aus beiden CSV-Dateien\n",
    "warehouse_data = pd.concat([warehouse_data_wuerzburg, warehouse_data_wuerzburg_kreis], axis=0)  # DataFrames zusammenfügen\n",
    "\n",
    "# Extrahieren der x- und y-Koordinaten aus der 'geoGrid'-Spalte unter Verwendung einer Funktion (angenommen, 'geohash_to_csr3035' ist anderswo definiert)\n",
    "warehouse_data[['x_csr3035', 'y_csr3035']] = warehouse_data['geoGrid'].apply(lambda x: pd.Series(geohash_to_csr3035(x)))\n",
    "\n",
    "# Erstellen einer Geometriespalte unter Verwendung von Point-Objekten aus den x- und y-Koordinaten\n",
    "warehouse_data['geometry'] = warehouse_data.apply(lambda row: Point(row['x_csr3035'], row['y_csr3035']), axis=1)\n",
    "\n",
    "# Konvertieren der Daten in ein GeoDataFrame mit spezifizierter Geometriespalte und CRS\n",
    "warehouses_gdf = gpd.GeoDataFrame(warehouse_data, geometry='geometry', crs='EPSG:3035')\n",
    "\n",
    "# Zurücksetzen des Indexes, um potenzielle Probleme mit doppelten Indizes zu vermeiden\n",
    "warehouses_gdf = warehouses_gdf.reset_index(drop=True)  # Index zurücksetzen und optional die alte Spalte entfernen\n",
    "\n",
    "# Bereinigen und Verarbeiten der 'pricePerSquareMetre'-Spalte\n",
    "warehouses_gdf['pricePerSquareMetre'] = warehouses_gdf['pricePerSquareMetre'].replace('', np.nan)\n",
    "warehouses_gdf['pricePerSquareMetre'] = warehouses_gdf[warehouses_gdf['pricePerSquareMetre'].notna()]['pricePerSquareMetre'].apply(convert_price_string_to_float)  # Funktion auf nicht-NaN-Werte anwenden, um das Preisformat zu konvertieren\n",
    "warehouses_gdf['pricePerSquareMetre'].fillna(warehouses_gdf['pricePerSquareMetre'].median(), inplace=True)  # NaN-Werte mit dem Median füllen\n",
    "warehouses_gdf['pricePerSquareMetre'] = warehouses_gdf['pricePerSquareMetre'].apply(lambda x: round(x, 2))  # Preiswerte auf 2 Dezimalstellen runden\n",
    "\n",
    "# Bereinigen und Verarbeiten der 'floorSpace'-Spalte\n",
    "warehouses_gdf['floorSpace_big'] = warehouses_gdf['floorSpace'].apply(extract_largest_float)\n",
    "warehouses_gdf['floorSpace_small'] = warehouses_gdf['floorSpace'].apply(extract_smallest_float)\n",
    "\n",
    "# Erstellen einer neuen Spalte mit dem entsprechenden Preiselement\n",
    "warehouses_gdf['total_price_big'] = warehouses_gdf['floorSpace_big'] * warehouses_gdf['pricePerSquareMetre'] * 12\n",
    "warehouses_gdf['total_price_small'] = warehouses_gdf['floorSpace_small'] * warehouses_gdf['pricePerSquareMetre'] * 12\n",
    "\n",
    "# Entfernen nicht benötigter Spalten\n",
    "warehouses_gdf = warehouses_gdf.drop(columns=['features', 'pictureUrls'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warehouses_gdf.to_file('./Donner_Data/warehouses_donner.gpkg', driver='GPKG')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterarbeit_python311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
