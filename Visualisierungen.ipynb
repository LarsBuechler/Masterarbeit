{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "import geohash2\n",
    "import pyproj\n",
    "from pyproj import Proj, transform, CRS\n",
    "from functools import partial\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon\n",
    "from geopy.distance import geodesic\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy.stats import poisson\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bevölkerungsdemographie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_gdf = gpd.read_file('./Donner_Data/geo_donner.gpkg')\n",
    "\n",
    "bevölkerungs_gdf = gpd.read_file('./Donner_Data/pharmacy_assigned_complete.gpkg')\n",
    "bevölkerungs_gdf['Alter'] = bevölkerungs_gdf['Alter'].apply(json.loads)\n",
    "bevölkerungs_gdf['Geschlecht'] = bevölkerungs_gdf['Geschlecht'].apply(json.loads)\n",
    "\n",
    "customers_gdf = gpd.read_file('./Donner_Data/cluster_donner.gpkg')\n",
    "customers_gdf['Alter'] = customers_gdf['Alter'].apply(json.loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zum Berechnen des Durchschnittsalters\n",
    "def calculate_average_age(age_dict):\n",
    "    age_ranges = list(age_dict.keys())\n",
    "    age_counts = list(age_dict.values())\n",
    "    age_midpoints = [np.mean(list(map(int, age_range.split('-')))) if '-' in age_range else 80 for age_range in age_ranges]\n",
    "    weighted_sum = sum(midpoint * count for midpoint, count in zip(age_midpoints, age_counts))\n",
    "    total_count = sum(age_counts)\n",
    "    average_age = weighted_sum / total_count if total_count != 0 else 0\n",
    "    return average_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bevölkerungs_gdf['average_age'] = bevölkerungs_gdf['Alter'].apply(calculate_average_age)\n",
    "customers_gdf['average_age'] = customers_gdf['Alter'].apply(calculate_average_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechne die Gesamtanzahl je Altersgruppe\n",
    "age_ranges = [\"0-10\", \"10-20\", \"20-30\", \"30-40\", \"40-50\", \"50-60\", \"60-70\", \"70-80\", \"80+\"]\n",
    "total_counts = {age_range: 0 for age_range in age_ranges}\n",
    "for age_dict in customers_gdf['Alter']:\n",
    "    for age_range, count in age_dict.items():\n",
    "        total_counts[age_range] += int(count)\n",
    "\n",
    "average_age_overall = customers_gdf['average_age'].mean()\n",
    "\n",
    "# Erstelle eine benutzerdefinierte Farbkarte\n",
    "colors = plt.cm.coolwarm(np.linspace(0, 1, len(age_ranges)))\n",
    "cmap = ListedColormap(colors)\n",
    "\n",
    "# Zuordnung der Farben zu Altersabschnitten\n",
    "age_color_map = {age_range: color for age_range, color in zip(age_ranges, colors)}\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Plot the raster with boundary\n",
    "geo_gdf.boundary.plot(ax=ax, color='gray', linewidth=0.5)\n",
    "\n",
    "# Plot the customers with custom colormap based on average age\n",
    "bevölkerungs_gdf.plot(ax=ax, column='average_age', cmap=cmap, markersize = 1.5)\n",
    "\n",
    "# Add title and labels\n",
    "plt.axis('off')\n",
    "\n",
    "# Add custom legend for age ranges with total counts and average age\n",
    "handles = [Patch(color=age_color_map[age_range], label=f\"{age_range}: {total_counts[age_range]}\") for age_range in age_ranges]\n",
    "handles.append(Patch(color='none', label=f\"Ø: {average_age_overall:.2f}\"))\n",
    "legend = ax.legend(handles=handles, title=\"Altersabschnitte | Einwohnerzahl\", loc='center left', bbox_to_anchor=(0.8, 0.9), frameon=False)\n",
    "\n",
    "# Setze die Texte der Legende linksbündig\n",
    "plt.setp(legend.get_texts(), ha='left')\n",
    "\n",
    "# Add scale bar\n",
    "scalebar = ScaleBar(1, location='lower right', label='Maßstab')  # 1 pixel = 1 meter\n",
    "ax.add_artist(scalebar)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechne die Gesamtanzahl je Altersgruppe\n",
    "age_ranges = [\"0-10\", \"10-20\", \"20-30\", \"30-40\", \"40-50\", \"50-60\", \"60-70\", \"70-80\", \"80+\"]\n",
    "total_counts = {age_range: 0 for age_range in age_ranges}\n",
    "for age_dict in customers_gdf['Alter']:\n",
    "    for age_range, count in age_dict.items():\n",
    "        total_counts[age_range] += int(count)\n",
    "\n",
    "average_age_overall = customers_gdf['average_age'].mean()\n",
    "\n",
    "# Erstelle eine benutzerdefinierte Farbkarte\n",
    "colors = plt.cm.coolwarm(np.linspace(0, 1, len(age_ranges)))\n",
    "cmap = ListedColormap(colors)\n",
    "\n",
    "# Zuordnung der Farben zu Altersabschnitten\n",
    "age_color_map = {age_range: color for age_range, color in zip(age_ranges, colors)}\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Plot the raster with boundary\n",
    "geo_gdf.boundary.plot(ax=ax, color='gray', linewidth=0.5)\n",
    "\n",
    "# Plot the customers with custom colormap based on average age\n",
    "bevölkerungs_gdf.plot(ax=ax, column='average_age', cmap=cmap, markersize = 2)\n",
    "\n",
    "# Add title and labels\n",
    "plt.axis('off')\n",
    "\n",
    "# Add custom legend for age ranges with total counts and average age\n",
    "handles = [Patch(color=age_color_map[age_range], label=f\"{age_range}: {total_counts[age_range]}\") for age_range in age_ranges]\n",
    "handles.append(Patch(color='none', label=f\"Ø: {average_age_overall:.2f}\"))\n",
    "legend = ax.legend(handles=handles, title=\"Altersabschnitte | Einwohnerzahl\", loc='center left', bbox_to_anchor=(0.9, 0.9))\n",
    "\n",
    "# Setze die Texte der Legende linksbündig\n",
    "plt.setp(legend.get_texts(), ha='left')\n",
    "\n",
    "# Add scale bar\n",
    "scalebar = ScaleBar(1, location='lower right', label='Maßstab')  # 1 pixel = 1 meter\n",
    "ax.add_artist(scalebar)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a colormap based on the \"nachfrage\" column\n",
    "vmin = customers_gdf['nachfrage'].min()\n",
    "vmax = customers_gdf['nachfrage'].max()\n",
    "cmap = 'coolwarm'  \n",
    "\n",
    "# Plot the raster with boundary\n",
    "ax = geo_gdf.boundary.plot(color='gray', linewidth=0.5, figsize = (5,5))\n",
    "\n",
    "# Plot the customers with custom colormap\n",
    "customers_gdf.plot(ax=ax, column='nachfrage', cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "\n",
    "# Add title and labels\n",
    "plt.axis('off')\n",
    "plt.title('Nachfrage der Cluster des Landkreis Würzburg')\n",
    "#plt.xlabel('Breitengradkoordinate im CSR3035 Format')\n",
    "#plt.ylabel('Längengradkoordinate im CSR3035 Format')\n",
    "\n",
    "# Add colorbar\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "sm._A = []  # Fake up the array of the scalar mappable\n",
    "cbar = plt.colorbar(sm, ax=ax, shrink=0.5, label='Nachfrage')  # Adjust shrink value as needed\n",
    "\n",
    "# Add scale bar\n",
    "scalebar = ScaleBar(1, location='lower left', label='Maßstab')  # 1 pixel = 1 meter\n",
    "ax.add_artist(scalebar)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster Graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_city = gpd.read_file('./99_Old/Wuerzburg/Raster_Wuerzburg.gpkg')\n",
    "geo_gdf = gpd.read_file('./Wuerzburg_Data/geo_wuerzburg.gpkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrahieren der Polygon-Koordinaten als Features für das Clustering\n",
    "X = np.array(gdf_city.geometry.apply(lambda polygon: [polygon.centroid.x, polygon.centroid.y]).tolist())\n",
    "\n",
    "# DBSCAN-Clustering durchführen\n",
    "dbscan = DBSCAN(eps=100, min_samples=4)  # Anpassen von eps und min_samples je nach Bedarf\n",
    "dbscan.fit(X)\n",
    "\n",
    "# Fügen Sie die Cluster-Zuordnung als neue Spalte zum GeoDataFrame hinzu\n",
    "gdf_city['cluster'] = dbscan.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion, um einen Teil einer Colormap zu extrahieren\n",
    "def truncate_colormap(cmap, minval=0.4, maxval=1.0, n=100):\n",
    "    new_cmap = plt.cm.colors.LinearSegmentedColormap.from_list(\n",
    "        f'trunc({cmap.name},{minval:.2f},{maxval:.2f})', \n",
    "        cmap(np.linspace(minval, maxval, n)))\n",
    "    return new_cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_middle_indices(cluster_sizes, n):\n",
    "    \"\"\"\n",
    "    Gibt die Indizes der mittleren n Cluster zurück.\n",
    "    \"\"\"\n",
    "    sorted_indices = cluster_sizes.sort_values().index\n",
    "    middle_start = (len(sorted_indices) - n) // 2\n",
    "    middle_end = middle_start + n\n",
    "    return sorted_indices[middle_start:middle_end][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zum Berechnen der Anzahl der Einwohner und Polygone für jeden Cluster\n",
    "def get_cluster_info(cluster_id):\n",
    "    population = int(gdf_city[gdf_city[\"cluster\"] == cluster_id][\"INSGESAMT_0\"].sum())\n",
    "    num_polygons = len(gdf_city[gdf_city[\"cluster\"] == cluster_id])\n",
    "    return population, num_polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zur Erzeugung von Abständen\n",
    "def format_label(cluster_id, population, num_polygons):\n",
    "    cluster_id_str = f'Cluster {cluster_id}:'\n",
    "    population_str = f'{population}'\n",
    "    num_polygons_str = f'|   {num_polygons * 10000 / 1000000}km²'\n",
    "    \n",
    "    if len(str(cluster_id)) < 2:\n",
    "        population_pos = 17  # Abstand von Cluster ID\n",
    "    elif len(str(cluster_id)) < 3:\n",
    "        population_pos = 16  # Abstand von Cluster ID\n",
    "    else:\n",
    "        population_pos = 15  # Abstand von Cluster ID\n",
    "\n",
    "    if len(str(population)) < 3:\n",
    "        num_polygons_pos = population_pos + 11  # Abstand von Population\n",
    "    elif len(str(population)) < 4:\n",
    "        num_polygons_pos = population_pos + 10  # Abstand von Population\n",
    "    elif len(str(population)) < 5:\n",
    "        num_polygons_pos = population_pos + 9  # Abstand von Population\n",
    "    elif len(str(population)) < 6:\n",
    "        num_polygons_pos = population_pos + 8  # Abstand von Population\n",
    "    else:\n",
    "        num_polygons_pos = population_pos + 7  # Abstand von Population\n",
    "    \n",
    "    label = f'{cluster_id_str:<{population_pos}}{population_str:<{num_polygons_pos - population_pos}}{num_polygons_str}'\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gruppiere die Polygone nach Cluster-ID und vereinige sie zu MultiPolygons\n",
    "cluster_multipolygons = gdf_city.dissolve(by='cluster')\n",
    "# Erstelle einen neuen GeoDataFrame (optional, falls weitere Modifikationen nötig sind)\n",
    "gdf_clusters = gpd.GeoDataFrame(cluster_multipolygons, geometry='geometry')\n",
    "gdf_clusters['color_int'] = gdf_clusters.apply(lambda x: random.randint(1, len(gdf_clusters)), axis=1)\n",
    "\n",
    "# Verwende den helleren Teil der cividis-Colormap\n",
    "cmap = truncate_colormap(plt.get_cmap('viridis'), 0.2, 1.0)\n",
    "\n",
    "# Berechne die Clustergröße\n",
    "cluster_sizes = gdf_city[gdf_city['cluster'] != -1]['cluster'].value_counts()\n",
    "# Filtere die 3 größten Cluster\n",
    "largest_clusters = cluster_sizes.nlargest(3).index.tolist()\n",
    "# Filtere die 3 kleinsten Cluster\n",
    "smallest_clusters = cluster_sizes.nsmallest(3).index.tolist()\n",
    "# Berechne die mittleren Cluster, indem du die größten und kleinsten entfernst\n",
    "remaining_clusters = cluster_sizes[~cluster_sizes.index.isin(largest_clusters + smallest_clusters)]\n",
    "middle_clusters = get_middle_indices(remaining_clusters, 4).tolist()\n",
    "# Kombiniere die Cluster in einer Liste\n",
    "selected_clusters = largest_clusters + middle_clusters + smallest_clusters\n",
    "\n",
    "# Anzahl der Polygone im Cluster -1\n",
    "outlier_count = len(gdf_city[gdf_city['cluster'] == -1])\n",
    "\n",
    "# Plotten der Boundary\n",
    "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "geo_gdf.boundary.plot(ax=ax, color='gray', linewidth=0.5)\n",
    "\n",
    "# Plotten der Polygone mit Cluster-Färbung\n",
    "gdf_clusters[gdf_clusters.index != -1].plot(ax=ax, column='color_int', cmap=cmap, legend=False)\n",
    "gdf_city[gdf_city['cluster'] == -1].plot(ax=ax, color='purple', legend=False)  # Lila für Cluster -1\n",
    "\n",
    "\n",
    "# Zentroiden und Anzahl der Polygone der 10 größten Cluster anzeigen\n",
    "for cluster_id in selected_clusters:\n",
    "    cluster_data = gdf_city[gdf_city['cluster'] == cluster_id]\n",
    "    centroid = cluster_data.geometry.unary_union.centroid\n",
    "    ax.plot(centroid.x, centroid.y, '^', color='red', markersize=6)\n",
    "    if cluster_id == 89:\n",
    "        ax.text(centroid.x - 1600, centroid.y - 800, cluster_id, fontsize=12, ha='center', va='center', color='black', fontweight='bold') \n",
    "    else:\n",
    "        ax.text(centroid.x + 1600, centroid.y - 800, cluster_id, fontsize=12, ha='center', va='center', color='black', fontweight='bold')  # Versetzte Position\n",
    "\n",
    "\n",
    "# Text unterhalb der Farblegende hinzufügen\n",
    "fig.text(1.185, 0.6772, f'Fläche der Ausreiser: {outlier_count* 10000 / 1000000}km²', ha='right', va='center', fontsize=9)\n",
    "fig.text(1.13, 0.6555, f'Anzahl der Cluster: {gdf_city[\"cluster\"].nunique()-1}', ha='right', va='center', fontsize=9)\n",
    "\n",
    "# Erstelle die Legende\n",
    "legend_handles = []\n",
    "for cluster_id in selected_clusters:\n",
    "    population, num_polygons = get_cluster_info(cluster_id)\n",
    "    cluster_label = format_label(cluster_id, population, num_polygons)\n",
    "    legend_handles.append(\n",
    "        Line2D([0], [0], marker='^', color='w', markerfacecolor='red', markersize=10, label=cluster_label)\n",
    "    )\n",
    "\n",
    "# Annahme: ax ist bereits definiert und Plot ist erstellt\n",
    "legend2 = ax.legend(handles=legend_handles, title='Cluster: Einwohnerzahl | Fläche', bbox_to_anchor=(1, 1), loc='upper left', borderaxespad=0., fontsize='small', ncol=1,  alignment='center', frameon=False)\n",
    "ax.add_artist(legend2)\n",
    "\n",
    "# Add scale bar\n",
    "scalebar = ScaleBar(1, location='lower right', label='Maßstab')\n",
    "ax.add_artist(scalebar)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pharmacy/Warehouse Graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_gdf = gpd.read_file('./Wuerzburg_Data/geo_wuerzburg.gpkg')\n",
    "\n",
    "pharmacy_df = pd.read_csv('./Wuerzburg_Data/wuerzburg-Apotheken.csv')\n",
    "pharmacy_gdf = gpd.GeoDataFrame(pharmacy_df, geometry=gpd.points_from_xy(pharmacy_df['lon'], pharmacy_df['lat']), crs=CRS(\"EPSG:4326\"))\n",
    "pharmacy_gdf = pharmacy_gdf.to_crs('3035')\n",
    "\n",
    "warehouses_gdf = gpd.read_file('./Wuerzburg_Data/warehouses_wuerzburg.gpkg')\n",
    "warehouses_gdf['month_rent'] = warehouses_gdf['floorSpace_small'] * warehouses_gdf['pricePerSquareMetre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechne die durchschnittlichen monatlichen Mietkosten\n",
    "warehouses_gdf['avg_monthly_rent'] = ((warehouses_gdf['total_price_small'] + warehouses_gdf['total_price_big']) / 2) / 12\n",
    "\n",
    "# Min- und Max-Werte der \"avg_monthly_rent\" Spalte\n",
    "vmin = warehouses_gdf['avg_monthly_rent'].min()\n",
    "vmax = warehouses_gdf['avg_monthly_rent'].max()\n",
    "cmap = 'coolwarm'\n",
    "\n",
    "# Berechne die Größe der Punkte basierend auf der durchschnittlichen Fläche (floorSpace_small und floorSpace_big)\n",
    "avg_floorSpace = (warehouses_gdf['floorSpace_small'] + warehouses_gdf['floorSpace_big']) / 2\n",
    "min_size = 15\n",
    "max_size = 200\n",
    "size = np.interp(avg_floorSpace, (avg_floorSpace.min(), avg_floorSpace.max()), (min_size, max_size))\n",
    "\n",
    "# Berechne die tatsächliche maximale und minimale Punktgröße auf der Karte\n",
    "max_point_size = size[np.argmax(avg_floorSpace)]\n",
    "min_point_size = size[np.argmin(avg_floorSpace)]\n",
    "\n",
    "# Rahmen der Grafik definieren\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "geo_gdf.boundary.plot(ax=ax, color='gray', linewidth=0.5)\n",
    "\n",
    "# Plotte pharmacy_gdf auf dieselbe Achse\n",
    "pharmacy_gdf.plot(ax=ax, markersize=15, marker='^', color='purple', label='Apotheken')\n",
    "\n",
    "# Plotte warehouses_gdf auf dieselbe Achse\n",
    "warehouses_gdf.plot(ax=ax, column='avg_monthly_rent', cmap=cmap, markersize=size, marker='o', legend=False, alpha=0.6, edgecolor='black', linewidth=0.5)\n",
    "\n",
    "# Titel hinzufügen\n",
    "plt.axis('off')\n",
    "\n",
    "# Add colorbar\n",
    "norm = plt.Normalize(vmin=vmin, vmax=vmax)\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm._A = []  # Fake up the array of the scalar mappable\n",
    "cbar = plt.colorbar(sm, ax=ax, shrink=0.44)\n",
    "cbar.set_label('Monatliche Mietkosten der Mindestfläche', fontsize='small', weight='normal')\n",
    "\n",
    "# Add custom legend for warehouse sizes and types\n",
    "custom_legend = [\n",
    "    Line2D([0], [0], marker='^', color='w', markerfacecolor='purple', markersize=10, label=f'Apotheken: {len(pharmacy_gdf)}'),\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='lightblue', markersize=10, label=f'Versandlager: {len(warehouses_gdf)}')\n",
    "]\n",
    "# Berechne interpolierte Punktgrößen für die Legende\n",
    "legend_sizes = [6, 11, 16]\n",
    "legend_labels = [int(avg_floorSpace.min()), int(avg_floorSpace.median()), int(avg_floorSpace.max())]\n",
    "\n",
    "# Erstelle die Größenskala für die Legende untereinander mit Farbverlauf von blue zu lightblue zu lightred\n",
    "colors = ['lightblue', 'lightblue', 'lightblue']\n",
    "size_legend = []\n",
    "for size_label, label, color in zip(legend_sizes, legend_labels, colors):\n",
    "    size_legend.append(Line2D([0], [0], marker='o', color='w', markerfacecolor=color, markersize=size_label, label=f'{label} m²'))\n",
    "\n",
    "# Hinzufügen der kombinierten Legende\n",
    "legend1 = ax.legend(handles=custom_legend, title='Versandlager / Apotheken', bbox_to_anchor=(1, 0.98), loc='upper left', borderaxespad=0., fontsize='small', ncol=1, frameon=False, prop={'size': 'small', 'weight': 'normal'})\n",
    "ax.add_artist(legend1)\n",
    "\n",
    "# Erstelle die Legende mit den Punkten untereinander und genügend Abstand zwischen den Zeilen\n",
    "legend2 = ax.legend(handles=size_legend, title='Ø - Fläche der Versandlager', bbox_to_anchor=(1, 0.88), loc='upper left', borderaxespad=0., fontsize='small', ncol=1, handleheight=2.25, handletextpad=1.25, frameon=False, prop={'size': 'small', 'weight': 'normal'})\n",
    "ax.add_artist(legend2)\n",
    "\n",
    "# Setze die Font-Eigenschaften der Titel und Texte der Legenden\n",
    "plt.setp(legend1.get_title(), fontsize='small', fontweight='normal')\n",
    "plt.setp(legend1.get_texts(), fontsize='small', fontweight='normal')\n",
    "plt.setp(legend2.get_title(), fontsize='small', fontweight='normal')\n",
    "plt.setp(legend2.get_texts(), fontsize='small', fontweight='normal')\n",
    "\n",
    "# Add scale bar\n",
    "scalebar = ScaleBar(1, location='lower right', label='Maßstab')\n",
    "ax.add_artist(scalebar)\n",
    "\n",
    "# Zeige den Plot an\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal Warehouse Graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_gdf = gpd.read_file('./Donner_Data/geo_donner.gpkg')\n",
    "warehouses_gdf = gpd.read_file('./Donner_Data/warehouses_donner.gpkg')\n",
    "\n",
    "with open('./Results/optimal_run_results.pkl', 'rb') as infile:\n",
    "    optimal_results = pickle.load(infile)\n",
    "\n",
    "opened_warehouses = optimal_results[1]['result_list'][0]['results']['opened_warehouses']\n",
    "warehouse_info = optimal_results[1]['result_list'][0]['results']['Warehouse Info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rahmen der Grafik definieren\n",
    "ax = geo_gdf.boundary.plot(color='gray', linewidth=0.5, figsize=(8, 8))\n",
    "\n",
    "# Plotte gdf_loaded auf dieselbe Achse\n",
    "warehouses_gdf[~warehouses_gdf.index.isin(opened_warehouses)].plot(ax=ax, color='red', marker='o', markersize=25)\n",
    "warehouses_gdf.loc[opened_warehouses].plot(ax=ax, color='blue', marker='^', markersize=35)\n",
    "\n",
    "plt.axis('off')\n",
    "\n",
    "# Add scale bar\n",
    "scalebar = ScaleBar(1, location='lower right', label='Maßstab')\n",
    "ax.add_artist(scalebar)\n",
    "\n",
    "# Erste Legende\n",
    "custom_legend = [\n",
    "    Line2D([0], [0], marker='^', color='w', markerfacecolor='blue', markersize=10, label='Geöffnet'),\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='red', markersize=10, label='Nicht geöffnet')\n",
    "]\n",
    "legend1 = ax.legend(handles=custom_legend, title='Versandlager', bbox_to_anchor=(0.89, 1), loc='upper left', borderaxespad=0., fontsize='small', ncol=1, frameon=False)\n",
    "ax.add_artist(legend1)\n",
    "\n",
    "# Zweite Legende\n",
    "legend_handles = [\n",
    "    Line2D(\n",
    "        [0], [0], marker='^', color='w', markersize=10,\n",
    "        label=f'Lager {warehouse}: {info[\"floor_space_assigned\"]} m² | {info[\"number_of_drones\"]} Drohnen'\n",
    "    )\n",
    "    for warehouse, info in warehouse_info.items()\n",
    "]\n",
    "legend2 = ax.legend(handles=legend_handles, title='Mietfläche | Drohnenanzahl', bbox_to_anchor=(0.87, 0.87), loc='upper left', borderaxespad=0., fontsize='small', ncol=1, frameon=False)\n",
    "\n",
    "# Index jedes Warehouses anzeigen\n",
    "for idx, row in warehouses_gdf.loc[opened_warehouses].iterrows():\n",
    "    plt.annotate(idx, (row.geometry.x, row.geometry.y), xytext=(5, 5), textcoords='offset points', fontsize=10, color='black', fontweight='bold')\n",
    "\n",
    "\n",
    "# Zeige den Plot an\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Region Warehouse Solution Graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_gdf = gpd.read_file('./Wuerzburg_Data/geo_wuerzburg.gpkg')\n",
    "warehouses_gdf = gpd.read_file('./Wuerzburg_Data/warehouses_wuerzburg.gpkg')\n",
    "customers_gdf = gpd.read_file('./Results/Optimal_Results_customers_wuerzburg.gpkg')\n",
    "customers_gdf['Alter'] = customers_gdf['Alter'].apply(json.loads)\n",
    "\n",
    "with open('./Results/optimal_run_results.pkl', 'rb') as infile:\n",
    "    optimal_results = pickle.load(infile)\n",
    "\n",
    "opened_warehouses = optimal_results[0]['result_list'][0]['results']['opened_warehouses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a colormap with a color for each opened warehouse\n",
    "colors = plt.cm.tab20(np.linspace(0, 1, len(opened_warehouses)))\n",
    "warehouse_colors = dict(zip(opened_warehouses, colors))\n",
    "\n",
    "# Create a dictionary to map each warehouse to a color\n",
    "warehouse_colors = {\n",
    "    warehouse: color\n",
    "    for warehouse, color in zip(opened_warehouses, warehouse_colors.values())\n",
    "}\n",
    "\n",
    "# Plot the boundaries of the region\n",
    "ax = geo_gdf.boundary.plot(color='gray', linewidth=0.5, figsize=(8, 8))\n",
    "\n",
    "\n",
    "# Plot the customers with the color of their assigned warehouse\n",
    "for index, row in customers_gdf.iterrows():\n",
    "    warehouse = row['assigned_warehouse']\n",
    "    color = warehouse_colors.get(warehouse, 'gray')  # Use gray color if warehouse is not in the dictionary\n",
    "    customers_gdf.iloc[[index]].plot(ax=ax, color=color, markersize=20)\n",
    "\n",
    "\n",
    "# Plot the warehouses with their assigned colors\n",
    "for warehouse, color in warehouse_colors.items():\n",
    "    warehouses_gdf[warehouses_gdf.index == warehouse].plot(ax=ax, color=color, marker='^', markersize=50, edgecolor='black')\n",
    "\n",
    "\n",
    "# Turn off axis\n",
    "plt.axis('off')\n",
    "\n",
    "# Add legend\n",
    "# Erstelle die Legende\n",
    "legend_handles = [\n",
    "    Line2D(\n",
    "        [0], [0], marker='^', color='w', markerfacecolor=color, markersize=10,\n",
    "        label=f'Versandlager {warehouse}: {int(customers_gdf[customers_gdf[\"assigned_warehouse\"] == warehouse][\"sum_INSGESAMT_0\"].sum())}'\n",
    "    )\n",
    "    for warehouse, color in warehouse_colors.items()\n",
    "]\n",
    "ax.legend(handles=legend_handles, title='Versandlager | Einwohnerzahl', bbox_to_anchor=(0.95, 1), loc='upper left', borderaxespad=0., fontsize='small', ncol=1, frameon=False)\n",
    "\n",
    "# Add scale bar\n",
    "scalebar = ScaleBar(1, location='lower right', label='Maßstab')\n",
    "ax.add_artist(scalebar)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabellenerstellung "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Results/sensitivity_results_complete.pkl', 'rb') as infile:\n",
    "    sensitivity_results = pickle.load(infile)\n",
    "\n",
    "with open('./Results/optimal_run_results.pkl', 'rb') as infile:\n",
    "    optimal_results = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = ['wuerzburg', 'donner', 'frankfurt']\n",
    "\n",
    "for i in range(3):\n",
    "    opened_warehouses = optimal_results[i]['result_list'][0]['results']['opened_warehouses']\n",
    "    optimal_solution_counter = 0\n",
    "    solution_dict = []\n",
    "    for j in range(i*16, i*16+16):\n",
    "        for item in sensitivity_results[j]['result_list']:\n",
    "            if np.array_equal(item['opened_warehouses'], opened_warehouses):\n",
    "                optimal_solution_counter+=1\n",
    "            else:\n",
    "                solution_dict.append(\n",
    "                    {\n",
    "                        'parameter': item['parameter_name'],\n",
    "                        'parameter_value': item['parameter_value'],\n",
    "                        'opened_warehouses': item['opened_warehouses'],\n",
    "                        'number_of_drones':  item['number_of_drones'],\n",
    "                        'floor_space_assigned': item['floor_space_assigned'],\n",
    "                        'warehouse_info': item['Warehouse Info']\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    solution_dict.append({\n",
    "        'optimal_count': optimal_solution_counter\n",
    "    })\n",
    "    with open(f'./Results/solution_dict_{city[i]}.pkl', 'wb') as outfile:\n",
    "        pickle.dump(solution_dict, outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "factory_fix_costs = 50000\n",
    "factory_variable_costs = 0.5\n",
    "factory_operating_costs = 0.375\n",
    "qm_per_customer = 10\n",
    "minimum_square_requirement = 1000\n",
    "rent_factor = 1 #Prozent\n",
    "max_flight_distance = 25 #km\n",
    "drone_initial_costs = 4000 #Eur\n",
    "drone_speed = 65/60 #km/h/60 = km/min\n",
    "time_window = 630 #Min\n",
    "delivery_time = 60 #Min\n",
    "alpha = 0.5\n",
    "night_shift_dist = 0.00112103746 #Prozent\n",
    "demand_factor = 1 #Prozent\n",
    "watt_drone = 0.3 #Kw\n",
    "kwh_eur = 0.4175\n",
    "\n",
    "optimal_parameter_values = {\n",
    "    'factory_fix_costs': factory_fix_costs,\n",
    "    'factory_variable_costs': factory_variable_costs,\n",
    "    'factory_operating_costs': factory_operating_costs,\n",
    "    'qm_per_customer': qm_per_customer,\n",
    "    'minimum_square_requirement': minimum_square_requirement,\n",
    "    'rent_factor': rent_factor,\n",
    "    'max_flight_distance': max_flight_distance,\n",
    "    'drone_initial_costs': drone_initial_costs,\n",
    "    'drone_speed': drone_speed,\n",
    "    'time_window': time_window,\n",
    "    'delivery_time': delivery_time,\n",
    "    'alpha': alpha,\n",
    "    'night_shift_dist': night_shift_dist,\n",
    "    'demand_factor': demand_factor,\n",
    "    'watt_drone': watt_drone,\n",
    "    'kwh_eur': kwh_eur\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_based_on_reference(data, optimal_parameter_values):\n",
    "    grouped_data = defaultdict(list)\n",
    "\n",
    "    # Group the entries by parameter\n",
    "    for entry in data:\n",
    "        if 'parameter' in entry:\n",
    "            param = entry['parameter']\n",
    "            grouped_data[param].append(entry)\n",
    "\n",
    "    sorted_data = []\n",
    "\n",
    "    # Sort each parameter group\n",
    "    for param, entries in grouped_data.items():\n",
    "        below_optimal = []\n",
    "        above_optimal = []\n",
    "        optimal_value = optimal_parameter_values[param]\n",
    "\n",
    "        for entry in entries:\n",
    "            value = entry['parameter_value']\n",
    "\n",
    "            if value < optimal_value:\n",
    "                entry['change'] = 'lower'\n",
    "                below_optimal.append(entry)\n",
    "            else:\n",
    "                entry['change'] = 'higher'\n",
    "                above_optimal.append(entry)\n",
    "\n",
    "        # Sort the data below the optimal value in descending order\n",
    "        below_optimal_sorted = sorted(below_optimal, key=lambda x: x['parameter_value'], reverse=True)\n",
    "        # Sort the data above the optimal value in ascending order\n",
    "        above_optimal_sorted = sorted(above_optimal, key=lambda x: x['parameter_value'])\n",
    "\n",
    "        # Combine the sorted data for the current parameter\n",
    "        sorted_data.extend(below_optimal_sorted + above_optimal_sorted)\n",
    "\n",
    "    return sorted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_latex_table(sorted_data):\n",
    "    parameter_save = []\n",
    "    # Erzeuge die LaTeX-Tabelle\n",
    "    table_header = '''\n",
    "\\\\documentclass{article}\n",
    "\\\\usepackage{array}\n",
    "\\\\usepackage{booktabs}\n",
    "\n",
    "\\\\begin{document}\n",
    "\n",
    "\\\\begin{table}[h!]\n",
    "\\\\centering\n",
    "\\\\begin{tabular}{|l|l|l|l|l|l|}\n",
    "\\\\hline\n",
    "\\\\textbf{Parameter} & \\\\textbf{Value} & \\\\textbf{Change Type} & \\\\textbf{Opened Warehouses} & \\\\textbf{Number of Drones} & \\\\textbf{Floor Space Assigned} \\\\\\\\\n",
    "\\\\hline\n",
    "'''\n",
    "\n",
    "    table_footer = '''\n",
    "\\\\end{tabular}\n",
    "\\\\caption{Parameter changes affecting warehouse configurations.}\n",
    "\\\\end{table}\n",
    "\n",
    "\\\\end{document}\n",
    "'''\n",
    "\n",
    "    table_body = ''\n",
    "\n",
    "    # Vergleichsarray\n",
    "    comparison_opened_warehouses = optimal_results[2]['result_list'][0]['results']['opened_warehouses']\n",
    "    \n",
    "\n",
    "    for entry in sorted_data:\n",
    "        param = entry['parameter']\n",
    "        value = entry['parameter_value']\n",
    "        opened_warehouses = entry['opened_warehouses']\n",
    "        number_of_drones = entry['number_of_drones']\n",
    "        floor_space_assigned = entry['floor_space_assigned']\n",
    "        change = entry['change']\n",
    "\n",
    "        if np.array_equal(opened_warehouses, comparison_opened_warehouses):\n",
    "            continue  # Überspringe, wenn keine Änderung\n",
    "\n",
    "        comparison_opened_warehouses = opened_warehouses\n",
    "\n",
    "        ow_str = ', '.join(map(str, opened_warehouses)) if len(opened_warehouses) > 0 else 'None'\n",
    "        ow_str = ow_str\n",
    "\n",
    "        nd_str = str(number_of_drones)\n",
    "        nd_str = nd_str \n",
    "\n",
    "        fsa_str = str(floor_space_assigned)\n",
    "        fsa_str = fsa_str\n",
    "\n",
    "        table_body += f'{param} & {value:.2f} & {ow_str} & {nd_str} & {fsa_str} & {change} \\\\\\\\ \\\\hline\\n'\n",
    "\n",
    "        parameter_save.append({\n",
    "            param: value\n",
    "        })\n",
    "\n",
    "    return table_header + table_body + table_footer, parameter_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Results/solution_dict_donner.pkl', 'rb') as infile:\n",
    "    solution = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_solution = sort_based_on_reference(solution, optimal_parameter_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_table, parameter_save = create_latex_table(sorted_solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'factory_fix_costs': 23734.640373414044},\n",
       " {'factory_fix_costs': 14136.822980688848},\n",
       " {'factory_fix_costs': 90980.99672282944},\n",
       " {'qm_per_customer': 8.645249555259689},\n",
       " {'qm_per_customer': 7.877592160157169},\n",
       " {'qm_per_customer': 7.839435893865452},\n",
       " {'qm_per_customer': 7.2575827919681775},\n",
       " {'qm_per_customer': 7.111855065523687},\n",
       " {'qm_per_customer': 5.357652218134865},\n",
       " {'qm_per_customer': 5.0},\n",
       " {'qm_per_customer': 10.781573067634419},\n",
       " {'qm_per_customer': 11.801892655327105},\n",
       " {'qm_per_customer': 13.125106145805585},\n",
       " {'max_flight_distance': 18.472507735416258},\n",
       " {'max_flight_distance': 13.0},\n",
       " {'drone_initial_costs': 2000.0},\n",
       " {'time_window': 60.0},\n",
       " {'demand_factor': 0.8604597072310793},\n",
       " {'demand_factor': 0.8445265834444771},\n",
       " {'demand_factor': 0.7935189539944023},\n",
       " {'demand_factor': 0.5},\n",
       " {'demand_factor': 1.116509422503339},\n",
       " {'demand_factor': 1.1527902283463318},\n",
       " {'demand_factor': 1.1656572029038603},\n",
       " {'demand_factor': 1.1859958383972014},\n",
       " {'demand_factor': 1.3884796114525302},\n",
       " {'demand_factor': 1.4023926311929111},\n",
       " {'demand_factor': 1.5}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./Results/parameter_comparison_donner.pkl', 'wb') as outfile:\n",
    "    pickle.dump(parameter_save, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterarbeit_python311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
