{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from pyproj import Proj, transform, CRS\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from time import sleep \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Berechnung der Entferunung von Gebäude zu Apotheke mithilfe der OSM Routing API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bevölkerungs_gdf = gpd.read_file('./WLP/pharmacy_assigned.gpkg')\n",
    "bevölkerungs_gdf['Alter'] = bevölkerungs_gdf['Alter'].apply(json.loads)\n",
    "bevölkerungs_gdf['Geschlecht'] = bevölkerungs_gdf['Geschlecht'].apply(json.loads)\n",
    "\n",
    "pharmacy_df = pd.read_csv('./OSM_Data/Donner-Apotheken.csv')\n",
    "pharmacy_gdf = gpd.GeoDataFrame(pharmacy_df, geometry=gpd.points_from_xy(pharmacy_df['lon'], pharmacy_df['lat']), crs=CRS(\"EPSG:4326\"))\n",
    "pharmacy_gdf = pharmacy_gdf.to_crs(bevölkerungs_gdf.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zur Berechnung der Entfernung zur nächstgelegenen Apotheke\n",
    "def calculate_distance_to_nearest_pharmacy(row):\n",
    "    # Finden der nächstgelegenen Apotheke basierend auf der zugewiesenen Apotheken-ID\n",
    "    nearest_pharmacy = pharmacy_gdf[pharmacy_gdf['id'] == row.assigned_pharmacy]\n",
    "\n",
    "    # Extrahieren der Längen- und Breitengrade des Gebäudes und der Apotheke\n",
    "    lon_build = row.lon\n",
    "    lat_build = row.lat\n",
    "    lon_pharm = nearest_pharmacy.lon.iloc[0]\n",
    "    lat_pharm = nearest_pharmacy.lat.iloc[0]\n",
    "\n",
    "    max_retries = 3  # Maximale Anzahl von Wiederholungsversuchen festlegen\n",
    "\n",
    "    # Schleife für Wiederholungsversuche\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            # Erstellen der Anforderungs-URL für die OSRM-Route\n",
    "            request_string = f\"http://router.project-osrm.org/route/v1/driving/{lon_build},{lat_build};{lon_pharm},{lat_pharm}?overview=false\"\n",
    "            res = requests.get(request_string)\n",
    "            res.raise_for_status()  # Ausnahme bei nicht-200-Statuscodes auslösen\n",
    "\n",
    "            # Inhalt der Antwort laden und die Entfernung und Dauer extrahieren\n",
    "            content = json.loads(res.content)\n",
    "            distance = content['routes'][0]['legs'][0]['distance']\n",
    "            duration = content['routes'][0]['legs'][0]['duration']\n",
    "            return distance, duration\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            # Fehlerbehandlung und Wartezeit vor erneutem Versuch\n",
    "            print(f\"Error occurred on attempt {attempt} for {lon_build},{lat_build} -> {lon_pharm},{lat_pharm}: {e}\")\n",
    "            sleep(30)  # 30 Sekunden warten vor erneutem Versuch\n",
    "\n",
    "    # Wenn alle Wiederholungsversuche fehlschlagen, 0 für Entfernung und Zeit zurückgeben\n",
    "    print(f\"All retries failed for {lon_build},{lat_build} -> {lon_pharm},{lat_pharm}\")\n",
    "    return 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aufteilen des DataFrames in 10 gleiche Teile (Chunks)\n",
    "chunksize = int(len(bevölkerungs_gdf) / 10)\n",
    "chunks = [bevölkerungs_gdf.iloc[i * chunksize:(i + 1) * chunksize] for i in range(10)]\n",
    "start_chunk = 0  # Start-Chunk-Index setzen\n",
    "\n",
    "# Iteration über jeden Chunk ab dem start_chunk-Index\n",
    "for iteration, chunk in enumerate(chunks[start_chunk:]):\n",
    "    # Berechnung der Entfernung und Zeit für jede Zeile im Chunk\n",
    "    for index, row in tqdm(chunk.iterrows(), total=len(chunk)):\n",
    "        distance, time = calculate_distance_to_nearest_pharmacy(row)\n",
    "        chunk.loc[index, 'distance_pharmacy'] = distance\n",
    "        chunk.loc[index, 'time_pharmacy'] = time\n",
    "\n",
    "    # Konvertierung spezifischer Spalten in JSON und Speichern des Chunks\n",
    "    chunk['Alter'] = chunk['Alter'].apply(json.dumps)\n",
    "    chunk['Geschlecht'] = chunk['Geschlecht'].apply(json.dumps)\n",
    "    chunk.to_file(f'./Processed_WLP/Würzburg/pharmacy_assigned_{iteration + start_chunk}.gpkg', driver='GPKG')\n",
    "\n",
    "print(\"All chunks processed and saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechnung der Chunkgröße und des Restes\n",
    "chunksize = len(bevölkerungs_gdf) // 10  # Bestimmen der Anzahl der Zeilen pro Chunk\n",
    "remainder = len(bevölkerungs_gdf) % 10  # Bestimmen der Anzahl der verbleibenden Zeilen\n",
    "\n",
    "# Verarbeitung der verbleibenden Zeilen (falls vorhanden)\n",
    "if remainder > 0:\n",
    "    last_chunk_start = 10 * chunksize  # Startindex für den letzten Chunk\n",
    "    last_chunk = bevölkerungs_gdf.iloc[last_chunk_start:]  # Extrahieren des letzten Chunks\n",
    "\n",
    "    # Berechnung der Entfernung und Zeit für jede Zeile im letzten Chunk\n",
    "    for index, row in tqdm(last_chunk.iterrows(), total=len(last_chunk)):\n",
    "        distance, time = calculate_distance_to_nearest_pharmacy(row)\n",
    "        last_chunk.loc[index, 'distance_pharmacy'] = distance\n",
    "        last_chunk.loc[index, 'time_pharmacy'] = time\n",
    "    \n",
    "    # Konvertierung der 'Alter'- und 'Geschlecht'-Spalten in JSON-Format\n",
    "    last_chunk['Alter'] = last_chunk['Alter'].apply(json.dumps)\n",
    "    last_chunk['Geschlecht'] = last_chunk['Geschlecht'].apply(json.dumps)\n",
    "    \n",
    "    # Speichern des letzten Chunks als GeoPackage-Datei\n",
    "    last_chunk.to_file(f'./Processed_WLP/Würzburg/pharmacy_assigned_10.gpkg', driver='GPKG')\n",
    "    print(\"Processed remaining rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste zur Speicherung der Dateipfade\n",
    "file_paths = []\n",
    "# Erstellen der Dateipfade für die 11 GeoPackage-Dateien\n",
    "for i in range(11):\n",
    "    file_paths.append(f'./Processed_WLP/Würzburg/pharmacy_assigned_{i}.gpkg')\n",
    "\n",
    "# Verkettung der GeoDataFrames mittels Listenverständnis\n",
    "bevölkerungs_gdf = pd.concat([gpd.read_file(path) for path in file_paths])\n",
    "\n",
    "# Speichern des zusammengefügten GeoDataFrames als eine vollständige GeoPackage-Datei\n",
    "bevölkerungs_gdf.to_file('./WLP/pharmacy_assigned_complete.gpkg', driver='GPKG')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterarbeit_python311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
