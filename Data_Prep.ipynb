{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import csv as csv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "from matplotlib.lines import Line2D\n",
    "import alphashape\n",
    "import random\n",
    "import json\n",
    "import math\n",
    "\n",
    "from scipy.stats import poisson\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "import geopandas as gpd\n",
    "import pyproj\n",
    "from pyproj import Proj, transform, CRS\n",
    "from shapely.geometry import Polygon, Point, MultiPolygon\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bevölkerungsdaten - Zensus Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './Einwohner_Data/Bevoelkerung100M.csv'\n",
    "df = pd.read_csv(file_path, encoding='ISO-8859-1', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_merkmale = [' INSGESAMT', 'ALTER_KURZ', 'GESCHLECHT', 'ALTER_10JG']\n",
    "df_einwohner = df[df['Merkmal'].isin(list_of_merkmale)]\n",
    "\n",
    "df_bezeichnungen = pd.DataFrame()\n",
    "bezeichnungen = ['Merkmal', 'Auspraegung_Text', 'Auspraegung_Code']\n",
    "df_bezeichnungen = df_einwohner[bezeichnungen]\n",
    "df_bezeichnungen.drop_duplicates(inplace=True)\n",
    "df_bezeichnungen.sort_values(by=['Merkmal', 'Auspraegung_Code'], inplace=True)\n",
    "df_bezeichnungen.reset_index(drop=True, inplace=True)\n",
    "df_bezeichnungen.to_csv('./Einwohner_Data/Bezeichnungen.csv', index=False)\n",
    "\n",
    "df_einwohner['Attribute'] = df_einwohner['Merkmal'] + '_' + df_einwohner['Auspraegung_Code'].astype(str)\n",
    "df_einwohner.drop(columns=['Merkmal', 'Auspraegung_Code', 'Auspraegung_Text', 'Gitter_ID_100m', 'Anzahl_q'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df = df_einwohner.pivot(index=['Gitter_ID_100m_neu'], columns=['Attribute'], values='Anzahl').reset_index()\n",
    "pivot_df.columns.name = None\n",
    "pivot_df = pivot_df.fillna(0)\n",
    "pivot_df.rename(columns={' INSGESAMT_0': 'INSGESAMT_0'}, inplace=True)\n",
    "pivot_df.to_csv('./Einwohner_Data/Einwohner_Cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geo = pd.read_csv('./Einwohner_Data/Einwohner_Cleaned.csv')\n",
    "# Extrahiere Informationen aus der Gitter-IDs mithilfe von regulären Ausdrücken\n",
    "pattern = re.compile(r'N(\\d+)E(\\d+)')\n",
    "df_geo[['origin_n', 'origin_e']] = df_geo['Gitter_ID_100m_neu'].str.extract(pattern).astype(int)\n",
    "\n",
    "# Setze feste Werte für crs_code und resolution \n",
    "df_geo['crs_code'] = 3035\n",
    "df_geo['resolution'] = 100\n",
    "\n",
    "# Erstelle Geometrien (Quadrate) für jedes Gitter\n",
    "df_geo['geometry'] = [Polygon([(e, n), (e + 100, n), (e + 100, n - 100), (e, n - 100)]) for e, n in zip(df_geo['origin_e'], df_geo['origin_n'])]\n",
    "df_geo.to_csv('./GeoDaten/GeoDataFrame_Bevoelkerung.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.GeoDataFrame(df_geo, geometry='geometry', crs=CRS(f\"EPSG:{df_geo['crs_code'].iloc[0]}\"))\n",
    "gdf.to_file('./GeoDaten/Deutschland_Raster.gpkg', driver='GPKG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin, vmax = 0, 20\n",
    "# Plotte das GeoDataFrame mit Farbhervorhebung der 'INSGESAMT'-Werte und angepasster Skala\n",
    "gdf.plot(column='INSGESAMT_0', cmap='viridis', legend=True, figsize=(10, 10), vmin=vmin, vmax=vmax)\n",
    "plt.title('Farbliche Hervorhebung der INSGESAMT-Werte')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laden der Verwaltungsbezirke um die Raster zu filtern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file('./99_Old/GeoDaten/Deutschland_Raster_Bevoelkerung.gpkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_bundesländer = gpd.read_file('./99_Old/GeoDaten/DE_NUTS5000.gpkg')\n",
    "geo_würzburg = geo_bundesländer[geo_bundesländer['NUTS_NAME'].str.contains('Würzburg')]\n",
    "geo_würzburg = geo_würzburg.to_crs(gdf.crs)\n",
    "#geo_würzburg.to_file('./Wuerzburg_Data/geo_wuerzburg.gpkg', driver = 'GPKG')\n",
    "mask_overlapping = gdf.geometry.intersects(geo_würzburg.unary_union)\n",
    "gdf_würzburg = gdf[mask_overlapping]\n",
    "gdf_würzburg.to_file('./Wuerzburg_Data/Raster_Wuerzburg.gpkg', driver='GPKG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_bundesländer = gpd.read_file('./GeoDaten/DE_NUTS5000.gpkg')\n",
    "geo_frankfurt = geo_bundesländer[geo_bundesländer['NUTS_NAME'].str.contains('Frankfurt am Main')]\n",
    "geo_frankfurt = geo_frankfurt.to_crs('3035')\n",
    "geo_frankfurt.to_file('./Frankfurt_Data/geo_frankfurt.gpkg', driver = 'GPKG')\n",
    "mask_overlapping = gdf.geometry.intersects(geo_frankfurt.unary_union)\n",
    "gdf_frankfurt = gdf[mask_overlapping]\n",
    "gdf_frankfurt.to_file('./Frankfurt_Data/Raster_Frankfurt.gpkg', driver='GPKG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_bundesländer = gpd.read_file('./GeoDaten/DE_NUTS5000.gpkg')\n",
    "geo_donner = geo_bundesländer[geo_bundesländer['NUTS_NAME'].str.contains('Donnersbergkreis')]\n",
    "geo_donner = geo_donner.to_crs('3035')\n",
    "geo_donner.to_file('./Donner_Data/geo_donner.gpkg', driver = 'GPKG')\n",
    "mask_overlapping = gdf.geometry.intersects(geo_donner.unary_union)\n",
    "gdf_donner = gdf[mask_overlapping]\n",
    "gdf_donner.to_file('./Donner_Data/Raster_Donner.gpkg', driver='GPKG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gebäudedaten und Bevölkerungsdaten mappen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_buildings = pd.read_csv('./Donner_Data/Donner-Buildings.csv')\n",
    "gdf_würzburg = gpd.read_file('./Donner_Data/Raster_Donner.gpkg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gebäude einem Raster zuordnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_polygon_id(point, polygons):\n",
    "    return polygons.distance(point.geometry).sort_values().index[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_buildings = gpd.GeoDataFrame(df_buildings, geometry=gpd.points_from_xy(df_buildings['lon'], df_buildings['lat']), crs=CRS(\"EPSG:4326\"))\n",
    "gdf_buildings = gdf_buildings.to_crs(gdf_würzburg.crs)\n",
    "df_buildings['Raster_ID'] = -1\n",
    "\n",
    "for index, building in gdf_buildings.iterrows():\n",
    "\n",
    "    mask_overlapping = gdf_würzburg.intersects(building['geometry'])\n",
    "    \n",
    "    if any(mask_overlapping):\n",
    "        df_buildings.loc[index, 'Raster_ID'] = gdf_würzburg[mask_overlapping].index[0]\n",
    "    else:\n",
    "        df_buildings.loc[index, 'Raster_ID'] = find_nearest_polygon_id(building, gdf_würzburg)\n",
    "\n",
    "\n",
    "gdf_buildings_with_raster = gpd.GeoDataFrame(df_buildings, geometry=gdf_buildings['geometry'], crs=gdf_würzburg.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zähle die eindeutigen Werte in der Spalte 'Spalte_Name'\n",
    "value_counts = gdf_buildings_with_raster['Raster_ID'].value_counts()\n",
    "\n",
    "# Sortiere die Ergebnisse nach den Werten\n",
    "sorted_value_counts = value_counts.sort_values(ascending = False)\n",
    "\n",
    "# Gib die sortierten Ergebnisse aus\n",
    "print(\"Sortierte Wertezählungen:\")\n",
    "print(sorted_value_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jedem Gebäude die Bevölkerung zuweisen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_buildings_with_raster['Einwohner'] = 0\n",
    "gdf_buildings_with_raster['Alter'] = {} \n",
    "gdf_buildings_with_raster['Geschlecht'] = {} \n",
    "\n",
    "\n",
    "unique_raster_indices = gdf_buildings_with_raster['Raster_ID'].unique()\n",
    "\n",
    "for raster_index in unique_raster_indices:\n",
    "    einwohner_aus_raster = gdf_würzburg.at[raster_index, 'INSGESAMT_0']\n",
    "\n",
    "    alter_dict_raster = {\n",
    "            '0-10':  int(gdf_würzburg.at[raster_index, 'ALTER_10JG_1']),\n",
    "            '10-20': int(gdf_würzburg.at[raster_index, 'ALTER_10JG_2']),\n",
    "            '20-30': int(gdf_würzburg.at[raster_index, 'ALTER_10JG_3']),\n",
    "            '30-40': int(gdf_würzburg.at[raster_index, 'ALTER_10JG_4']), \n",
    "            '40-50': int(gdf_würzburg.at[raster_index, 'ALTER_10JG_5']), \n",
    "            '50-60': int(gdf_würzburg.at[raster_index, 'ALTER_10JG_6']),\n",
    "            '60-70': int(gdf_würzburg.at[raster_index, 'ALTER_10JG_7']), \n",
    "            '70-80': int(gdf_würzburg.at[raster_index, 'ALTER_10JG_8']),\n",
    "            '80+':   int(gdf_würzburg.at[raster_index, 'ALTER_10JG_9'])\n",
    "        }\n",
    "    \n",
    "    geschlecht_dict_raster = {\n",
    "            'maennlich': gdf_würzburg.at[raster_index, 'GESCHLECHT_1'],\n",
    "            'weiblich':  gdf_würzburg.at[raster_index, 'GESCHLECHT_2']\n",
    "        }\n",
    "   \n",
    "    for index, building in gdf_buildings_with_raster[gdf_buildings_with_raster['Raster_ID'] == raster_index].iterrows():\n",
    "\n",
    "        alter_dict_geb = {\n",
    "            '0-10': 0,\n",
    "            '10-20': 0,\n",
    "            '20-30': 0,\n",
    "            '30-40': 0, \n",
    "            '40-50': 0, \n",
    "            '50-60': 0,\n",
    "            '60-70': 0, \n",
    "            '70-80': 0,\n",
    "            '80+': 0\n",
    "        }\n",
    "\n",
    "        geschlecht_dict_geb = {\n",
    "            'maennlich': 0,\n",
    "            'weiblich': 0\n",
    "        }\n",
    "\n",
    "\n",
    "        if index == gdf_buildings_with_raster[gdf_buildings_with_raster['Raster_ID'] == raster_index].index.max():\n",
    "            random_einwohner = einwohner_aus_raster\n",
    "        else:\n",
    "            random_einwohner = np.random.choice(int(einwohner_aus_raster))\n",
    "\n",
    "        \n",
    "        random_einwohner = int(random_einwohner)\n",
    "        alter_count = random_einwohner\n",
    "        geschlecht_count = random_einwohner\n",
    "\n",
    "        for key in np.random.permutation(list(alter_dict_raster.keys())):\n",
    "            if alter_count == 0:\n",
    "                break\n",
    "            if alter_dict_raster[key] > 0:\n",
    "                if alter_count <= alter_dict_raster[key]:\n",
    "                    alter_dict_geb[key] = alter_count\n",
    "                    alter_dict_raster[key] -= alter_count\n",
    "                    alter_count = 0\n",
    "\n",
    "                else:\n",
    "                    alter_dict_geb[key] = alter_dict_raster[key]\n",
    "                    alter_count -= alter_dict_raster[key]\n",
    "                    alter_dict_raster[key] = 0\n",
    "        \n",
    "\n",
    "        if alter_count != 0:\n",
    "            alter_dict_geb[random.choice(list(alter_dict_geb.keys()))] += alter_count\n",
    "            \n",
    "\n",
    "\n",
    "        for key in np.random.permutation(list(geschlecht_dict_raster.keys())):\n",
    "            if geschlecht_count == 0:\n",
    "                break\n",
    "            if geschlecht_dict_raster[key] > 0:\n",
    "                if geschlecht_count <= geschlecht_dict_raster[key]:\n",
    "                    geschlecht_dict_geb[key] = geschlecht_count\n",
    "                    geschlecht_dict_raster[key] -= geschlecht_count\n",
    "                    geschlecht_count = 0\n",
    "\n",
    "                else:\n",
    "                    geschlecht_dict_geb[key] = geschlecht_dict_raster[key]\n",
    "                    geschlecht_count -= geschlecht_dict_raster[key]\n",
    "                    geschlecht_dict_raster[key] = 0\n",
    "\n",
    "\n",
    "        if geschlecht_count != 0:\n",
    "            geschlecht_dict_geb[random.choice(list(geschlecht_dict_geb.keys()))] += geschlecht_count\n",
    "\n",
    "\n",
    "        gdf_buildings_with_raster.at[index, 'Einwohner'] = random_einwohner\n",
    "        gdf_buildings_with_raster.loc[index, 'Alter'] = [alter_dict_geb]\n",
    "        gdf_buildings_with_raster.loc[index, 'Geschlecht'] = [geschlecht_dict_geb]\n",
    "        einwohner_aus_raster -= random_einwohner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_buildings_with_raster['Alter'] = gdf_buildings_with_raster['Alter'].apply(json.dumps)\n",
    "gdf_buildings_with_raster['Geschlecht'] = gdf_buildings_with_raster['Geschlecht'].apply(json.dumps)\n",
    "\n",
    "gdf_buildings_with_raster.to_file('./Donner_Data/Buildings_Raster_Demographie.gpkg', driver='GPKG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pharmacy allocation to each building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['name', 'building', 'addr:street', 'addr:housenumber', 'addr:postcode']\n",
    "bevölkerungs_gdf = gpd.read_file('./Donner_Data/Buildings_Raster_Demographie.gpkg')\n",
    "bevölkerungs_gdf['Alter'] = bevölkerungs_gdf['Alter'].apply(json.loads)\n",
    "bevölkerungs_gdf['Geschlecht'] = bevölkerungs_gdf['Geschlecht'].apply(json.loads)\n",
    "bevölkerungs_gdf.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "pharmacy_df = pd.read_csv('./Donner_Data/Donner-Apotheken.csv')\n",
    "pharmacy_gdf = gpd.GeoDataFrame(pharmacy_df, geometry=gpd.points_from_xy(pharmacy_df['lon'], pharmacy_df['lat']), crs=CRS(\"EPSG:4326\"))\n",
    "pharmacy_gdf = pharmacy_gdf.to_crs(bevölkerungs_gdf.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_point_with_cKDTree(lon, lat, points_df):\n",
    "  coordinates = np.array(points_df[['lon', 'lat']])\n",
    "  reference_point = np.array([lon, lat])\n",
    "  # Calculate pairwise squared distances (faster for cKDTree)\n",
    "  distances = np.sum((coordinates - reference_point)**2, axis=1)\n",
    "  # Find index of minimum distance\n",
    "  idx = np.argmin(distances)\n",
    "\n",
    "  return points_df.iloc[idx]  # Use iloc for faster integer indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance_to_nearest_pharmacy(row):\n",
    "    nearest_pharmacy = find_nearest_point_with_cKDTree(row.lon, row.lat, pharmacy_gdf)\n",
    "    return nearest_pharmacy['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bevölkerungs_gdf['assigned_pharmacy'] = 0 \n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "# Iterate through rows\n",
    "for index, row in tqdm(bevölkerungs_gdf.iterrows(), total=len(bevölkerungs_gdf)):\n",
    "    pharmacy = calculate_distance_to_nearest_pharmacy(row)\n",
    "    bevölkerungs_gdf.loc[index, 'assigned_pharmacy'] = pharmacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bevölkerungs_gdf['Alter'] = bevölkerungs_gdf['Alter'].apply(json.dumps)\n",
    "bevölkerungs_gdf['Geschlecht'] = bevölkerungs_gdf['Geschlecht'].apply(json.dumps)\n",
    "bevölkerungs_gdf.to_file('./Donner_Data/pharmacy_assigned.gpkg', driver='GPKG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nachfrage-Wahrscheinlichkeitsverteilung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequent von Apothekenbesuchen nach Altersverteilung\n",
    "\"Mehrmals in der Woche, Etwa einmal in der Woche, Zwei- bis dreimal im Monat, Einmal im Monat, Etwa einmal im Vierteljahr, Seltener, Nie, so gut wie nie\"\n",
    "apotheken_besuch = {\n",
    "    '14-19': [0.002, 0.005, 0.023, 0.053, 0.18, 0.305, 0.432],\n",
    "    '20-29': [0.003, 0.009, 0.052, 0.131, 0.282, 0.326, 0.197],\n",
    "    '30-39': [0.006, 0.013, 0.098, 0.198, 0.287, 0.275, 0.123],\n",
    "    '40-49': [0.009, 0.014, 0.105, 0.21, 0.297, 0.258, 0.106],\n",
    "    '50-59': [0.008, 0.019, 0.116, 0.252, 0.308, 0.209, 0.087],\n",
    "    '60-69': [0.005, 0.037, 0.173, 0.277, 0.278, 0.159, 0.071],\n",
    "    '70+':   [0.011, 0.065, 0.252, 0.336, 0.196, 0.064, 0.075]\n",
    "}\n",
    "\n",
    "\n",
    "# # Dauerhafte Einnahme von Medikamenten\n",
    "# 'keine, ein bis zwei, drei, vier, fünf oder mehr'\n",
    "# dauerhafte_einnahme = {\n",
    "#     'Maenner': [0.51, 0.24, 0.08, 0.06, 0.11],\n",
    "#     'Frauen':  [0.41, 0.35, 0.09, 0.06, 0.09],\n",
    "#     '18-29':   [0.66, 0.30, 0.02, 0.01, 0.01],\n",
    "#     '30-49':   [0.59, 0.31, 0.05, 0.02, 0.03],\n",
    "#     '50-69':   [0.37, 0.31, 0.12, 0.08, 0.12],\n",
    "#     '70+':     [0.22, 0.23, 0.16, 0.14, 0.25]\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrahieren der Spaltenwerte\n",
    "alter_verteilung = {\n",
    "    \"10-20\": 0,\n",
    "    \"20-30\": 0,\n",
    "    \"30-40\": 0,\n",
    "    \"40-50\": 0,\n",
    "    \"50-60\": 0,\n",
    "    \"60-70\": 0,\n",
    "    \"70-80\": 0\n",
    "}\n",
    "\n",
    "\n",
    "prob_werte = list(apotheken_besuch.values())\n",
    "prob_arrays = np.stack(prob_werte)\n",
    "\n",
    "keys = list(alter_verteilung.keys())\n",
    "\n",
    "#p_Monat = 1 - (1 - p_Tag)^(Anzahl Tage im Monat)\n",
    "#Mehrmals in der Woche, Etwa einmal in der Woche, Zwei- bis dreimal im Monat, Einmal im Monat\n",
    "probabilities = []\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(7):  \n",
    "        if i == 0:\n",
    "            alter_verteilung[keys[j]] += prob_arrays[j][i] / 3.85714285714\n",
    "\n",
    "        if i == 1:\n",
    "            alter_verteilung[keys[j]] += prob_arrays[j][i] / 7\n",
    "\n",
    "        if i == 2:\n",
    "            alter_verteilung[keys[j]] += prob_arrays[j][i] / 12\n",
    "            \n",
    "        if i == 3:\n",
    "            alter_verteilung[keys[j]] += prob_arrays[j][i] / 30\n",
    "\n",
    "        if i == 4:\n",
    "            alter_verteilung[keys[j]] += prob_arrays[j][i] / 90\n",
    "\n",
    "alter_verteilung[\"10-20\"] = alter_verteilung[\"10-20\"] /2 \n",
    "\n",
    "print(alter_verteilung)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transportkapazität"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drohnenlogistik Unternehmen und Drohnenparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 größten Drohnenlogistik Unternehmen:\n",
    "    # Drone Delivery Canada\n",
    "    # Amazon.com, Inc.\n",
    "    # Matternet\n",
    "    # DHL\n",
    "    # Zipline International Inc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drone Delivery Canada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparrow\n",
    "#     Max Range 20 km\n",
    "#     Max Speed 60 km/h\n",
    "#     Max Payload 4 kg\n",
    "#     MTOW 25 kg\n",
    "#     Aircraft Type Rotorcraft\n",
    "#     Powerplant 8 Electric Motors\n",
    "#     Navigation GPS-based\n",
    "#     Delivery Options Land - Drop Ship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canary\n",
    "#     Max Range 20 km\n",
    "#     Max Speed 72 km/h\n",
    "#     Max Payload 4.5 kg\n",
    "#     MTOW 25 kg\n",
    "#     Aircraft Type Rotorcraft\n",
    "#     Powerplant 8 Electric Motors\n",
    "#     Navigation GPS-based\n",
    "#     Delivery Options Land - Drop Ship"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon.com, Inc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prime Air MK27-2\n",
    "#     Max Range 25 km\n",
    "#     Max Speed 80 km/h\n",
    "#     Max Payload 2.26 kg\n",
    "#     MTOW 25 kg\n",
    "#     Max Altitude 122 m\n",
    "#     Weather resistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prime Air MK30\n",
    "#     ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matternet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M2 Drone \n",
    "    # Max Range 20 km\n",
    "    # Max Speed 50 km/h\n",
    "    # Max Payload 2 kg\n",
    "    # Max Altitude 120 m\n",
    "    # MTOW 9.5 kg\n",
    "    # Retail Price 7,499.00$\n",
    "    # Aircraft type Quadcopter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DHL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zipline International Inc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P1\n",
    "#   Max Range 193 km\n",
    "#   Max Speed 105 km/h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering der Rastereinheiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_city = gpd.read_file('./99_Old/Wuerzburg/Raster_Wuerzburg.gpkg')\n",
    "geo_gdf = gpd.read_file('./Wuerzburg_Data/geo_wuerzburg.gpkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrahieren der Polygon-Koordinaten als Features für das Clustering\n",
    "X = np.array(gdf_city.geometry.apply(lambda polygon: [polygon.centroid.x, polygon.centroid.y]).tolist())\n",
    "\n",
    "# DBSCAN-Clustering durchführen\n",
    "dbscan = DBSCAN(eps=100, min_samples=4)  # Anpassen von eps und min_samples je nach Bedarf\n",
    "dbscan.fit(X)\n",
    "\n",
    "# Fügen Sie die Cluster-Zuordnung als neue Spalte zum GeoDataFrame hinzu\n",
    "gdf_city['cluster'] = dbscan.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Gruppieren nach Clustern und Polygone in MultiPolygone umwandeln\n",
    "# multi_polygons = gdf_city.groupby('cluster')['geometry'].apply(lambda x: MultiPolygon(list(x)))\n",
    "# # Ein neues GeoDataFrame erstellen mit den MultiPolygons\n",
    "# gdf_multi = gpd.GeoDataFrame(multi_polygons, geometry='geometry').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion, um einen Teil einer Colormap zu extrahieren\n",
    "def truncate_colormap(cmap, minval=0.5, maxval=1.0, n=100):\n",
    "    new_cmap = plt.cm.colors.LinearSegmentedColormap.from_list(\n",
    "        f'trunc({cmap.name},{minval:.2f},{maxval:.2f})', \n",
    "        cmap(np.linspace(minval, maxval, n)))\n",
    "    return new_cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verwende den helleren Teil der cividis-Colormap\n",
    "cmap = truncate_colormap(plt.get_cmap('viridis'), 0.5, 1.0)\n",
    "\n",
    "# Berechne die 10 größten Cluster ohne Cluster -1\n",
    "top_clusters = gdf_city[gdf_city['cluster'] != -1]['cluster'].value_counts().nlargest(10).index\n",
    "\n",
    "# Anzahl der Polygone im Cluster -1\n",
    "outlier_count = len(gdf_city[gdf_city['cluster'] == -1])\n",
    "\n",
    "# Plotten der Boundary\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "geo_gdf.boundary.plot(ax=ax, color='gray', linewidth=0.5)\n",
    "\n",
    "# Plotten der Polygone mit Cluster-Färbung\n",
    "gdf_city[gdf_city['cluster'] != -1].plot(ax=ax, column='cluster', cmap=cmap, legend=False)\n",
    "gdf_city[gdf_city['cluster'] == -1].plot(ax=ax, color='purple', legend=False)  # Lila für Cluster -1\n",
    "\n",
    "# for cluster_id in gdf_multi[gdf_multi['cluster']!= -1].cluster:\n",
    "#     cluster_data = gdf_city[gdf_city['cluster'] == cluster_id]\n",
    "#     # Kombiniere alle Geometrien des Clusters zu einer einzigen Geometrie\n",
    "#     combined_geom = cluster_data.unary_union\n",
    "#     # Berechne die konvexe Hülle der kombinierten Geometrie\n",
    "#     if isinstance(combined_geom, (MultiPolygon, Polygon)):\n",
    "#         outer_boundary = combined_geom.convex_hull\n",
    "#         gpd.GeoSeries(outer_boundary).boundary.plot(ax=ax, color='lightgray', linewidth=0.4)\n",
    "#     else:\n",
    "#         for geom in combined_geom.geoms:\n",
    "#             gpd.GeoSeries(geom.convex_hull).boundary.plot(ax=ax, color='lightgray', linewidth=0.4)\n",
    "\n",
    "\n",
    "# Zentroiden und Anzahl der Polygone der 10 größten Cluster anzeigen\n",
    "for cluster_id in top_clusters:\n",
    "    cluster_data = gdf_city[gdf_city['cluster'] == cluster_id]\n",
    "    centroid = cluster_data.geometry.unary_union.centroid\n",
    "    polygon_count = len(cluster_data)\n",
    "    ax.plot(centroid.x, centroid.y, '^', color='red', markersize=6)\n",
    "    ax.text(centroid.x + 1800, centroid.y, str(polygon_count), fontsize=12, ha='center', va='center', color='black', fontweight='bold')  # Versetzte Position\n",
    "\n",
    "# Hinzufügen eines Farbbalkens\n",
    "norm = plt.Normalize(vmin=gdf_city['cluster'].min(), vmax=gdf_city['cluster'].max())\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cbar = fig.colorbar(sm, ax=ax, shrink=0.65)  # Colormap kleiner machen\n",
    "cbar.set_label('ID der Cluster')\n",
    "# Text unterhalb der Farblegende hinzufügen\n",
    "plt.text(1.2, 0, f'Anzahl der Ausreiser: {outlier_count}', ha='right', va='center', transform=ax.transAxes, fontsize=10)\n",
    "\n",
    "\n",
    "# Add scale bar\n",
    "scalebar = ScaleBar(1, location='lower left', label='Maßstab')\n",
    "ax.add_artist(scalebar)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alle eindeutigen Cluster-Werte und ihre Anzahl der Polygone ausgeben\n",
    "cluster_counts = gdf_city['cluster'].value_counts().sort_index()\n",
    "print(\"Cluster-Werte und ihre Anzahl der Polygone:\")\n",
    "for cluster, count in cluster_counts.items():\n",
    "    print(f\"Cluster {cluster}: {count} Polygone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotten der Rauschpunkte (Clusterlabel -1)\n",
    "noise_points = gdf_city[gdf_city['cluster'] == -1]\n",
    "ax = noise_points.boundary.plot(color='red', alpha=0.5, figsize=(5, 5))\n",
    "plt.title('Noise')\n",
    "plt.xlabel('X-Achse')\n",
    "plt.ylabel('Y-Achse')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_to_sum = 'INSGESAMT_0'\n",
    "sum_of_column = noise_points[column_to_sum].sum()\n",
    "\n",
    "print('Anzahl der Raster, die als Noise erkannt wurden: {}'.format(len(noise_points)))\n",
    "print(\"Sum of column '{}' in noise points: {}\".format(column_to_sum, sum_of_column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gruppierung nach dem Cluster und Aggregierung der Punkte in jedem Cluster\n",
    "cluster_summary = gdf_city.groupby('cluster').agg(\n",
    "    Gitter_ID_100m_neu=('Gitter_ID_100m_neu', 'first'),\n",
    "    count=('cluster', 'size'),  # Anzahl der Polygone in jedem Cluster\n",
    "    sum_INSGESAMT_0=('INSGESAMT_0', 'sum'),  \n",
    "    sum_ALTER_10JG_1=('ALTER_10JG_1', 'sum'), \n",
    "    sum_ALTER_10JG_2=('ALTER_10JG_2', 'sum'), \n",
    "    sum_ALTER_10JG_3=('ALTER_10JG_3', 'sum'), \n",
    "    sum_ALTER_10JG_4=('ALTER_10JG_4', 'sum'), \n",
    "    sum_ALTER_10JG_5=('ALTER_10JG_5', 'sum'), \n",
    "    sum_ALTER_10JG_6=('ALTER_10JG_6', 'sum'), \n",
    "    sum_ALTER_10JG_7=('ALTER_10JG_7', 'sum'), \n",
    "    sum_ALTER_10JG_8=('ALTER_10JG_8', 'sum'), \n",
    "    sum_ALTER_10JG_9=('ALTER_10JG_9', 'sum'),\n",
    "    sum_GESCHLECHT_1=('GESCHLECHT_1', 'sum'),\n",
    "    sum_GESCHLECHT_2=('GESCHLECHT_2', 'sum'),\n",
    "    crs_code=('crs_code', 'first'),\n",
    "    resolution=('resolution', 'first'),\n",
    "    origin_n=('origin_n', 'first'),\n",
    "    origin_e=('origin_e', 'first'),\n",
    "    geometry=('geometry', lambda x: unary_union(x))  # Vereinigung der Polygone in jedem Cluster\n",
    ") \n",
    "\n",
    "# Umwandeln des aggregierten DataFrames in ein GeoDataFrame\n",
    "cluster_summary_gdf = gpd.GeoDataFrame(cluster_summary, geometry='geometry', crs=gdf_city.crs)\n",
    "cluster_summary_gdf = cluster_summary_gdf.reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zur Berechnung der Entfernung zwischen zwei Punkten\n",
    "def distance(point1, point2):\n",
    "    return point1.distance(point2)\n",
    "\n",
    "# Berechnung der durchschnittlichen Entfernung von jedem Polygon-Centroid zu seinen Ecken\n",
    "average_distances = []\n",
    "for idx, row in cluster_summary_gdf.iterrows():\n",
    "    centroid = row['geometry'].centroid\n",
    "    polygon = row['geometry']\n",
    "\n",
    "    if isinstance(polygon, MultiPolygon):\n",
    "        average_distance = 0  # Setzen Sie die durchschnittliche Entfernung auf 0 für Multipolygone\n",
    "    else:\n",
    "        # Extrahieren der Koordinaten der Polygon-Ecken\n",
    "        polygon_corners = polygon.exterior.coords[:-1]  # Letzter Punkt ist der gleiche wie der erste\n",
    "        # Berechnung der Entfernungen und Speichern der Ergebnisse\n",
    "        distances = [distance(centroid, Point(coord)) for coord in polygon_corners]\n",
    "        average_distance = sum(distances) / len(distances)\n",
    "        \n",
    "    average_distances.append(average_distance)\n",
    "\n",
    "# Hinzufügen der durchschnittlichen Entfernungen als neue Spalte zum GeoDataFrame\n",
    "cluster_summary_gdf['average_distance'] = average_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot der Raster mit Polygone farblich darstellen\n",
    "ax = cluster_summary_gdf.plot(cmap='viridis', legend=True, figsize=(5, 5))\n",
    "\n",
    "# Hervorhebung der Rastergrenzen\n",
    "cluster_summary_gdf.boundary.plot(ax=ax, color='black')\n",
    "\n",
    "# Titel hinzufügen\n",
    "plt.title('Bevölkerungsraster des Landkreis Würzburg')\n",
    "\n",
    "# Achsenbeschriftungen hinzufügen\n",
    "plt.xlabel('Breitengradkoordinate im CSR3035 Format')\n",
    "plt.ylabel('Längengradkoordinate im CSR3035 Format')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiere die Projektionen\n",
    "in_proj = Proj(init='epsg:3035')  # CSR3035\n",
    "out_proj = Proj(init='epsg:4326')  # WGS84 (Längen- und Breitengrade)\n",
    "\n",
    "# Funktion zum Umwandeln von CSR3035-Koordinaten in Längen- und Breitengrade\n",
    "def csr3035_to_latlon(polygon):\n",
    "    point = polygon.centroid\n",
    "    x_csr3035 = point.x\n",
    "    y_csr3035 = point.y\n",
    "    lon, lat = transform(in_proj, out_proj, x_csr3035, y_csr3035)\n",
    "    return lon, lat\n",
    "\n",
    "# Wende die Funktion auf die Geometry-Spalte an und erstelle neue Spalten für Längen- und Breitengrade\n",
    "cluster_summary_gdf['lon'], cluster_summary_gdf['lat'] = zip(*cluster_summary_gdf['geometry'].apply(lambda point: csr3035_to_latlon(point)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_group_columns = [col for col in cluster_summary_gdf.columns if col.startswith('sum_ALTER_10JG_')]\n",
    "\n",
    "new_age_groups = { '0-10': 0,\n",
    "                    '10-20': 3,\n",
    "                    '20-30': 0,\n",
    "                    '30-40': 0,\n",
    "                    '40-50': 6,\n",
    "                    '50-60': 8,\n",
    "                    '60-70': 0,\n",
    "                    '70-80': 9,\n",
    "                    '80+': 0}\n",
    "\n",
    "age_groups_list = list(new_age_groups.keys())\n",
    "\n",
    "\n",
    "def get_age_group_data(cluster_summary_gdf):\n",
    "    age_group_data = {}\n",
    "\n",
    "    for count in range(9):\n",
    "        age_group =  age_groups_list[count] # Extract age group from column name\n",
    "        population = cluster_summary_gdf[age_group_columns[count]]\n",
    "        age_group_data[age_group] = population\n",
    "    return age_group_data\n",
    "\n",
    "\n",
    "# Extract and merge age group data\n",
    "age_group_data_per_cluster = cluster_summary_gdf.apply(get_age_group_data, axis=1)\n",
    "\n",
    "cluster_summary_gdf['Alter'] = age_group_data_per_cluster\n",
    "\n",
    "# Remove the original 'ALTER_10JG_' columns\n",
    "cluster_summary_gdf.drop(columns=age_group_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polygon Geopandas speichern\n",
    "cluster_summary_gdf.to_file('./Donner_Data/cluster_donner.gpkg', driver='GPKG')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterarbeit_python311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
